"""
Spike: Valida se Claude usa CognitiveModel naturalmente via prompt
Objetivo: Testar se leitura de estado √© suficiente (sem tool)
"""
from anthropic import Anthropic
import os
import json
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv()

# Simular cognitive_model atualizado pelo Observador
COGNITIVE_MODEL_EXAMPLE = {
    "claim": "LLMs aumentam produtividade de desenvolvedores Python",
    "proposicoes": [
        {
            "texto": "Existem equipes de desenvolvimento Python no mercado",
            "solidez": 0.85,
            "tipo": "fundamento"
        },
        {
            "texto": "LLMs podem gerar c√≥digo automaticamente",
            "solidez": 0.70,
            "tipo": "fundamento"
        }
    ],
    "concepts_detected": ["LLMs", "Produtividade", "Python"],
    "contradictions": [
        "Usu√°rio afirma que LLMs aumentam produtividade, mas tamb√©m disse que c√≥digo gerado precisa revis√£o extensa"
    ],
    "open_questions": [
        "Como medir produtividade objetivamente?",
        "Qual baseline de compara√ß√£o?"
    ],
    "overall_solidez": 0.42,
    "overall_completude": 0.35
}

ORCHESTRATOR_PROMPT = """Voc√™ √© o Orquestrador Socr√°tico, respons√°vel por guiar o desenvolvimento do argumento.

COGNITIVE MODEL DISPON√çVEL
O Observador analisou o di√°logo e extraiu o seguinte modelo cognitivo:

Afirma√ß√£o atual:
{claim}

Fundamentos identificados:
{proposicoes}

Conceitos detectados:
{concepts}

Contradi√ß√µes detectadas:
{contradictions}

Quest√µes em aberto:
{open_questions}

M√©tricas:
- Solidez geral: {solidez:.2f} (qu√£o bem fundamentada est√° a afirma√ß√£o)
- Completude: {completude:.2f} (quanto do argumento foi desenvolvido)

CONTEXTO DA CONVERSA
Usu√°rio disse: "Acho que LLMs realmente aumentam a produtividade. Equipes Python existem e LLMs geram c√≥digo. Mas √© verdade que o c√≥digo precisa de muita revis√£o..."

SUA TAREFA
Analise o Cognitive Model e o contexto. Decida o pr√≥ximo passo:
- explore: Fazer pergunta socr√°tica para aprofundar
- suggest_agent: Chamar agente especializado
- clarify: Pedir clarifica√ß√£o de ambiguidade

Explique seu racioc√≠nio e decis√£o.
"""


def test_natural_usage():
    """Testa se Claude usa cognitive_model naturalmente"""
    print("\n" + "="*60)
    print("TESTE: Claude Usa CognitiveModel Naturalmente?")
    print("="*60 + "\n")

    client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

    # Formatar prompt
    prompt = ORCHESTRATOR_PROMPT.format(
        claim=COGNITIVE_MODEL_EXAMPLE["claim"],
        proposicoes=json.dumps(COGNITIVE_MODEL_EXAMPLE["proposicoes"], indent=2, ensure_ascii=False),
        concepts=", ".join(COGNITIVE_MODEL_EXAMPLE["concepts_detected"]),
        contradictions="\n".join(f"- {c}" for c in COGNITIVE_MODEL_EXAMPLE["contradictions"]),
        open_questions="\n".join(f"- {q}" for q in COGNITIVE_MODEL_EXAMPLE["open_questions"]),
        solidez=COGNITIVE_MODEL_EXAMPLE["overall_solidez"],
        completude=COGNITIVE_MODEL_EXAMPLE["overall_completude"]
    )

    print("üì§ Enviando prompt para Claude...\n")

    response = client.messages.create(
        model="claude-3-5-haiku-20241022",
        max_tokens=1000,
        messages=[{
            "role": "user",
            "content": prompt
        }]
    )

    reasoning = response.content[0].text

    print("="*60)
    print("RESPOSTA DE CLAUDE")
    print("="*60 + "\n")
    print(reasoning)
    print("\n" + "="*60)

    # An√°lise
    print("\nAN√ÅLISE\n")

    keywords = {
        "solidez": "solidez" in reasoning.lower() or "0.42" in reasoning,
        "completude": "completude" in reasoning.lower() or "0.35" in reasoning,
        "contradi√ß√£o": "contradi" in reasoning.lower(),
        "quest√µes abertas": "quest√µes" in reasoning.lower() or "quest√µes em aberto" in reasoning.lower() or "open" in reasoning.lower(),
        "conceitos": any(c.lower() in reasoning.lower() for c in COGNITIVE_MODEL_EXAMPLE["concepts_detected"])
    }

    for key, found in keywords.items():
        status = "‚úÖ" if found else "‚ùå"
        print(f"{status} Mencionou '{key}': {found}")

    usage_score = sum(keywords.values()) / len(keywords)

    print(f"\nüìä Score de uso: {usage_score:.0%}")

    if usage_score >= 0.6:
        print("\n‚úÖ SUCESSO: Claude usa cognitive_model naturalmente")
        print("   Recomenda√ß√£o: Leitura de estado √© SUFICIENTE")
        return True
    else:
        print("\n‚ùå FALHA: Claude ignora cognitive_model")
        print("   Recomenda√ß√£o: Considerar tool expl√≠cito")
        return False


if __name__ == "__main__":
    success = test_natural_usage()

    print("\n" + "="*60)
    if success:
        print("CONCLUS√ÉO: ‚úÖ Proposta VI√ÅVEL")
    else:
        print("CONCLUS√ÉO: ‚ùå Proposta precisa AJUSTE")
    print("="*60 + "\n")

