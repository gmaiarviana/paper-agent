"""
Script para debugar resposta do LLM especificamente na detecÃ§Ã£o de maturidade.
"""
import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import json
from agents.models.cognitive_model import CognitiveModel
from agents.persistence.snapshot_manager import MATURITY_DETECTION_PROMPT
from utils.config import create_anthropic_client
from langchain_core.messages import HumanMessage

def test_maturity_detection():
    """Testa detecÃ§Ã£o de maturidade com LLM."""
    print("=" * 70)
    print(" DEBUG: Testando DetecÃ§Ã£o de Maturidade com LLM")
    print("=" * 70)

    # Criar modelo cognitivo de teste (imaturo)
    model_v1 = CognitiveModel(
        claim="LLMs aumentam produtividade",
        premises=["Reduzem tempo de tarefas repetitivas"],
        assumptions=["UsuÃ¡rios sabem usar LLMs"],
        open_questions=["Quanto aumenta exatamente?"],
    )

    print("\nğŸ“Š Modelo Cognitivo V1 (imaturo):")
    print(f"   Claim: {model_v1.claim}")
    print(f"   Premises: {len(model_v1.premises)}")
    print(f"   Assumptions: {len(model_v1.assumptions)}")
    print(f"   Open questions: {len(model_v1.open_questions)}")

    # Preparar dados para LLM
    model_dict = model_v1.to_dict()
    model_json = json.dumps(model_dict, indent=2, ensure_ascii=False)

    print("\nğŸ“ JSON enviado ao LLM:")
    print(model_json[:200] + "..." if len(model_json) > 200 else model_json)

    # Preparar prompt
    prompt = MATURITY_DETECTION_PROMPT.format(cognitive_model_json=model_json)

    print(f"\nğŸ“ Tamanho do prompt: {len(prompt)} caracteres")
    print("\nğŸ“ Prompt (primeiros 500 chars):")
    print(prompt[:500] + "...")

    # Criar cliente LLM
    llm = create_anthropic_client("claude-3-5-haiku-20241022")
    print("\nâœ… Cliente LLM criado")

    # Invocar LLM
    try:
        print("\nğŸ“ Invocando LLM...")
        message = HumanMessage(content=prompt)
        response = llm.invoke([message])

        print(f"\nâœ… Resposta recebida (tipo: {type(response.content)})")
        print(f"ğŸ“ Tamanho da resposta: {len(response.content)} caracteres")
        print("\nğŸ“ Resposta completa:")
        print("=" * 70)
        print(response.content)
        print("=" * 70)

        # Tentar parsear JSON
        response_text = response.content.strip()

        print(f"\nğŸ” Resposta apÃ³s strip: '{response_text[:100]}...'")
        print(f"   ComeÃ§a com '```': {response_text.startswith('```')}")
        print(f"   ComeÃ§a com '{{': {response_text.startswith('{')}")

        # Remover markdown code blocks se presentes
        if response_text.startswith("```"):
            print("   â†’ Removendo markdown code block")
            lines = response_text.split("\n")
            response_text = "\n".join(lines[1:-1])
            print(f"   â†’ ApÃ³s remoÃ§Ã£o: '{response_text[:100]}...'")

        print("\nğŸ”§ Tentando parsear JSON...")
        assessment_dict = json.loads(response_text)
        print("âœ… JSON parseado com sucesso!")
        print(json.dumps(assessment_dict, indent=2, ensure_ascii=False))

    except json.JSONDecodeError as e:
        print(f"\nâŒ Erro ao parsear JSON: {e}")
        print(f"   PosiÃ§Ã£o do erro: linha {e.lineno}, coluna {e.colno}")
        print(f"   Mensagem: {e.msg}")
        print(f"\nğŸ“ Texto que tentou parsear:")
        print("=" * 70)
        print(repr(response_text))
        print("=" * 70)
        return False
    except Exception as e:
        print(f"\nâŒ Erro inesperado: {e}")
        import traceback
        traceback.print_exc()
        return False

    print("\n" + "=" * 70)
    print("âœ… TESTE PASSOU!")
    print("=" * 70)
    return True

if __name__ == "__main__":
    success = test_maturity_detection()
    sys.exit(0 if success else 1)
