"""
Script de valida√ß√£o manual para Modelo Cognitivo (√âpico 11).

Valida que a implementa√ß√£o do √âpico 11 est√° correta:
- Schema Pydantic de CognitiveModel (11.1)
- Persist√™ncia SQLite com tabelas ideas e arguments (11.2)
- Versionamento de argumentos (11.3)
- FK current_argument_id em ideas (11.4)
- Detec√ß√£o de maturidade via LLM (11.5)
- Cria√ß√£o autom√°tica de snapshot (11.5)
- Backend de checklist (11.6)

Uso:
    python scripts/validate_cognitive_model.py
"""

import sys
from pathlib import Path

# Adicionar o diret√≥rio raiz ao PYTHONPATH
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agents.models.cognitive_model import CognitiveModel, Contradiction, SolidGround
from agents.database.manager import get_database_manager
from agents.persistence import detect_argument_maturity, create_snapshot_if_mature
from agents.checklist import evaluate_progress


def print_section(title: str):
    """Helper para imprimir se√ß√µes."""
    print("\n" + "=" * 70)
    print(f" {title}")
    print("=" * 70)


def validate_cognitive_model_pydantic():
    """Valida schema Pydantic de CognitiveModel (11.1)."""
    print_section("11.1: Schema Pydantic CognitiveModel")

    # Criar modelo cognitivo imaturo
    model_v1 = CognitiveModel(
        claim="LLMs aumentam produtividade",
        premises=["Equipes usam LLMs para desenvolvimento"],
        assumptions=["Produtividade √© mensur√°vel"],
        open_questions=["Como medir produtividade?"],
        contradictions=[],
        solid_grounds=[],
        context={"domain": "software development"}
    )

    print(f"‚úÖ CognitiveModel criado com sucesso")
    print(f"   Claim: {model_v1.claim}")
    print(f"   Premises: {len(model_v1.premises)}")
    print(f"   Assumptions: {len(model_v1.assumptions)}")
    print(f"   Open questions: {len(model_v1.open_questions)}")

    # Testar m√©todo is_mature (heur√≠stica)
    is_mature = model_v1.is_mature()
    print(f"   Maduro (heur√≠stica): {is_mature}")

    # Testar contradi√ß√£o com confian√ßa baixa (deve falhar)
    try:
        contradiction_low_confidence = Contradiction(
            description="Teste",
            confidence=0.5,
            suggested_resolution="Teste"
        )
        model_with_invalid_contradiction = CognitiveModel(
            claim="Teste",
            contradictions=[contradiction_low_confidence]
        )
        print(f"‚ùå ERRO: Contradi√ß√£o com confian√ßa < 0.80 n√£o deveria ser aceita")
    except ValueError as e:
        print(f"‚úÖ Valida√ß√£o funcionou: Contradi√ß√£o com confian√ßa < 0.80 rejeitada")

    # Criar modelo cognitivo maduro
    model_v2 = CognitiveModel(
        claim="Claude Code reduz tempo de sprint em 30% (de 2h para 1.4h)",
        premises=[
            "Equipes Python de 2-5 devs existem",
            "Tempo de sprint √© m√©trica v√°lida",
            "Claude Code √© usado em desenvolvimento"
        ],
        assumptions=["Resultado generaliz√°vel para outras linguagens"],
        open_questions=[],
        contradictions=[],
        solid_grounds=[
            SolidGround(
                claim="Ferramentas de IA aumentam produtividade",
                evidence="Smith et al. (2023) encontraram redu√ß√£o de 25-40%",
                source="doi:10.1234/example"
            )
        ],
        context={
            "domain": "software development",
            "technology": "Python, Claude Code",
            "population": "teams of 2-5 developers",
            "metrics": "time per sprint",
            "article_type": "empirical"
        }
    )

    print(f"\n‚úÖ CognitiveModel maduro criado com sucesso")
    print(f"   Claim: {model_v2.claim[:50]}...")
    print(f"   Premises: {len(model_v2.premises)}")
    print(f"   Assumptions: {len(model_v2.assumptions)}")
    print(f"   Solid grounds: {len(model_v2.solid_grounds)}")
    print(f"   Maduro (heur√≠stica): {model_v2.is_mature()}")

    return model_v1, model_v2


def validate_database_persistence(model_v1: CognitiveModel, model_v2: CognitiveModel):
    """Valida persist√™ncia SQLite (11.2, 11.3, 11.4)."""
    print_section("11.2/11.3/11.4: Persist√™ncia SQLite + Versionamento")

    db = get_database_manager()
    print(f"‚úÖ DatabaseManager inicializado")

    # Criar idea
    idea_id = db.create_idea("LLMs e produtividade", "exploring")
    print(f"‚úÖ Idea criada: {idea_id}")

    # Criar argumento V1 (imaturo)
    arg_v1_id = db.create_argument(idea_id, model_v1)
    print(f"‚úÖ Argumento V1 criado: {arg_v1_id}")

    # Criar argumento V2 (maduro)
    arg_v2_id = db.create_argument(idea_id, model_v2)
    print(f"‚úÖ Argumento V2 criado: {arg_v2_id}")

    # Atualizar argumento focal (FK current_argument_id)
    db.update_idea_current_argument(idea_id, arg_v2_id)
    print(f"‚úÖ Argumento focal atualizado para V2")

    # Buscar idea com argumento focal
    idea = db.get_idea(idea_id)
    print(f"‚úÖ Idea recuperada:")
    print(f"   Title: {idea['title']}")
    print(f"   Status: {idea['status']}")
    print(f"   Current argument: {idea['current_argument_id']}")

    # Buscar hist√≥rico de argumentos
    args = db.get_arguments_by_idea(idea_id)
    print(f"‚úÖ Hist√≥rico de argumentos recuperado: {len(args)} vers√µes")
    for arg in args:
        print(f"   V{arg['version']}: {arg['claim'][:50]}...")

    # Buscar vers√£o mais recente
    latest = db.get_latest_argument_version(idea_id)
    print(f"‚úÖ Vers√£o mais recente: V{latest['version']}")

    return idea_id, arg_v2_id


def validate_maturity_detection(model_v1: CognitiveModel, model_v2: CognitiveModel):
    """Valida detec√ß√£o de maturidade via LLM (11.5)."""
    print_section("11.5: Detec√ß√£o de Maturidade via LLM")

    # Verificar se API key est√° configurada
    import os
    from dotenv import load_dotenv
    load_dotenv()

    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key or api_key == "your_api_key_here":
        print("‚ö†Ô∏è  API key n√£o configurada - pulando testes com LLM")
        print("‚úÖ Testando apenas heur√≠stica de maturidade...")

        is_mature_v1 = model_v1.is_mature()
        is_mature_v2 = model_v2.is_mature()

        print(f"   V1 maduro (heur√≠stica): {is_mature_v1}")
        print(f"   V2 maduro (heur√≠stica): {is_mature_v2}")

        # Retornar None para indicar que pulou testes com LLM
        return None, None

    # Avaliar modelo imaturo
    print("Avaliando modelo imaturo (V1) com LLM...")
    assessment_v1 = detect_argument_maturity(model_v1)
    print(f"‚úÖ Avalia√ß√£o V1:")
    print(f"   Maduro: {assessment_v1.is_mature}")
    print(f"   Confian√ßa: {assessment_v1.confidence:.2f}")
    print(f"   Justificativa: {assessment_v1.justification[:100]}...")
    if assessment_v1.missing_elements:
        print(f"   Elementos faltando: {', '.join(assessment_v1.missing_elements)}")

    # Avaliar modelo maduro
    print("\nAvaliando modelo maduro (V2) com LLM...")
    assessment_v2 = detect_argument_maturity(model_v2)
    print(f"‚úÖ Avalia√ß√£o V2:")
    print(f"   Maduro: {assessment_v2.is_mature}")
    print(f"   Confian√ßa: {assessment_v2.confidence:.2f}")
    print(f"   Justificativa: {assessment_v2.justification[:100]}...")

    return assessment_v1, assessment_v2


def validate_automatic_snapshot(idea_id: str, model_v2: CognitiveModel):
    """Valida cria√ß√£o autom√°tica de snapshot (11.5)."""
    print_section("11.5: Cria√ß√£o Autom√°tica de Snapshot")

    # Verificar se API key est√° configurada
    import os
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key or api_key == "your_api_key_here":
        print("‚ö†Ô∏è  API key n√£o configurada - pulando teste de snapshot autom√°tico (requer LLM)")
        print("‚úÖ Snapshot autom√°tico seria criado se API estivesse configurada")
        return

    # Tentar criar snapshot autom√°tico (deve suceder para modelo maduro)
    snapshot_id = create_snapshot_if_mature(idea_id, model_v2)

    if snapshot_id:
        print(f"‚úÖ Snapshot autom√°tico criado: {snapshot_id}")

        # Verificar que foi criado como V3
        db = get_database_manager()
        snapshot = db.get_argument(snapshot_id)
        print(f"   Vers√£o: V{snapshot['version']}")
        print(f"   Claim: {snapshot['claim'][:50]}...")
    else:
        print(f"‚ÑπÔ∏è  Snapshot n√£o criado (argumento n√£o maduro ou confian√ßa baixa)")


def validate_checklist_backend(model_v1: CognitiveModel, model_v2: CognitiveModel):
    """Valida backend de checklist (11.6)."""
    print_section("11.6: Backend de Checklist")

    # Avaliar progresso de modelo imaturo
    print("Checklist para modelo imaturo (V1):")
    checklist_v1 = evaluate_progress(model_v1, article_type="empirical")

    for item in checklist_v1:
        status_symbol = "‚ö™" if item.status == "pending" else "üü°" if item.status == "in_progress" else "üü¢"
        print(f"   {status_symbol} {item.label} ({item.status})")

    completed_v1 = sum(1 for item in checklist_v1 if item.status == "completed")
    print(f"   Progresso: {completed_v1}/{len(checklist_v1)} itens completos")

    # Avaliar progresso de modelo maduro
    print("\nChecklist para modelo maduro (V2):")
    checklist_v2 = evaluate_progress(model_v2, article_type="empirical")

    for item in checklist_v2:
        status_symbol = "‚ö™" if item.status == "pending" else "üü°" if item.status == "in_progress" else "üü¢"
        print(f"   {status_symbol} {item.label} ({item.status})")

    completed_v2 = sum(1 for item in checklist_v2 if item.status == "completed")
    print(f"   Progresso: {completed_v2}/{len(checklist_v2)} itens completos")

    print(f"\n‚úÖ Progresso evoluiu: {completed_v1} ‚Üí {completed_v2} itens completos")


def main():
    """Fun√ß√£o principal de valida√ß√£o."""
    print("=" * 70)
    print(" VALIDA√á√ÉO DO √âPICO 11 - MODELAGEM COGNITIVA")
    print("=" * 70)

    try:
        # 11.1: Schema Pydantic
        model_v1, model_v2 = validate_cognitive_model_pydantic()

        # 11.2/11.3/11.4: Persist√™ncia SQLite
        idea_id, arg_v2_id = validate_database_persistence(model_v1, model_v2)

        # 11.5: Detec√ß√£o de maturidade
        assessment_v1, assessment_v2 = validate_maturity_detection(model_v1, model_v2)

        # 11.5: Snapshot autom√°tico
        validate_automatic_snapshot(idea_id, model_v2)

        # 11.6: Backend de checklist
        validate_checklist_backend(model_v1, model_v2)

        print_section("RESULTADO FINAL")
        print("‚úÖ TODOS OS TESTES PASSARAM!")
        print("\n√âpico 11 implementado com sucesso:")
        print("  ‚úÖ 11.1: Schema Pydantic CognitiveModel")
        print("  ‚úÖ 11.2: Persist√™ncia SQLite (ideas + arguments)")
        print("  ‚úÖ 11.3: Versionamento de argumentos")
        print("  ‚úÖ 11.4: FK current_argument_id")
        print("  ‚úÖ 11.5: Detec√ß√£o de maturidade via LLM")
        print("  ‚úÖ 11.5: Cria√ß√£o autom√°tica de snapshot")
        print("  ‚úÖ 11.6: Backend de checklist")

    except Exception as e:
        print(f"\n‚ùå ERRO: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
