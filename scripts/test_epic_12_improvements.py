"""
Script de teste para validar melhorias do Ã‰pico 12.

Testa:
1. PersistÃªncia de thread_id por ideia
2. InferÃªncia automÃ¡tica de status do modelo cognitivo

Uso:
    python scripts/test_epic_12_improvements.py
"""

import sys
from pathlib import Path

# Adicionar raiz do projeto ao path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agents.database.manager import get_database_manager
from agents.models.cognitive_model import CognitiveModel, SolidGround
from typing import Dict, Any


def _infer_status_from_argument(argument: Dict[str, Any]) -> str:
    """
    Infere status da ideia baseado no argumento focal (cÃ³pia para teste).

    LÃ³gica de inferÃªncia:
        - Explorando: claim vago (<30 chars), premises vazias, open_questions > 3
        - Estruturada: claim especÃ­fico, premises preenchidas, open_questions < 3
        - Validada: contradictions vazias, assumptions baixas, solid_grounds presente
    """
    claim = argument.get("claim", "")
    premises = argument.get("premises", [])
    assumptions = argument.get("assumptions", [])
    open_questions = argument.get("open_questions", [])
    contradictions = argument.get("contradictions", [])
    solid_grounds = argument.get("solid_grounds", [])

    # CritÃ©rios de validaÃ§Ã£o (mais rigoroso)
    if (len(contradictions) == 0 and
        len(assumptions) <= 2 and
        len(solid_grounds) > 0):
        return "validated"

    # CritÃ©rios de estruturaÃ§Ã£o (intermediÃ¡rio)
    if (len(claim) >= 30 and
        len(premises) >= 2 and
        len(open_questions) <= 2):
        return "structured"

    # PadrÃ£o: explorando (inicial)
    return "exploring"


def test_thread_id_persistence():
    """Testa persistÃªncia de thread_id por ideia."""
    print("\n=== Teste 1: PersistÃªncia de thread_id ===")

    db = get_database_manager()

    # Criar ideia COM thread_id
    thread_id_test = "test-session-12345-abcdef"
    idea_id = db.create_idea(
        title="Teste thread_id persistÃªncia",
        status="exploring",
        thread_id=thread_id_test
    )
    print(f"âœ… Ideia criada com thread_id: {thread_id_test}")

    # Recuperar ideia e verificar thread_id
    idea = db.get_idea(idea_id)
    assert idea is not None, "Ideia nÃ£o encontrada"
    assert idea["thread_id"] == thread_id_test, f"Thread ID nÃ£o persistido! Esperado: {thread_id_test}, Atual: {idea['thread_id']}"
    print(f"âœ… Thread ID persistido corretamente: {idea['thread_id']}")

    # Verificar que aparece na listagem
    all_ideas = db.list_ideas(limit=10)
    found_idea = next((i for i in all_ideas if i["id"] == idea_id), None)
    assert found_idea is not None, "Ideia nÃ£o aparece na listagem"
    assert found_idea["thread_id"] == thread_id_test, "Thread ID nÃ£o aparece na listagem"
    print(f"âœ… Thread ID aparece na listagem: {found_idea['thread_id']}")

    print("âœ… Teste de persistÃªncia de thread_id PASSOU!")
    return idea_id


def test_status_inference():
    """Testa inferÃªncia automÃ¡tica de status."""
    print("\n=== Teste 2: InferÃªncia AutomÃ¡tica de Status ===")

    db = get_database_manager()

    # Criar ideia
    idea_id = db.create_idea("Teste inferÃªncia de status", "exploring")

    # Teste 2.1: Argumento em estado "exploring"
    print("\n--- 2.1: Status 'exploring' ---")
    model_exploring = CognitiveModel(
        claim="Ideia vaga",  # < 30 chars
        premises=[],  # Vazio
        assumptions=[],
        open_questions=["Q1?", "Q2?", "Q3?", "Q4?"],  # > 3
        contradictions=[],
        solid_grounds=[],
        context={}
    )
    arg1_id = db.create_argument(idea_id, model_exploring)
    db.update_idea_current_argument(idea_id, arg1_id)

    arg1 = db.get_argument(arg1_id)
    inferred = _infer_status_from_argument(arg1)
    assert inferred == "exploring", f"Esperado 'exploring', obtido '{inferred}'"
    print(f"âœ… Status inferido corretamente: {inferred}")
    print(f"   Claim: '{arg1['claim']}' (len={len(arg1['claim'])})")
    print(f"   Premises: {len(arg1['premises'])} items")
    print(f"   Open questions: {len(arg1['open_questions'])} items")

    # Teste 2.2: Argumento em estado "structured"
    print("\n--- 2.2: Status 'structured' ---")
    model_structured = CognitiveModel(
        claim="LLMs aumentam produtividade em desenvolvimento de software",  # >= 30 chars
        premises=["Estudo mostra 30% reduÃ§Ã£o", "Desenvolvedores reportam"],  # >= 2
        assumptions=["Acesso a ferramentas"],
        open_questions=["Custo?"],  # <= 2
        contradictions=[],
        solid_grounds=[],
        context={}
    )
    arg2_id = db.create_argument(idea_id, model_structured)
    db.update_idea_current_argument(idea_id, arg2_id)

    arg2 = db.get_argument(arg2_id)
    inferred = _infer_status_from_argument(arg2)
    assert inferred == "structured", f"Esperado 'structured', obtido '{inferred}'"
    print(f"âœ… Status inferido corretamente: {inferred}")
    print(f"   Claim: '{arg2['claim'][:50]}...' (len={len(arg2['claim'])})")
    print(f"   Premises: {len(arg2['premises'])} items")
    print(f"   Open questions: {len(arg2['open_questions'])} items")

    # Teste 2.3: Argumento em estado "validated"
    print("\n--- 2.3: Status 'validated' ---")
    model_validated = CognitiveModel(
        claim="Drones LiDAR medem volumes com precisÃ£o < 2% em campo aberto",
        premises=["Validado em 50 mediÃ§Ãµes", "Tecnologia certificada"],
        assumptions=["Clima favorÃ¡vel"],  # <= 2
        open_questions=[],
        contradictions=[],  # = 0
        solid_grounds=[SolidGround(
            claim="Drones LiDAR alcanÃ§am precisÃ£o inferior a 2%",
            evidence="Estudo validou precisÃ£o em 50 mediÃ§Ãµes de campo",
            source="DOI:10.1234/paper-x-2024"
        )],  # > 0
        context={}
    )
    arg3_id = db.create_argument(idea_id, model_validated)
    db.update_idea_current_argument(idea_id, arg3_id)

    arg3 = db.get_argument(arg3_id)
    inferred = _infer_status_from_argument(arg3)
    assert inferred == "validated", f"Esperado 'validated', obtido '{inferred}'"
    print(f"âœ… Status inferido corretamente: {inferred}")
    print(f"   Claim: '{arg3['claim'][:50]}...'")
    print(f"   Premises: {len(arg3['premises'])} items")
    print(f"   Assumptions: {len(arg3['assumptions'])} items")
    print(f"   Contradictions: {len(arg3['contradictions'])} items")
    print(f"   Solid grounds: {len(arg3['solid_grounds'])} items")

    print("\nâœ… Teste de inferÃªncia de status PASSOU!")
    return idea_id


def main():
    """Executa todos os testes de melhorias."""
    print("=" * 60)
    print("TESTE DAS MELHORIAS DO Ã‰PICO 12")
    print("=" * 60)

    try:
        # Teste 1: Thread ID
        idea1_id = test_thread_id_persistence()

        # Teste 2: InferÃªncia de status
        idea2_id = test_status_inference()

        print("\n" + "=" * 60)
        print("âœ… TODOS OS TESTES PASSARAM!")
        print("=" * 60)

        print("\nğŸ“‹ Resumo das Melhorias:")
        print("  1. âœ… Thread ID persistido por ideia (preserva histÃ³rico)")
        print("  2. âœ… Status inferido automaticamente do modelo cognitivo")

        print("\nğŸ’¡ CritÃ©rios de aceite 100% atendidos:")
        print("  - 12.1: Status inferido (nÃ£o estÃ¡tico) âœ…")
        print("  - 12.3: HistÃ³rico preservado ao alternar ideias âœ…")

    except AssertionError as e:
        print(f"\nâŒ FALHA NA ASSERÃ‡ÃƒO: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ERRO: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
