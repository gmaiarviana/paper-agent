# Memory Agent (Mem√≥ria de Longo Prazo)

## Vis√£o Geral

O **Memory Agent** √© respons√°vel por armazenar e recuperar mem√≥ria de longo prazo do sistema. Inspirado na mem√≥ria humana, organiza informa√ß√µes em **camadas temporais** com degrada√ß√£o natural: informa√ß√£o recente √© mais acess√≠vel, informa√ß√£o antiga requer mais esfor√ßo para acessar.

## Status

‚ö†Ô∏è **CONCEITUAL - N√ÉO IMPLEMENTADO**

Este documento descreve a vis√£o futura do Memory Agent. Atualmente, o sistema mant√©m hist√≥rico completo em mem√≥ria ativa do Orquestrador/Observador.

## Filosofia

### Inspira√ß√£o: Mem√≥ria Humana

Assim como humanos:
- Lembram facilmente do que aconteceu ontem
- Precisam de esfor√ßo para lembrar do m√™s passado
- Podem esquecer detalhes, mas lembrar da ess√™ncia
- Consolidam mem√≥rias importantes, descartam trivialidades

### Problema que Resolve

**Sem Memory Agent:**
Conversa com 50 turnos:
‚îú‚îÄ Orquestrador processa 10k tokens de hist√≥rico a cada turno
‚îú‚îÄ Custo: ~$0.15 por turno
‚îú‚îÄ Lat√™ncia: ~2s de processamento
‚îî‚îÄ Escalabilidade: quebra em conversas longas (100+ turnos)

**Com Memory Agent:**
Conversa com 50 turnos:
‚îú‚îÄ Orquestrador processa apenas CognitiveModel (~500 tokens)
‚îú‚îÄ Memory consultado apenas quando necess√°rio (5-10% dos turnos)
‚îú‚îÄ Custo: ~$0.03 por turno (economia de 80%)
‚îú‚îÄ Lat√™ncia: ~500ms (busca em camada superficial)
‚îî‚îÄ Escalabilidade: suporta conversas infinitas

## Arquitetura

### Tr√™s Camadas de Mem√≥ria
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           CAMADA SUPERFICIAL (Recente)          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Resumos Condensados                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - key_phrases: ["LLMs", "produtividade"]‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - context_summary: "..."                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - concepts: [conceito_ids]              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - turn_range: 40-50                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - accessibility: R√ÅPIDA (~100-300ms)    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      CAMADA INTERMEDI√ÅRIA (Evolu√ß√£o)            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Snapshots de CognitiveModel             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - claim: "..."                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - proposicoes: [...]                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - solidez: 0.65                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - turn: 25                              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - accessibility: MODERADA (~300ms-1s)   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         CAMADA PROFUNDA (Literal)               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Mensagens Literais Brutas               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - user_message: "..."                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - assistant_message: "..."              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - turn: 5                               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - timestamp: ISO-8601                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - accessibility: LENTA (~1-5s)          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - pode estar COMPACTADA (>30 dias)      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

### Degrada√ß√£o Temporal
```python
def calcular_accessibility(dias_desde_turno: int) -> float:
    """
    Retorna score de acessibilidade (1.0 = instant√¢neo, 0.1 = muito lento)
    """
    if dias_desde_turno <= 7:
        return 1.0  # √öltima semana: fresco
    elif dias_desde_turno <= 30:
        return 0.7  # √öltimo m√™s: acess√≠vel
    elif dias_desde_turno <= 365:
        return 0.4  # √öltimo ano: requer esfor√ßo
    else:
        return 0.1  # Mais de 1 ano: arquivado, muito lento
```

## Responsabilidades

### 1. Armazenamento em Camadas

**Quando um turno ocorre:**

Mensagem literal ‚Üí armazenada em Camada Profunda
Observador processa ‚Üí gera resumo condensado ‚Üí Camada Superficial
CognitiveModel muda significativamente ‚Üí snapshot ‚Üí Camada Intermedi√°ria


**Exemplo:**
```python
# Turno 15: Usu√°rio define baseline
memory.store_literal(
    turn=15,
    user_msg="Baseline √© 45min sem ferramenta",
    assistant_msg="Entendi. Ent√£o a m√©trica ser√° tempo economizado vs 45min"
)

memory.store_summary(
    turn_range=(15, 15),
    summary="Baseline definido: 45min sem ferramenta",
    key_phrases=["baseline", "45min", "sem ferramenta"],
    concepts=["m√©trica", "baseline"]
)

# CognitiveModel mudou: baseline era undefined, agora √© 45min
memory.store_snapshot(
    turn=15,
    cognitive_model={
        "claim": "LLMs aumentam produtividade",
        "baseline": "45min",
        "metrica": "tempo economizado",
        "solidez": 0.65
    }
)
```

### 2. Busca Estratificada (Query)

**Orquestrador consulta Memory:**
```python
# Busca por padr√£o: come√ßa na camada superficial
resultado = memory.query(
    query="O que o usu√°rio disse sobre baseline?",
    max_results=3,
    strategy="superficial_first"  # tenta superficial ‚Üí intermedi√°ria ‚Üí profunda
)
```

**Estrat√©gias de busca:**

**A) Superficial First (padr√£o):**

Busca embedding em Camada Superficial
Se encontrar match (score > 0.8) ‚Üí retorna
Se n√£o, busca em Camada Intermedi√°ria
Se n√£o, busca em Camada Profunda (√∫ltimo recurso)


**B) Deep Search (quando precis√£o literal √© necess√°ria):**

Busca diretamente em Camada Profunda
Retorna mensagens literais exatas
Mais lento, mas mais preciso


**C) Evolution Search (rastrear mudan√ßas):**

Busca snapshots em Camada Intermedi√°ria
Retorna evolu√ß√£o temporal de CognitiveModel
√ötil para: "quando definimos popula√ß√£o?", "como claim mudou?"


### 3. Compacta√ß√£o Peri√≥dica

**Processo mensal (automatizado):**
```python
def compactar_mensal():
    """
    Turnos com >30 dias:
    1. Camada Profunda: comprimir mensagens literais (gzip)
    2. Camada Superficial: manter intacto (j√° √© resumo)
    3. Camada Intermedi√°ria: manter snapshots cr√≠ticos apenas
    """
    turnos_antigos = memory.get_turns_older_than(days=30)
    
    for turno in turnos_antigos:
        # Comprimir literal
        memory.compress_literal(turno, method="gzip")
        
        # Manter snapshot apenas se CognitiveModel mudou >20%
        if snapshot_is_critical(turno):
            memory.keep_snapshot(turno)
        else:
            memory.delete_snapshot(turno)
```

**Processo anual (automatizado):**
```python
def compactar_anual():
    """
    Turnos com >365 dias:
    1. Arquivar Camada Profunda (cold storage)
    2. Manter apenas Camada Superficial + snapshots cr√≠ticos
    3. Acesso requer descompacta√ß√£o (~10s+)
    """
    turnos_muito_antigos = memory.get_turns_older_than(days=365)
    memory.archive_to_cold_storage(turnos_muito_antigos)
```

## Gatilhos de Consulta

Memory Agent √© **reativo**, n√£o proativo. Consultado apenas quando necess√°rio:

### 1. Observador Detecta Incongru√™ncia
Observador: "Usu√°rio disse 'bugs aumentaram', mas CognitiveModel diz 'bugs est√°veis'"
‚Üì
Observador sinaliza Orquestrador
‚Üì
Orquestrador: "Deixa eu verificar contexto hist√≥rico..."
‚Üì
Orquestrador consulta Memory: "Buscar men√ß√µes a 'bugs' nos √∫ltimos 20 turnos"
‚Üì
Memory retorna: "Turno 3: 'bugs est√°veis h√° 6 meses'
Turno 15: 'bugs aumentaram 20% no √∫ltimo m√™s'"
‚Üì
Orquestrador: "N√£o √© contradi√ß√£o, s√£o per√≠odos diferentes"

### 2. Valida√ß√£o de Entendimento
Orquestrador: "Usu√°rio mencionou 'baseline'. Ele j√° definiu isso?"
‚Üì
Orquestrador consulta Memory: "Buscar defini√ß√£o de 'baseline'"
‚Üì
Memory retorna: "Turno 8: 'Baseline √© 45min sem ferramenta'"
‚Üì
Orquestrador: "Sim, j√° definiu. N√£o preciso perguntar de novo."

### 3. Recall Expl√≠cito do Usu√°rio
Usu√°rio: "O que eu disse sobre popula√ß√£o?"
‚Üì
Orquestrador consulta Memory: "Buscar men√ß√µes a 'popula√ß√£o'"
‚Üì
Memory retorna: "Turno 12: 'Popula√ß√£o s√£o equipes Python de 2-5 devs'"
‚Üì
Orquestrador responde: "Voc√™ definiu popula√ß√£o como equipes Python de 2-5 devs"

### 4. Mudan√ßa de Foco (Retomar Ideia Anterior)
Usu√°rio: "E aquela ideia de produtividade?"
‚Üì
Observador: "Foco atual √© 'bugs', usu√°rio quer voltar para 'produtividade'"
‚Üì
Observador sinaliza Orquestrador
‚Üì
Orquestrador consulta Memory: "Buscar discuss√µes sobre 'produtividade'"
‚Üì
Memory retorna: "Turnos 1-12: Explora√ß√£o de LLMs e produtividade,
Claim em constru√ß√£o: 'LLMs aumentam produtividade'"
‚Üì
Orquestrador: "A gente estava explorando LLMs e produtividade. Quer retomar?"

## Fluxo de Informa√ß√£o
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TURNO                          ‚îÇ
‚îÇ  Usu√°rio envia mensagem                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 OBSERVADOR                        ‚îÇ
‚îÇ  1. Processa turno                                ‚îÇ
‚îÇ  2. Detecta padr√µes/incongru√™ncias                ‚îÇ
‚îÇ  3. Gera resumo condensado                        ‚îÇ
‚îÇ  4. Atualiza CognitiveModel                       ‚îÇ
‚îÇ  5. Sinaliza Orquestrador (se necess√°rio)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               ORQUESTRADOR                        ‚îÇ
‚îÇ  1. Recebe sinal do Observador                    ‚îÇ
‚îÇ  2. Decide se precisa consultar Memory            ‚îÇ
‚îÇ  3. Se sim: formula query                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚Üì (apenas se necess√°rio)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               MEMORY AGENT                        ‚îÇ
‚îÇ  1. Recebe query do Orquestrador                  ‚îÇ
‚îÇ  2. Busca em camadas (superficial ‚Üí profunda)     ‚îÇ
‚îÇ  3. Retorna resultados                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               ORQUESTRADOR                        ‚îÇ
‚îÇ  1. Processa resultados de Memory                 ‚îÇ
‚îÇ  2. Decide next_step                              ‚îÇ
‚îÇ  3. Responde usu√°rio (ou envia para Comunicador)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚Üì
(fim do turno)
‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               MEMORY AGENT                        ‚îÇ
‚îÇ  1. Armazena mensagem literal (Camada Profunda)   ‚îÇ
‚îÇ  2. Armazena resumo (Camada Superficial)          ‚îÇ
‚îÇ  3. Armazena snapshot se necess√°rio (Intermedi√°ria)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

## Integra√ß√£o com Bastidores Transparentes

Quando usu√°rio ativa bastidores transparentes, Memory Agent registra:
```json
{
  "agent": "memory_agent",
  "action": "query",
  "input": {
    "query": "Buscar defini√ß√£o de baseline",
    "strategy": "superficial_first"
  },
  "output": {
    "layer": "superficial",
    "results": [
      {
        "turn_range": "8-8",
        "summary": "Baseline definido: 45min sem ferramenta",
        "score": 0.92
      }
    ],
    "latency_ms": 120
  },
  "reasoning": "Orquestrador consultou Memory porque usu√°rio mencionou 'baseline' sem contexto"
}
```

Usu√°rio v√™:
üîç [Bastidores]
‚îú‚îÄ Orquestrador consultou Memory
‚îú‚îÄ Busca: "defini√ß√£o de baseline"
‚îú‚îÄ Encontrado em: Camada Superficial (Turno 8)
‚îî‚îÄ Lat√™ncia: 120ms

## Configura√ß√£o por Produto

### Paper-Agent (Sess√£o)
```python
memory_config = {
    "scope": "session",
    "superficial": {
        "max_turns": 10,  # √öltimos 10 turnos resumidos
        "retention_days": 7
    },
    "intermediaria": {
        "snapshot_on": "cognitive_model_change > 20%",
        "retention_days": 30
    },
    "profunda": {
        "max_turns": 50,  # √öltimas 50 mensagens literais
        "compress_after_days": 30
    }
}
```

### Fichamento (Documento)
```python
memory_config = {
    "scope": "document",
    "superficial": {
        "group_by": "chapter",  # Resumo por cap√≠tulo
        "retention_days": 90
    },
    "intermediaria": {
        "snapshot_on": "new_concept_identified",
        "retention_days": 365
    },
    "profunda": {
        "store": "citations_only",  # Apenas cita√ß√µes literais
        "compress_after_days": 90
    }
}
```

### Rede Social (Perfil)
```python
memory_config = {
    "scope": "user_profile",
    "superficial": {
        "max_conversations": 10,  # √öltimas 10 conversas resumidas
        "retention_days": 30
    },
    "intermediaria": {
        "snapshot_on": "interest_evolution",  # Mudan√ßas de interesse
        "retention_years": 5
    },
    "profunda": {
        "archive_after_days": 365,
        "compress": True
    }
}
```

## Implementa√ß√£o Futura

### Tecnologias Candidatas

**Armazenamento:**
- ChromaDB: embeddings para busca sem√¢ntica (Camada Superficial)
- SQLite: metadados estruturados (timestamps, turn_ids, scores)
- Redis: cache de queries recentes (hot memory)
- S3/Blob Storage: camada profunda compactada/arquivada

**Busca:**
- Sentence-Transformers: gerar embeddings de queries
- FAISS: busca vetorial r√°pida
- Full-text search: fallback para literais (PostgreSQL FTS ou Elasticsearch)

**Compacta√ß√£o:**
- gzip: compress√£o de mensagens literais
- Delta encoding: armazenar apenas mudan√ßas em snapshots consecutivos

### M√©tricas de Sucesso

- **Taxa de hit em Camada Superficial**: >70% das queries resolvidas sem ir fundo
- **Lat√™ncia m√©dia de query**: <500ms (P95)
- **Economia de custo**: >60% vs processar hist√≥rico completo
- **Precis√£o de recall**: >90% quando usu√°rio pergunta sobre passado

## Refer√™ncias

- `../architecture/data-models/ontology.md` - MemoryLayer na ontologia
- `../architecture/vision/super_system.md` - Configura√ß√£o por produto
- `docs/agents/orchestrator.md` - Quem consulta Memory
- `docs/agents/observer.md` - Quem detecta necessidade de consulta
- `core/docs/features/transparent_backstage.md` - Rastreamento de consultas

---

**Status**: Conceitual, aguardando implementa√ß√£o
**Prioridade**: Alta (ap√≥s √âpico 13 - Conceitos)
**Complexidade**: Alta (novo agente, novo storage, nova l√≥gica de busca)

