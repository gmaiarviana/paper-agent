Methodologist Agent
===================

**Status:** Em desenvolvimento (Ã‰picos 2 â†’ 4)
**VersÃ£o:** 1.4
**Data:** 13/11/2025

## Resumo

Agente especializado em avaliar rigor cientÃ­fico de hipÃ³teses. Implementado como agente autÃ´nomo usando LangGraph, capaz de:
- Fazer perguntas ao usuÃ¡rio para obter clarificaÃ§Ãµes
- Tomar decisÃµes com raciocÃ­nio explÃ­cito
- Avaliar hipÃ³teses segundo critÃ©rios metodolÃ³gicos (testabilidade, falseabilidade, especificidade)

**âš ï¸ NOTA IMPORTANTE:** O Metodologista Ã© chamado **automaticamente** pelo Orquestrador quando o contexto Ã© suficiente para validaÃ§Ã£o metodolÃ³gica. O Orquestrador faz curadoria do resultado e apresenta ao usuÃ¡rio em tom coeso, sem necessidade de negociaÃ§Ã£o prÃ©via.

## ImplementaÃ§Ã£o Atual

### Modo Colaborativo (Ã‰pico 4)

**Objetivo:** Metodologista como PARCEIRO que ajuda a construir, nÃ£o apenas validar.

**3 Modos de operaÃ§Ã£o:**

1. **approved:**
   - HipÃ³tese testÃ¡vel, falseÃ¡vel, especÃ­fica, operacionalizada
   - Estrutura cientÃ­fica sÃ³lida
   - Pronta para desenho experimental

2. **needs_refinement (NOVO):**
   - Ideia tem potencial cientÃ­fico
   - Falta especificidade (populaÃ§Ã£o, mÃ©tricas, variÃ¡veis)
   - Pode ser melhorada com refinamento
   - Campo `improvements` lista gaps especÃ­ficos

3. **rejected:**
   - Sem base cientÃ­fica (crenÃ§a popular, impossÃ­vel testar)
   - Vagueza extrema que refinamento nÃ£o resolve
   - Usado apenas em casos extremos

**Quando usar cada modo:**

| Input | Modo | RazÃ£o |
|-------|------|-------|
| "MÃ©todo X reduz tempo em 30% em equipes 2-5 devs" | approved | TestÃ¡vel, especÃ­fico |
| "MÃ©todo X Ã© mais rÃ¡pido" | needs_refinement | Potencial, falta populaÃ§Ã£o/mÃ©tricas |
| "X Ã© bom porque todo mundo sabe" | rejected | Apelo Ã  crenÃ§a, nÃ£o-testÃ¡vel |

### Estado (MethodologistState)

TypedDict gerenciado pelo LangGraph com os seguintes campos:

- `hypothesis` (str): HipÃ³tese a ser avaliada
- `messages` (Annotated[list, add_messages]): HistÃ³rico de mensagens do grafo
- `clarifications` (dict[str, str]): Perguntas e respostas coletadas
- `status` (Literal["pending", "approved", "rejected"]): Status da anÃ¡lise
- `iterations` (int): Contador de perguntas feitas
- `max_iterations` (int): Limite de perguntas (padrÃ£o: 3)
- `justification` (str): Justificativa da decisÃ£o final
- `needs_clarification` (bool): Flag de controle de fluxo

**Checkpointer:** MemorySaver para persistÃªncia de sessÃ£o em memÃ³ria

### Tools Implementadas

#### `ask_user(question: str) -> str`
- Permite agente fazer perguntas ao usuÃ¡rio
- Usa `interrupt()` do LangGraph para pausar execuÃ§Ã£o
- Logging estruturado de perguntas e respostas
- **LocalizaÃ§Ã£o:** `agents/methodologist/tools.py:18`

### NÃ³s do Grafo

#### 1. `analyze` (agents/methodologist/nodes.py:38)
**Responsabilidade:** Avaliar hipÃ³tese e decidir se precisa de clarificaÃ§Ãµes

**Processo:**
1. Analisa hipÃ³tese fornecida
2. Considera clarificaÃ§Ãµes jÃ¡ coletadas
3. Usa LLM (claude-3-5-haiku-20241022) para decidir se tem informaÃ§Ã£o suficiente
4. Atualiza `needs_clarification` para controlar fluxo

**Output:**
```python
{
    "messages": [AIMessage],  # AnÃ¡lise do LLM
    "needs_clarification": bool  # True se precisa de mais info
}
```

#### 2. `ask_clarification` (agents/methodologist/nodes.py:119)
**Responsabilidade:** Solicitar clarificaÃ§Ã£o ao usuÃ¡rio

**Processo:**
1. Verifica se atingiu `max_iterations`
2. Usa LLM para formular pergunta especÃ­fica sobre aspectos metodolÃ³gicos
3. Chama `ask_user()` para obter resposta
4. Registra em `clarifications`
5. Incrementa `iterations`

**Output:**
```python
{
    "clarifications": dict,  # Pergunta/resposta adicionada
    "iterations": int,  # Contador incrementado
    "messages": [AIMessage, HumanMessage]
}
```

#### 3. `decide` (agents/methodologist/nodes.py:215)
**Responsabilidade:** Tomar decisÃ£o final sobre a hipÃ³tese

**Processo:**
1. Analisa toda informaÃ§Ã£o coletada (hipÃ³tese + clarificaÃ§Ãµes)
2. Avalia segundo critÃ©rios cientÃ­ficos:
   - Testabilidade
   - Falseabilidade
   - Especificidade
   - OperacionalizaÃ§Ã£o
3. Define status (approved/rejected)
4. Gera justificativa detalhada

### Output (atualizado - Ã‰pico 4)

**Estrutura:**
```python
{
    "status": "approved" | "needs_refinement" | "rejected",
    "justification": str,
    "improvements": [  # NOVO - apenas se needs_refinement
        {
            "aspect": "populaÃ§Ã£o" | "mÃ©tricas" | "variÃ¡veis" | "testabilidade",
            "gap": str,
            "suggestion": str
        }
    ],
    "clarifications": dict  # Mantido do Ã‰pico 2
}
```

**Exemplo de needs_refinement:**
```python
{
    "status": "needs_refinement",
    "justification": "Ideia central clara (mÃ©todo incremental impacta velocidade), mas falta operacionalizaÃ§Ã£o para teste empÃ­rico.",
    "improvements": [
        {
            "aspect": "populaÃ§Ã£o",
            "gap": "NÃ£o especificada",
            "suggestion": "Definir populaÃ§Ã£o-alvo (ex: equipes de 2-5 desenvolvedores com experiÃªncia em LangGraph)"
        },
        {
            "aspect": "mÃ©tricas",
            "gap": "Velocidade nÃ£o mensurÃ¡vel",
            "suggestion": "Operacionalizar velocidade (ex: tempo por sprint, bugs por deploy, taxa de retrabalho)"
        }
    ],
    "clarifications": {}
}
```

### Knowledge Base

**LocalizaÃ§Ã£o:** `core/docs/agents/methodologist_knowledge.md`

**ConteÃºdo:**
- DiferenÃ§a entre lei, teoria e hipÃ³tese
- CritÃ©rios de testabilidade e falseabilidade (Popper)
- Exemplos prÃ¡ticos de hipÃ³teses boas vs ruins:
  - CafeÃ­na e desempenho cognitivo
  - MÃºsica e crescimento de plantas

**Nota:** Knowledge base micro para MVP. VersÃ£o completa serÃ¡ implementada futuramente com tool `consult_methodology`.

### System Prompt

**LocalizaÃ§Ã£o:** `utils/prompts/methodologist.py`
**Constante:** `METHODOLOGIST_AGENT_SYSTEM_PROMPT_V1`

**CaracterÃ­sticas:**
- Linguagem direta e concisa (265 palavras)
- InstruÃ§Ãµes explÃ­citas sobre uso da tool `ask_user`
- Define output JSON: `{"status": "approved|rejected", "justification": "..."}`
- CritÃ©rios cientÃ­ficos claros: testabilidade, falseabilidade, especificidade, operacionalizaÃ§Ã£o
- Exemplos prÃ¡ticos de aprovaÃ§Ã£o e rejeiÃ§Ã£o

**ValidaÃ§Ã£o:** `scripts/health_checks/validate_system_prompt.py`

### Prompt Colaborativo (Ã‰pico 4)

**LocalizaÃ§Ã£o:** `utils/prompts/methodologist.py` - `METHODOLOGIST_DECIDE_PROMPT_V2`

**InstruÃ§Ãµes adicionadas:**
```
MODO COLABORATIVO (Ã‰pico 4):

VocÃª Ã© um PARCEIRO que ajuda a CONSTRUIR hipÃ³teses, nÃ£o apenas validar
Use "needs_refinement" quando a ideia tem potencial mas falta especificidade
Use "rejected" APENAS quando nÃ£o hÃ¡ base cientÃ­fica (crenÃ§a popular, impossÃ­vel testar)
Campo "improvements": seja ESPECÃFICO sobre gaps e como preencher

DECISÃƒO DE STATUS:

approved: TestÃ¡vel + especÃ­fico + operacionalizado
needs_refinement: Potencial + falta elementos (populaÃ§Ã£o, mÃ©tricas, variÃ¡veis)
rejected: Sem base cientÃ­fica + impossÃ­vel refinar

CAMPO "improvements" (needs_refinement):
[
{
"aspect": "populaÃ§Ã£o" | "mÃ©tricas" | "variÃ¡veis" | "testabilidade",
"gap": "DescriÃ§Ã£o clara do que falta",
"suggestion": "Como preencher (exemplo concreto)"
}
]
EXEMPLOS:
Input: "MÃ©todo X Ã© melhor"
Output: {
"status": "needs_refinement",
"improvements": [
{"aspect": "mÃ©tricas", "gap": "Melhor nÃ£o mensurÃ¡vel", "suggestion": "Definir: reduz tempo em X%, aumenta qualidade em Y%"}
]
}
```

### Fluxo de ExecuÃ§Ã£o (Interno do Metodologista)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   START     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     needs_clarification=true    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   analyze   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ ask_clarificationâ”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                                  â”‚
      â”‚ needs_clarification=false                        â”‚
      â”‚                 â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                      (loop atÃ© max_iterations)
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   decide    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     END     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Uso no Fluxo Multi-Agente (TransiÃ§Ã£o Fluida)

**âš ï¸ IMPORTANTE:** O Metodologista Ã© chamado automaticamente pelo Orquestrador
quando o contexto Ã© suficiente para validaÃ§Ã£o metodolÃ³gica. O Orquestrador
faz curadoria do resultado e apresenta ao usuÃ¡rio em tom coeso.

**Fluxo:**

1. Orquestrador detecta contexto suficiente (hipÃ³tese estruturada)
2. Metodologista Ã© chamado automaticamente (bastidores)
3. Metodologista valida: approved | needs_refinement | rejected
4. Orquestrador recebe resultado e faz curadoria
5. Orquestrador apresenta: "Validei sua hipÃ³tese: [resultado]. Faz sentido?"

**Exemplo completo:**

```
Orquestrador: "Validei sua hipÃ³tese. Ela atende critÃ©rios de testabilidade
              e falseabilidade. Identifiquei que falta definir baseline.
              Isso faz sentido para vocÃª?"
[Bastidores: ğŸ”¬ Metodologista validou â†’ ğŸ¯ Orquestrador curou]
â†“
UsuÃ¡rio: "Faz sentido, mas como definir baseline?"
â†“
Orquestrador: "Podemos usar mÃ©tricas histÃ³ricas da equipe ou benchmark
              da literatura. Qual prefere?"
```

**PrincÃ­pios:**
- âœ… Metodologista trabalha **automaticamente** quando contexto suficiente
- âœ… Refinamento Ã© **automÃ¡tico** quando necessÃ¡rio
- âœ… Orquestrador **cura resposta final** (tom unificado)
- âœ… TransparÃªncia nos **bastidores** (usuÃ¡rio pode ver quem trabalhou)
- âœ… UsuÃ¡rio pode **mudar de direÃ§Ã£o** a qualquer momento

### LLM Utilizado

**Modelo:** claude-3-5-haiku-20241022
**Justificativa:** Custo-efetivo para MVP, suficiente para anÃ¡lise metodolÃ³gica e geraÃ§Ã£o de JSON estruturado
**Temperature:** 0 (determinÃ­stico)

## Testes

### Testes UnitÃ¡rios
- **Estado:** `tests/unit/test_methodologist_state.py` (4/4)
- **Tool ask_user:** `tests/unit/test_ask_user_tool.py` (10/10)
- **NÃ³s do grafo:** `tests/unit/test_graph_nodes.py` (16/16)

### Scripts de ValidaÃ§Ã£o Manual
- `scripts/state_introspection/validate_state.py`: Valida estado e checkpointer
- `scripts/state_introspection/validate_ask_user.py`: Valida tool ask_user
- `scripts/state_introspection/validate_graph_nodes.py`: Valida nÃ³s do grafo

## EvoluÃ§Ã£o (Ã‰picos 2 â†’ 4)

**Ã‰pico 2:** Metodologista validador
- âœ… Analisa hipÃ³tese
- âœ… Faz perguntas (ask_user)
- âœ… Decide: approved/rejected

**Ã‰pico 4:** Metodologista colaborativo
- âœ… Modo "needs_refinement" (novo)
- âœ… Campo "improvements" com gaps especÃ­ficos
- âœ… Integrado no fluxo conversacional (nÃ£o automÃ¡tico)
- âš ï¸ **Refinamento sob demanda** (usuÃ¡rio decide quando refinar)
- âŒ DecisÃ£o forÃ§ada removida (usuÃ¡rio controla iteraÃ§Ãµes)

**Futuras melhorias (pÃ³s-Ã‰pico 4):**
- Tool `consult_methodology` para knowledge base ampliada
- SugestÃµes de desenho experimental
- ValidaÃ§Ã£o de testes estatÃ­sticos

