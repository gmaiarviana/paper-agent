# Ontologia do Sistema

## VisÃ£o Geral

Este documento Ã© o **Single Source of Truth (SSoT)** que define a ontologia do super-sistema. Ele estabelece o que sÃ£o Conceito, Ideia, Argumento, ProposiÃ§Ã£o, EvidÃªncia e Mensagem do ponto de vista filosÃ³fico, e como essas entidades se relacionam entre si.

A ontologia reflete uma filosofia epistemolÃ³gica onde nÃ£o existe distinÃ§Ã£o binÃ¡ria entre "fato" e "suposiÃ§Ã£o", mas sim proposiÃ§Ãµes com diferentes graus de solidez baseados em evidÃªncias. Para entender a base filosÃ³fica completa, consulte `core/docs/vision/epistemology.md`.

Outros documentos de arquitetura referenciam este documento como base para entender as entidades fundamentais do sistema.

### Fundamento Vetorial

Todas as entidades desta ontologia existem no **espaÃ§o vetorial compartilhado** do Motor Vetorial. Isso significa:

- Conceitos, Argumentos, Ideias e ProposiÃ§Ãµes sÃ£o vetorizados
- RelaÃ§Ãµes entre entidades sÃ£o calculadas via operaÃ§Ãµes vetoriais (similaridade, composiÃ§Ã£o)
- InferÃªncias sÃ£o feitas via cÃ¡lculos vetoriais, nÃ£o apenas via LLM
- O sistema opera em essÃªncias, nÃ£o em palavras

Para filosofia completa do Motor Vetorial, consulte `core/docs/vision/system_philosophy.md`.

---

## Espectro de AbstraÃ§Ã£o

As entidades da ontologia se distribuem em um espectro de abstraÃ§Ã£o:
```
MATERIAL (forma)                                    ESSENCIAL (espÃ­rito)
     â”‚                                                      â”‚
     â–¼                                                      â–¼
palavras â†’ contexto â†’ proposiÃ§Ãµes â†’ argumentos â†’ ideias â†’ conceitos
     â”‚                                                      â”‚
  especÃ­fico                                           universal
  temporal                                             atemporal
  idioma-dependente                                    idioma-agnÃ³stico
```

### ImplicaÃ§Ãµes

- **Conceitos** estÃ£o no extremo essencial: padrÃµes universais, atemporais
- **ProposiÃ§Ãµes** estÃ£o mais prÃ³ximas do material: unidades de texto especÃ­ficas
- **Argumentos** emergem de proposiÃ§Ãµes quando contextualizados
- **Ideias** sÃ£o conjuntos de argumentos, especÃ­ficas mas reutilizÃ¡veis
- **Mensagens** preparam ideias para materializaÃ§Ã£o em forma linguÃ­stica

O sistema busca operar no lado essencial sempre que possÃ­vel, descendo para o material apenas quando necessÃ¡rio (ex: produzir conteÃºdo final).

---

## Observador e CognitiveModel

### ResponsÃ¡vel pela AtualizaÃ§Ã£o

O **Observador (Mente AnalÃ­tica)** Ã© o agente responsÃ¡vel por monitorar conversa e atualizar o `CognitiveModel` a cada turno.

**Processo:**
1. UsuÃ¡rio envia mensagem
2. Orquestrador processa (decide next_step)
3. **Observador processa em paralelo** (silencioso):
   - Extrai claims emergentes
   - Identifica fundamentos
   - Detecta contradiÃ§Ãµes
   - Cataloga conceitos (ChromaDB + SQLite)
   - Identifica open_questions
   - Atualiza context (domÃ­nio, populaÃ§Ã£o, tecnologia)
   - Calcula mÃ©tricas (solidez, completude)
4. CognitiveModel atualizado

**Timing:** Todo turno, sempre (nÃ£o apenas snapshots).

**CaracterÃ­sticas:**
- âœ… Silencioso (nÃ£o interfere no fluxo)
- âœ… AutomÃ¡tico (nÃ£o precisa ser chamado)
- âœ… Completo (processa todos os turnos)
- âœ… ConsultÃ¡vel (Orquestrador pode pedir insights)

**MemÃ³ria e DegradaÃ§Ã£o:**
- CognitiveModel atual = mantido em memÃ³ria ativa (Observador)
- CognitiveModel histÃ³rico = armazenado em MemoryLayer.intermediÃ¡ria como snapshots
- CognitiveModel recente Ã© rapidamente acessÃ­vel, antigo requer consulta a Memory

### Estrutura do CognitiveModel

> **Nota:** Esta Ã© a estrutura do CognitiveModel em memÃ³ria (durante conversa).  
> Quando persistido, vira entidade `Argument` no banco de dados (ver seÃ§Ã£o "Argumento" abaixo).  
> 
> **RelaÃ§Ã£o entre `proposicoes` e `fundamentos`:**
> - `proposicoes` (CognitiveModel): Entidades de conhecimento (ProposiÃ§Ãµes) que podem sustentar o argumento
> - `fundamentos` (Argument): ProposiÃ§Ãµes no **papel** de sustentar o argumento (referÃªncias a ProposiÃ§Ãµes)
> - **EssÃªncia:** Fundamentos sÃ£o proposiÃ§Ãµes assumindo o papel de bases que sustentam um argumento. Uma mesma ProposiÃ§Ã£o pode ser fundamento de mÃºltiplos Argumentos.

```python
CognitiveModel:
  # AfirmaÃ§Ã£o central
  claim: str
  
  # ProposiÃ§Ãµes que sustentam o argumento (fundamentos)
  # Cada proposiÃ§Ã£o tem solidez variÃ¡vel (0-1)
  # Substitui distinÃ§Ã£o binÃ¡ria premise/assumption (Ã‰pico 11.4)
  proposicoes: list[Proposicao]  # {texto, solidez, evidencias}
  
  # InconsistÃªncias detectadas
  contradictions: list[Contradiction]  # {description, confidence, suggested_resolution}
  
  # Conceitos semÃ¢nticos (biblioteca global)
  conceitos: list[UUID]  # ReferÃªncias a Concept
  
  # Lacunas a investigar
  open_questions: list[str]
  
  # Contexto evolutivo
  context: dict  # {domain, population, technology}
  
  # EvidÃªncias bibliogrÃ¡ficas (futuro - Pesquisador)
  solid_grounds: list[SolidGround]  # {claim, evidence, source}
  
  # MÃ©tricas calculadas
  solidez_geral: float  # 0-1
  completude: float     # 0-1
```

**Proposicao:**
```python
class Proposicao:
    texto: str          # Enunciado da proposiÃ§Ã£o
    solidez: float|None # 0-1 (None = nÃ£o avaliada)
    evidencias: list    # IDs de evidÃªncias (futuro)
```

---

## Entidades Fundamentais

### Conceito (Abstrato, ReutilizÃ¡vel, Atemporal)

**O que Ã©:** NÃºcleo semÃ¢ntico abstrato que pode assumir diferentes formas linguÃ­sticas.

**Natureza:** Entidade **GLOBAL** (biblioteca Ãºnica, nÃ£o pertence a uma ideia especÃ­fica).

**Filosofia:**
- Conceitos sÃ£o **essÃªncias compartilhadas** entre mÃºltiplas ideias
- Uma ideia **referencia** conceitos, nÃ£o os **possui**
- Biblioteca cresce continuamente (conceitos de todas as conversas)
- DeduplicaÃ§Ã£o automÃ¡tica (threshold 0.80) garante catÃ¡logo limpo

**CaracterÃ­sticas:**
- Transcende palavras especÃ­ficas
- ReutilizÃ¡vel entre diferentes ideias
- Tem variaÃ§Ãµes linguÃ­sticas (produtividade, eficiÃªncia, performance = mesma essÃªncia)
- **Atemporal**: Conceitos existem independentemente de tempo, contexto ou usuÃ¡rio
- **NÃ£o possui solidez**: Conceitos sÃ£o rÃ³tulos semÃ¢nticos, nÃ£o afirmaÃ§Ãµes sobre o mundo
- **Origem flexÃ­vel**: Podem vir de usuÃ¡rio, literatura, mÃºltiplos usuÃ¡rios ou emergir do sistema

#### Biblioteca Global de Conceitos

**Natureza independente:**
- Conceitos existem independentemente de ideias
- Sistema mantÃ©m vocabulÃ¡rio compartilhado (dicionÃ¡rio universal)
- MÃºltiplas ideias referenciam o mesmo conceito da biblioteca global
- Conceito existe uma vez na biblioteca, usado por N ideias
- **Conceitos sÃ£o atemporais**: Existem independente de quem os usa ou quando foram criados
- **Conceitos nÃ£o tÃªm "solidez"**: SÃ£o rÃ³tulos semÃ¢nticos, nÃ£o afirmaÃ§Ãµes que podem ser verdadeiras ou falsas

**Exemplo:**
```
Ideia 1: "LLMs aumentam produtividade"
  â†’ referencia: [Concept: "LLMs", Concept: "Produtividade"]

Ideia 2: "Produtividade depende de mÃ©tricas claras"
  â†’ referencia: [Concept: "Produtividade", Concept: "MÃ©tricas"]

Biblioteca global:
  â€¢ LLMs (usado por: Ideia 1)
  â€¢ Produtividade (usado por: Ideia 1, Ideia 2)
  â€¢ MÃ©tricas (usado por: Ideia 2)
```

**Atualizado por:** Observador (a cada turno)

**Schema:**
```python
Concept:
  id: UUID
  label: str                    # "LLMs", "Produtividade"
  essence: str                  # DefiniÃ§Ã£o curta (opcional)
  variations: list[str]         # ["Language Models", "Large Language Models"]
  embedding: vector[384]        # ChromaDB (sentence-transformers)
  
  # Metadados
  created_at: datetime
  usage_count: int              # Quantas ideias usam este conceito
```

**Relacionamento N:N:**
```sql
idea_concepts:
  idea_id: UUID â†’ ideas(id)
  concept_id: UUID â†’ concepts(id)
```

**DeduplicaÃ§Ã£o:**
- Similaridade > 0.80: variation do conceito existente
- Similaridade < 0.80: conceito novo

#### PosiÃ§Ã£o no Espectro

Conceitos ocupam o extremo **essencial** do espectro:
- SÃ£o padrÃµes universais que transcendem idioma e Ã©poca
- Existem independentemente de quem os usa
- A mesma essÃªncia pode ter mÃºltiplas manifestaÃ§Ãµes linguÃ­sticas

Exemplo: O conceito "JustiÃ§a" pode se manifestar como:
- "justiÃ§a" (portuguÃªs)
- "dharma" (sÃ¢nscrito, em certo contexto)
- "harmonia" (chinÃªs, em certo contexto)

O sistema detecta essa convergÃªncia via similaridade vetorial.

**Exemplos de globalidade:**

Conceito "CooperaÃ§Ã£o" (global, Ãºnico na biblioteca):
- EssÃªncia: AÃ§Ã£o coordenada de mÃºltiplos agentes
- VariaÃ§Ãµes linguÃ­sticas: cooperaÃ§Ã£o, colaboraÃ§Ã£o, teamwork, coopÃ©ration (francÃªs)
- Referenciado por Ideia 1: "CooperaÃ§Ã£o via mitos" (Sapiens)
- Referenciado por Ideia 2: "CooperaÃ§Ã£o tribal" (Clastres)
- Referenciado por Ideia 3: "CooperaÃ§Ã£o cÃ­vica" (Putnam)

### Ideia (TerritÃ³rio, Contextual)

**O que Ã©:** Pensamento articulado que reÃºne conceitos e argumentos em contexto especÃ­fico.

**CaracterÃ­sticas:**
- Usa mÃºltiplos conceitos
- Pode ter mÃºltiplos argumentos (diferentes lentes)
- Evolui ao longo de conversa
- Contextual (nÃ£o necessariamente universal)

**Exemplos:**
- Ideia: "CooperaÃ§Ã£o humana via mitos compartilhados"
  - Conceitos usados: [CooperaÃ§Ã£o, FicÃ§Ã£o, Linguagem]
  - Argumentos: [ReligiÃ£o permite cooperaÃ§Ã£o, Nacionalismo permite cooperaÃ§Ã£o]

### ProposiÃ§Ã£o (Unidade Base de Conhecimento)

**O que Ã©:** AfirmaÃ§Ã£o sobre o mundo que pode ser sustentada ou refutada por evidÃªncias. Ã‰ a unidade base de conhecimento no sistema.

**Estrutura:**
```python
ProposiÃ§Ã£o:
  id: UUID
  texto: str                        # "Qualidade de cÃ³digo Ã© mensurÃ¡vel"
  solidez: Optional[float]          # 0-1, DERIVADO (nÃ£o definido manualmente)
                                    # None = proposiÃ§Ã£o ainda nÃ£o avaliada pelo sistema
  evidencias: list[EvidÃªncia]       # Lista de evidÃªncias (inicialmente vazia)
  usos: [ArgumentoRef]              # Onde Ã© usada como fundamento
```

**Solidez inicial:**
- ProposiÃ§Ãµes nascem com `solidez: None` (nÃ£o avaliada)
- Observador ou Orquestrador avaliam via LLM e atualizam para valor numÃ©rico (0-1)
- Pesquisador (futuro) adiciona evidÃªncias que recalculam solidez
- CÃ¡lculos de maturidade ignoram proposiÃ§Ãµes com `solidez=None`

**CaracterÃ­sticas fundamentais:**
- **NÃ£o existe "fato" vs "suposiÃ§Ã£o"**: Todas sÃ£o proposiÃ§Ãµes com diferentes graus de solidez
- **Solidez Ã© calculada**: Derivada automaticamente das evidÃªncias (quantidade, qualidade, fonte)
- **ReutilizÃ¡vel**: Uma proposiÃ§Ã£o pode ser usada como fundamento em mÃºltiplos argumentos
- **Evolutiva**: Solidez muda conforme novas evidÃªncias sÃ£o adicionadas

**Exemplos:**
- ProposiÃ§Ã£o: "Linguagem permite transmitir ficÃ§Ãµes"
  - Solidez: 0.85 (mÃºltiplas evidÃªncias de estudos linguÃ­sticos)
  - Usada em: Argumento sobre cooperaÃ§Ã£o via mitos
  
- ProposiÃ§Ã£o: "Qualidade de cÃ³digo Ã© mensurÃ¡vel"
  - Solidez: 0.60 (algumas evidÃªncias, mas debate metodolÃ³gico)
  - Usada em: Argumento sobre mÃ©tricas de produtividade

**Importante:** "Premissa" agora Ã© um **PAPEL**, nÃ£o um tipo. Premissa = proposiÃ§Ã£o sendo usada como fundamento de um argumento especÃ­fico. NÃ£o hÃ¡ mais distinÃ§Ã£o entre premise/assumption - apenas proposiÃ§Ãµes com solidez diferente.

#### ProposiÃ§Ã£o â†’ Argumento (TransformaÃ§Ã£o por Contexto)

Uma proposiÃ§Ã£o Ã© uma unidade de texto. Ela se torna **argumento** quando:
- Ã‰ usada para sustentar uma ideia especÃ­fica
- Recebe contexto e intenÃ§Ã£o
- Ã‰ selecionada para comunicaÃ§Ã£o

**Exemplo:**

ProposiÃ§Ã£o: "O sol nasce todo dia"
- Como texto: apenas uma afirmaÃ§Ã£o
- Como argumento (com contexto): sustenta a ideia de "constÃ¢ncia" ou "confiabilidade"

A mesma proposiÃ§Ã£o pode ser argumento em mÃºltiplas ideias, com papÃ©is diferentes.

#### PosiÃ§Ã£o no Espectro

ProposiÃ§Ãµes estÃ£o mais prÃ³ximas do lado **material**:
- SÃ£o unidades de texto especÃ­ficas
- Dependem de palavras e contexto linguÃ­stico
- Ao serem usadas como argumentos, movem-se para o lado essencial

**Relacionamento Bidirecional com Argumentos:**

Uma ProposiÃ§Ã£o pode:
- Ser usada como fundamento em mÃºltiplos Argumentos (role: fundamento)
- Ter mÃºltiplos Argumentos que a defendem (lentes diferentes)

**Exemplo:**
```python
ProposiÃ§Ã£o:
  enunciado: "Afastamento da natureza causa ansiedade"
  
  # Esta proposiÃ§Ã£o Ã© defendida por mÃºltiplas lentes:
  argumentos_que_defendem: [
    {id: "arg-cientifico", claim: "Estudos comprovam correlaÃ§Ã£o"},
    {id: "arg-vivencial", claim: "Relato pessoal de transformaÃ§Ã£o"},
    {id: "arg-evolutivo", claim: "Humanos evoluÃ­ram em natureza"}
  ]
  
  # Esta proposiÃ§Ã£o Ã© usada como fundamento em:
  usada_em_argumentos: [
    {id: "arg-principal", role: "fundamento"}
  ]
```

Cada argumento que defende a proposiÃ§Ã£o tem seu prÃ³prio vetor emocional. Sistema escolhe qual argumento usar baseado em similaridade com vetor da mensagem.

### EvidÃªncia (SustentaÃ§Ã£o de ProposiÃ§Ãµes)

**O que Ã©:** InformaÃ§Ã£o que apoia ou refuta uma proposiÃ§Ã£o.

**Estrutura:**
```python
EvidÃªncia:
  id: UUID
  descricao: str                    # "Estudo de Smith et al. (2023)"
  fonte: str                        # DOI, URL, referÃªncia
  forca: str                        # "forte", "moderada", "fraca"
  tipo: str                         # "estudo", "exemplo", "autoridade", "experiÃªncia"
  contexto: str                     # Em que contexto essa evidÃªncia se aplica
```

**CaracterÃ­sticas:**
- **Pode apoiar ou refutar**: Uma evidÃªncia pode fortalecer ou enfraquecer uma proposiÃ§Ã£o
- **ForÃ§a variÃ¡vel**: EvidÃªncias tÃªm diferentes graus de forÃ§a (forte, moderada, fraca)
- **Tipos diversos**: Estudos empÃ­ricos, exemplos, autoridade, experiÃªncia pessoal
- **Contexto importa**: EvidÃªncias sÃ£o vÃ¡lidas em contextos especÃ­ficos

**Exemplos:**
- EvidÃªncia (apoia): "Estudo de Smith et al. (2023) com 1000 desenvolvedores mostra correlaÃ§Ã£o entre TDD e reduÃ§Ã£o de bugs"
  - Tipo: estudo
  - ForÃ§a: forte
  - Fonte: DOI: 10.1234/example

- EvidÃªncia (refuta): "ExperiÃªncia pessoal: TDD aumentou tempo de desenvolvimento em 30%"
  - Tipo: experiÃªncia
  - ForÃ§a: fraca
  - Contexto: equipe pequena, projeto especÃ­fico

### Argumento (Lente, Estrutura LÃ³gica)

**O que Ã©:** Uma forma de ver/defender uma ideia atravÃ©s de estrutura lÃ³gica (claim + fundamentos).

**CaracterÃ­sticas:**
- Estrutura: claim â†’ fundamentos (proposiÃ§Ãµes) â†’ evidÃªncias
- MÃºltiplos argumentos podem defender mesma ideia (diferentes Ã¢ngulos)
- Argumento = mapa, Ideia = territÃ³rio
- **Fundamentos sÃ£o proposiÃ§Ãµes**: NÃ£o hÃ¡ mais distinÃ§Ã£o entre premises/assumptions

**Estrutura:**
```python
Argumento:
  id: UUID
  idea_id: UUID
  claim: str                        # AfirmaÃ§Ã£o principal (campo separado, nÃ£o Ã© proposiÃ§Ã£o)
  fundamentos: [ProposicaoRef]      # ProposiÃ§Ãµes que sustentam o argumento
  evidencias: [EvidenciaRef]        # EvidÃªncias diretas do argumento
  emocao_vetor: list[float]         # EmoÃ§Ãµes que este argumento desperta
                                    # MVP: {"empatia": 0.9, "confianca": 0.2}
                                    # VisÃ£o: [0.78, -0.23, 0.45, ...]
```

**Como vetor emocional Ã© usado:**
- Mensagem tem vetor emocional (intenÃ§Ã£o comunicativa)
- Argumento tem vetor emocional (emoÃ§Ãµes que desperta)
- Sistema calcula similaridade cosseno entre vetores
- Argumentos com alta similaridade â†’ selecionados para mensagem

**Exemplos:**
- Ideia: "Semana de 4 dias"
  - Argumento 1 (lente produtividade): 
    - Claim: "Aumenta produtividade via descanso"
    - Fundamentos: [ProposiÃ§Ã£o: "Descanso aumenta foco", ProposiÃ§Ã£o: "Foco aumenta produtividade"]
  - Argumento 2 (lente retenÃ§Ã£o):
    - Claim: "Reduz turnover em 20%"
    - Fundamentos: [ProposiÃ§Ã£o: "SatisfaÃ§Ã£o aumenta retenÃ§Ã£o"]

### Mensagem (CombinaÃ§Ã£o Intencional)

**O que Ã©:** SeleÃ§Ã£o intencional de proposiÃ§Ãµes/argumentos para transmitir ideia atravÃ©s de vetor emocional especÃ­fico.

**CaracterÃ­sticas:**
- Mensagem â‰  Forma (artigo, post, poema)
- Mensagem = O QUE comunicar + vetor emocional
- Forma = COMO expressar (vem depois)
- Mesma ideia â†’ mÃºltiplas mensagens (intenÃ§Ãµes diferentes)

**Estrutura:**
```python
Mensagem:
  id: UUID
  idea_id: UUID
  
  # NÃºcleo
  intencao: str                         # "Provocar questionamento sobre escolhas"
  emocao_vetor: list[float]             # Vetor no espaÃ§o latente (128-512 dims)
  
  # SeleÃ§Ã£o de componentes
  proposicoes_centrais: [ProposicaoRef]      # Alta aderÃªncia emocional
  proposicoes_perifericas: [ProposicaoRef]   # MÃ©dia aderÃªncia
  proposicoes_omitidas: [ProposicaoRef]      # Baixa aderÃªncia
  
  # CustomizaÃ§Ã£o
  argumentos_selecionados: [ArgumentoCustomizado]
```

**Grafo de RelevÃ¢ncia:**

Mensagem ilumina/apaga argumentos baseado em similaridade vetorial emocional:

```
    [ðŸ’¡ Ideia]
        |
    [ðŸ”µ ProposiÃ§Ã£o]
        |
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”
    |       |       |
[ðŸŸ¢ Arg] [âšª Arg] [ðŸŸ¡ Arg]
Alta sim  Baixa   MÃ©dia
(0.92)   (0.34)  (0.61)
```

**Vetor Emocional:**
- MVP: Categorias fixas ({"empatia": 0.8, "urgÃªncia": 0.5})
- VisÃ£o: EspaÃ§o latente sem rÃ³tulos ([0.23, -0.87, 0.45, ...])
- Sistema calcula similaridade (cosseno) entre vetor da mensagem e vetor de cada argumento

**CustomizaÃ§Ã£o de EvidÃªncias:**

Dentro de cada argumento selecionado, usuÃ¡rio pode escolher quais evidÃªncias incluir.

**Exemplos:**
- Mesma ideia "Cidades fazem mal" gera:
  - Mensagem A (despertar empatia) â†’ seleciona argumentos vivenciais
  - Mensagem B (despertar confianÃ§a) â†’ seleciona argumentos cientÃ­ficos

#### Onde Ã© Criada

Mensagem Ã© criada em **Camadas da Linguagem**:
- Input: Ideia (de Revelar ou Prisma Verbal)
- Processo: SeleÃ§Ã£o e organizaÃ§Ã£o de argumentos + definiÃ§Ã£o de intenÃ§Ã£o
- Output: Mensagem pronta para ExpressÃ£o

#### Para Onde Vai

Mensagem vai para **ExpressÃ£o** (ou especializaÃ§Ãµes como Produtor CientÃ­fico):
- ExpressÃ£o recebe Mensagem e dÃ¡ forma
- Forma pode ser: post, email, artigo, apresentaÃ§Ã£o

### MemoryLayer (Camada de MemÃ³ria)

**O que Ã©:** RepresentaÃ§Ã£o temporal da memÃ³ria de longo prazo. Inspirado na memÃ³ria humana, onde informaÃ§Ã£o recente Ã© mais acessÃ­vel que informaÃ§Ã£o antiga.

**CaracterÃ­sticas:**
- 3 tipos de camadas com diferentes caracterÃ­sticas de acesso
- DegradaÃ§Ã£o temporal natural: informaÃ§Ã£o mais antiga fica menos acessÃ­vel
- Permite busca eficiente priorizando recÃªncia sem perder histÃ³rico

**Estrutura:**
```python
MemoryLayer:
  id: UUID
  layer_type: str                   # "superficial" | "intermediÃ¡ria" | "profunda"
  turn_range: tuple[int, int]       # Intervalo de turnos cobertos (start, end)
  timestamp: datetime               # Quando foi criada
  accessibility: str                # Velocidade de busca: "rÃ¡pida" | "moderada" | "lenta"
  degradation_score: float          # QuÃ£o "fresca" estÃ¡ (1.0 = ontem, 0.1 = ano passado)
  
  # ConteÃºdo especÃ­fico por tipo
  content: dict                     # Varia conforme layer_type:
                                    # - superficial: {key_phrases, concepts, context_summary}
                                    # - intermediÃ¡ria: {cognitive_model_snapshot}
                                    # - profunda: {messages: [{role, content, timestamp}]}
```

**Tipos de Camada:**

**1. Superficial (recente):**
- Resumos condensados (key_phrases, concepts, context_summary)
- Busca rÃ¡pida, Ãºltimos dias/semanas
- Acesso imediato para contexto conversacional atual
- Exemplo: "Resumo: usuÃ¡rio explorando produtividade com LLMs, conceitos chave: [LLMs, Produtividade, MÃ©tricas]"

**2. IntermediÃ¡ria:**
- Snapshots de CognitiveModel (evoluÃ§Ã£o ao longo do tempo)
- Acesso moderado, Ãºtil para revisar progresso
- Captura estado do CognitiveModel em marcos importantes
- Exemplo: Snapshot do turno 50 mostrando CognitiveModel com claims consolidados e solidez calculada

**3. Profunda (antiga):**
- Mensagens literais brutas (user/assistant messages)
- Acesso mais lento, pode ser compactada periodicamente
- Arquivo histÃ³rico completo preservado

**RelaÃ§Ãµes:**
- MemoryLayer.superficial â†’ contÃ©m resumo de mÃºltiplos turnos
- MemoryLayer.intermediÃ¡ria â†’ contÃ©m snapshot de CognitiveModel
- MemoryLayer.profunda â†’ contÃ©m mensagens literais originais

**DegradaÃ§Ã£o temporal:**
- InformaÃ§Ã£o de ontem (degradation_score: 1.0) estÃ¡ mais acessÃ­vel que de mÃªs passado (0.5) ou ano passado (0.1)
- Sistema prioriza recÃªncia sem perder rastreabilidade completa
- Futuro: compactaÃ§Ã£o/arquivamento periÃ³dico (ex: anual) para manter performance

### BackstageContext (Contexto dos Bastidores)

**O que Ã©:** Rastreamento de decisÃµes e processamento interno do sistema. Captura transparÃªncia sobre como decisÃµes foram tomadas, alimentando a feature "Bastidores Transparentes".

**CaracterÃ­sticas:**
- Registra aÃ§Ãµes e raciocÃ­nio de todos os agentes
- Permite ao usuÃ¡rio entender origem de informaÃ§Ãµes e decisÃµes
- Funcionalidade opt-in (nÃ£o distrai por padrÃ£o, mas disponÃ­vel para transparÃªncia)

**Estrutura:**
```python
BackstageContext:
  id: UUID
  turn_id: UUID                     # Turno relacionado
  agent: str                        # Qual agente executou: "Observador" | "Orquestrador" | "Memory"
  action: str                       # O que foi feito:
                                    # - "detectou_incongruencia"
                                    # - "consultou_memory"
                                    # - "decidiu_next_step"
                                    # - "identificou_conceito"
                                    # - "atualizou_cognitive_model"
  input: dict                       # Contexto que levou Ã  aÃ§Ã£o
  output: dict                      # Resultado da aÃ§Ã£o
  reasoning: str                    # ExplicaÃ§Ã£o em linguagem natural (legÃ­vel para usuÃ¡rio)
  timestamp: datetime               # Quando ocorreu
```

**Exemplos de aÃ§Ãµes:**

**Observador:**
```python
BackstageContext(
  agent: "Observador",
  action: "detectou_incongruencia",
  input: {
    "turn_id": "abc123",
    "claim_atual": "LLMs aumentam produtividade",
    "claim_anterior": "AutomaÃ§Ã£o reduz qualidade"
  },
  output: {
    "incongruencia": "AfirmaÃ§Ã£o atual contradiz claim anterior sobre qualidade"
  },
  reasoning: "Sistema detectou possÃ­vel contradiÃ§Ã£o: usuÃ¡rio afirmou que automaÃ§Ã£o reduz qualidade, mas agora sugere que LLMs (tipo de automaÃ§Ã£o) aumentam produtividade. Isso pode indicar necessidade de clarificaÃ§Ã£o sobre o contexto especÃ­fico."
)
```

**Memory:**
```python
BackstageContext(
  agent: "Memory",
  action: "consultou_memory",
  input: {
    "query": "produtividade com LLMs",
    "turn_id": "xyz789"
  },
  output: {
    "results": [
      {"layer": "superficial", "matches": 3, "relevance": 0.85},
      {"layer": "intermediÃ¡ria", "matches": 1, "relevance": 0.72}
    ]
  },
  reasoning: "Buscou informaÃ§Ãµes sobre produtividade com LLMs. Encontrou 3 resumos recentes (Ãºltimas 2 semanas) e 1 snapshot de CognitiveModel de conversa anterior que abordou tema similar."
)
```

**Orquestrador:**
```python
BackstageContext(
  agent: "Orquestrador",
  action: "decidiu_next_step",
  input: {
    "cognitive_model": {"solidez": 0.45, "open_questions": 2},
    "user_intent": "quero entender mÃ©tricas"
  },
  output: {
    "decision": "chamar_metodologista",
    "justification": "Baixa solidez e questÃ£o sobre mÃ©tricas sugere necessidade de validaÃ§Ã£o metodolÃ³gica"
  },
  reasoning: "DecisÃ£o: acionar Metodologista para validar rigor cientÃ­fico. O CognitiveModel mostra solidez baixa (0.45) e usuÃ¡rio estÃ¡ questionando mÃ©tricas, indicando necessidade de fortalecimento metodolÃ³gico antes de prosseguir."
)
```

**RelaÃ§Ãµes:**
- BackstageContext â†’ rastreia decisÃµes de Observador
- BackstageContext â†’ rastreia consultas a Memory
- BackstageContext â†’ rastreia decisÃµes de Orquestrador

**Uso:**
- Alimenta feature "Bastidores Transparentes" (opt-in para usuÃ¡rio)
- Permite transparÃªncia sobre origem de informaÃ§Ãµes e raciocÃ­nio do sistema
- Formato legÃ­vel (nÃ£o JSON/tÃ©cnico por padrÃ£o) para melhor UX

---

## Fluxo de DetecÃ§Ã£o de Conceitos

### Pipeline (Observador)

```
UsuÃ¡rio: "LLMs aumentam produtividade"
    â†“
Observador: Processa turno
    â†“
1. LLM extrai conceitos: ["LLMs", "Produtividade"]
    â†“
2. Para cada conceito:
    â†“
   Gera embedding (sentence-transformers)
    â†“
   Busca similares no catÃ¡logo (ChromaDB)
    â†“
   Similaridade > 0.80?
     â”œâ”€ SIM â†’ Adiciona como variation
     â””â”€ NÃƒO â†’ Cria novo conceito
    â†“
   Salva metadados (SQLite)
    â†“
3. Atualiza CognitiveModel.conceitos
    â†“
4. Publica evento: ConceptsDetectedEvent
```

### Exemplo Completo

**Turno 1:**
```
Input: "LLMs aumentam produtividade"
Detecta: ["LLMs", "Produtividade"]
Salva ambos (conceitos novos)

Biblioteca:
â€¢ LLMs
â€¢ Produtividade
```

**Turno 3:**
```
Input: "Language models sÃ£o eficientes"
Detecta: ["Language models", "EficiÃªncia"]

"Language models" similar a "LLMs" (0.92)
â†’ Adiciona como variation de "LLMs"

"EficiÃªncia" similar a "Produtividade" (0.85)
â†’ Adiciona como variation de "Produtividade"

Biblioteca:
â€¢ LLMs (variations: ["Language models"])
â€¢ Produtividade (variations: ["EficiÃªncia"])
```

**Turno 5:**
```
Input: "Bugs afetam qualidade"
Detecta: ["Bugs", "Qualidade"]

Ambos novos (similaridade < 0.80)
â†’ Cria 2 novos conceitos

Biblioteca:
â€¢ LLMs (variations: ["Language models"])
â€¢ Produtividade (variations: ["EficiÃªncia"])
â€¢ Bugs
â€¢ Qualidade
```

---

## RelaÃ§Ãµes Entre Entidades

### Ideia â†” Conceito (N:N)
- **Relacionamento Ã© referÃªncia, nÃ£o posse**: Ideia referencia mÃºltiplos conceitos da biblioteca global
- Ideia nÃ£o possui conceitos, apenas referencia entidades globais existentes
- Mesmo conceito da biblioteca aparece em mÃºltiplas ideias (reutilizaÃ§Ã£o)
- Sistema detecta conceitos compartilhados via vetor semÃ¢ntico
- Conceito existe independentemente: mesmo que todas as ideias que o referenciam sejam removidas, o conceito permanece na biblioteca global

### Ideia â†” Argumento (1:N)
- Ideia pode ter mÃºltiplos argumentos (diferentes lentes)
- Argumento pertence a uma ideia

### Argumento â†” Conceito (N:N)
- Argumento usa conceitos nos fundamentos (proposiÃ§Ãµes contÃªm conceitos)

### Argumento â†” ProposiÃ§Ã£o (N:N)
- Argumento usa proposiÃ§Ãµes como fundamentos
- Uma proposiÃ§Ã£o pode ser usada em mÃºltiplos argumentos

### ProposiÃ§Ã£o â†” EvidÃªncia (N:N)
- ProposiÃ§Ã£o tem evidÃªncias que apoiam e evidÃªncias que refutam
- EvidÃªncia pode apoiar ou refutar mÃºltiplas proposiÃ§Ãµes

### Mensagem â†” Ideia (N:1)
- Uma Ideia pode gerar mÃºltiplas Mensagens (intenÃ§Ãµes diferentes)
- Mensagem referencia uma Ideia

### Mensagem â†” Argumento (N:N via seleÃ§Ã£o)
- Mensagem seleciona argumentos baseado em similaridade vetorial
- Mesmo argumento pode aparecer em mÃºltiplas mensagens

### ProposiÃ§Ã£o â†” Argumento (Bidirecional)
- **Role 1 (Fundamento):** ProposiÃ§Ã£o Ã© usada como fundamento em Argumentos
- **Role 2 (Defesa):** ProposiÃ§Ã£o Ã© defendida por mÃºltiplos Argumentos (lentes)

**Exemplo:**
```
ProposiÃ§Ã£o X: "Afastamento natureza causa ansiedade"
â”œâ”€ Usada como fundamento em: [Argumento Principal]
â””â”€ Defendida por: [Arg CientÃ­fico, Arg Vivencial, Arg Evolutivo]

Mensagem quer despertar empatia (vetor: [0.78, -0.23, ...])
â†’ Sistema calcula: Arg Vivencial tem vetor [0.76, -0.21, ...] (similaridade: 0.92)
â†’ Mensagem seleciona Arg Vivencial (nÃ£o os outros)
```

### CognitiveModel â†” MemoryLayer (1:N)
- CognitiveModel atual = mantido em memÃ³ria ativa (Observador)
- CognitiveModel histÃ³rico = armazenado em MemoryLayer.intermediÃ¡ria como snapshots
- MÃºltiplos snapshots de CognitiveModel podem existir ao longo do tempo

### MemoryLayer (Tipos de RelaÃ§Ã£o)
- MemoryLayer.superficial â†’ contÃ©m resumo de mÃºltiplos turnos
- MemoryLayer.intermediÃ¡ria â†’ contÃ©m snapshot de CognitiveModel
- MemoryLayer.profunda â†’ contÃ©m mensagens literais originais
- DegradaÃ§Ã£o temporal: superficial â†’ intermediÃ¡ria â†’ profunda

### BackstageContext (Rastreamento)
- BackstageContext â†’ rastreia decisÃµes de Observador
- BackstageContext â†’ rastreia consultas a Memory
- BackstageContext â†’ rastreia decisÃµes de Orquestrador
- BackstageContext â†’ vinculado a turn_id especÃ­fico

## Exemplo Completo: Sapiens (Harari)

**Texto original:**
"CooperaÃ§Ã£o humana em massa depende de mitos compartilhados. Dois catÃ³licos que nunca se encontraram podem embarcar juntos numa cruzada porque ambos acreditam que Deus encarnou num corpo humano."

**Sistema cristaliza:**

```python
Ideia: "CooperaÃ§Ã£o humana via mitos compartilhados"

Conceitos centrais:
- FicÃ§Ã£o/Mito (vetor semÃ¢ntico)
- CooperaÃ§Ã£o (vetor semÃ¢ntico)
- Linguagem (vetor semÃ¢ntico)

ProposiÃ§Ãµes:
- P1: "Linguagem permite transmitir ficÃ§Ãµes" (solidez: 0.85)
- P2: "Mitos compartilhados permitem cooperaÃ§Ã£o em massa" (solidez: 0.75)

EvidÃªncias:
- E1: "CatÃ³licos cooperam via crenÃ§a em Deus" (apoia P2, tipo: exemplo, forÃ§a: moderada)
- E2: "SÃ©rvios cooperam via crenÃ§a em naÃ§Ã£o" (apoia P2, tipo: exemplo, forÃ§a: moderada)
- E3: "Estudos linguÃ­sticos mostram capacidade de transmitir abstraÃ§Ãµes" (apoia P1, tipo: estudo, forÃ§a: forte)

Argumento principal:
claim: "CooperaÃ§Ã£o em massa depende de mitos compartilhados"
fundamentos: [P1, P2]  # ProposiÃ§Ãµes usadas como fundamentos
evidÃªncias: [E1, E2, E3]
```

## Hierarquia (Ideias dentro de Ideias)

Livros/textos complexos podem ter estrutura hierÃ¡rquica:

```
Ideia macro: "RevoluÃ§Ãµes que transformaram Sapiens"
â”œâ”€ Sub-ideia 1: "RevoluÃ§Ã£o Cognitiva"
â”‚   â””â”€ Ideia especÃ­fica: "CooperaÃ§Ã£o via mitos"
â”œâ”€ Sub-ideia 2: "RevoluÃ§Ã£o AgrÃ­cola"
â”‚   â””â”€ Ideia especÃ­fica: "Agricultura como armadilha"
```

Sistema identifica hierarquia automaticamente processando conteÃºdo.

---

## Observador e Snapshots

### Complementaridade

**Observador:** Processa TODOS os turnos (monitoramento contÃ­nuo)
**Snapshots:** Marcos importantes quando argumento amadurece

**Fluxo:**
```
Turno 1-5: Observador cataloga conceitos continuamente
    â†“
Turno 5: Argumento amadurece â†’ Snapshot criado
    â†“
Snapshot referencia conceitos catalogados pelo Observador
    â†“
Turno 6-10: Observador continua catalogando
    â†“
Turno 10: Novo snapshot â†’ referencia conceitos novos
```

**Vantagem:**
- Snapshots nÃ£o precisam reprocessar para detectar conceitos
- Conceitos jÃ¡ estÃ£o catalogados pelo Observador
- Snapshot apenas cria links (idea_concepts)

## Fluxo de MemÃ³ria em Camadas

### Ciclo de Vida da InformaÃ§Ã£o

**Fluxo temporal da informaÃ§Ã£o entre camadas:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TURNO ATUAL                                                 â”‚
â”‚                                                             â”‚
â”‚ UsuÃ¡rio: "LLMs aumentam produtividade"                     â”‚
â”‚     â†“                                                       â”‚
â”‚ Observador processa (em paralelo, silencioso)              â”‚
â”‚     â†“                                                       â”‚
â”‚ Atualiza CognitiveModel (memÃ³ria ativa)                    â”‚
â”‚     â†“                                                       â”‚
â”‚ Registra BackstageContext                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAMADA SUPERFICIAL (Ãºltimos dias/semanas)                  â”‚
â”‚                                                             â”‚
â”‚ â€¢ Resumos condensados (key_phrases, concepts)              â”‚
â”‚ â€¢ Busca rÃ¡pida para contexto conversacional                â”‚
â”‚ â€¢ DegradaÃ§Ã£o: 0.8-1.0 (informaÃ§Ã£o fresca)                  â”‚
â”‚                                                             â”‚
â”‚ Exemplo:                                                    â”‚
â”‚ {                                                           â”‚
â”‚   "key_phrases": ["LLMs", "produtividade", "mÃ©tricas"],    â”‚
â”‚   "concepts": [uuid1, uuid2],                              â”‚
â”‚   "context_summary": "Explorando impacto de LLMs..."       â”‚
â”‚ }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
              [PeriÃ³dico, a cada N turnos ou marcos]
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAMADA INTERMEDIÃRIA (semanas/meses)                       â”‚
â”‚                                                             â”‚
â”‚ â€¢ Snapshots de CognitiveModel                              â”‚
â”‚ â€¢ EvoluÃ§Ã£o da ideia ao longo do tempo                      â”‚
â”‚ â€¢ DegradaÃ§Ã£o: 0.3-0.7 (acesso moderado)                    â”‚
â”‚                                                             â”‚
â”‚ Exemplo:                                                    â”‚
â”‚ {                                                           â”‚
â”‚   "turn_id": 50,                                           â”‚
â”‚   "cognitive_model": {                                     â”‚
â”‚     "claims": ["LLMs aumentam produtividade em 30%"],     â”‚
â”‚     "solidez_geral": 0.65,                                 â”‚
â”‚     "conceitos": [uuid1, uuid2, uuid3]                     â”‚
â”‚   }                                                         â”‚
â”‚ }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
              [ApÃ³s perÃ­odo estendido ou compactaÃ§Ã£o]
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAMADA PROFUNDA (meses/anos)                               â”‚
â”‚                                                             â”‚
â”‚ â€¢ Mensagens literais brutas                                â”‚
â”‚ â€¢ Arquivo histÃ³rico completo                               â”‚
â”‚ â€¢ DegradaÃ§Ã£o: 0.1-0.3 (acesso lento)                       â”‚
â”‚                                                             â”‚
â”‚ Exemplo:                                                    â”‚
â”‚ {                                                           â”‚
â”‚   "messages": [                                            â”‚
â”‚     {"role": "user", "content": "LLMs aumentam...", ...}, â”‚
â”‚     {"role": "assistant", "content": "Interessante!...",...}â”‚
â”‚   ]                                                         â”‚
â”‚ }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
              [CompactaÃ§Ã£o/Arquivamento Anual]
                    â†“
         [InformaÃ§Ã£o preservada, acesso arquivado]
```

### Processo de DegradaÃ§Ã£o

**DegradaÃ§Ã£o temporal natural:**
1. **Turno atual â†’ Superficial:** InformaÃ§Ã£o imediatamente disponÃ­vel, busca instantÃ¢nea
2. **Superficial â†’ IntermediÃ¡ria:** ApÃ³s perÃ­odo (ex: 1-2 semanas), snapshot criado periodicamente
3. **IntermediÃ¡ria â†’ Profunda:** ApÃ³s perÃ­odo estendido (ex: 1-2 meses), mensagens literais arquivadas
4. **Profunda â†’ Compactada:** ApÃ³s perÃ­odo anual, pode ser compactada/arquivada

**DegradaÃ§Ã£o nÃ£o significa perda:**
- InformaÃ§Ã£o nunca Ã© perdida, apenas fica menos acessÃ­vel
- Sistema prioriza recÃªncia (busca superficial primeiro)
- Consulta camadas mais profundas apenas quando necessÃ¡rio
- Rastreabilidade completa mantida

### Consulta a Memory

**Quando sistema consulta memÃ³ria:**

```
UsuÃ¡rio pergunta sobre tÃ³pico abordado anteriormente
    â†“
Memory busca em camadas (ordem de prioridade):
    1. Superficial (rÃ¡pida) â†’ se encontrar relevante, retorna
    2. IntermediÃ¡ria (moderada) â†’ se necessÃ¡rio, busca snapshots
    3. Profunda (lenta) â†’ apenas se informaÃ§Ã£o especÃ­fica necessÃ¡ria
    â†“
Resultado agrega informaÃ§Ãµes de mÃºltiplas camadas
    â†“
BackstageContext registra consulta e resultados
```

**EficiÃªncia:**
- 90% das consultas resolvidas na camada superficial (acesso rÃ¡pido)
- 8% requerem camada intermediÃ¡ria (snapshots de CognitiveModel)
- 2% requerem camada profunda (mensagens literais especÃ­ficas)

---

## Rastreabilidade

### PropagaÃ§Ã£o de Solidez

Quando uma proposiÃ§Ã£o Ã© usada como fundamento em mÃºltiplos argumentos, sua solidez afeta todos eles:

- **Fragilidade se propaga**: Se uma proposiÃ§Ã£o base tem baixa solidez, todos os argumentos que dependem dela sÃ£o afetados
- **Fortalecimento se propaga**: Fortalecer uma proposiÃ§Ã£o fortalece todos os argumentos que dependem dela
- **Alertas automÃ¡ticos**: Sistema pode alertar: "3 argumentos dependem de proposiÃ§Ã£o com baixa solidez (0.35)"

**Exemplo:**
```
ProposiÃ§Ã£o P: "Qualidade de cÃ³digo Ã© mensurÃ¡vel" (solidez: 0.40)
  â””â”€ Usada em Argumento A1: "MÃ©tricas de qualidade validam TDD"
  â””â”€ Usada em Argumento A2: "Code review reduz bugs"
  â””â”€ Usada em Argumento A3: "Refactoring melhora manutenibilidade"

Sistema alerta: "3 argumentos dependem de proposiÃ§Ã£o com baixa solidez. 
Fortalecer P fortaleceria A1, A2 e A3."
```

### DependÃªncias ExplÃ­citas

O sistema mantÃ©m rastreabilidade clara de:
- Quais argumentos dependem de cada proposiÃ§Ã£o
- Quais proposiÃ§Ãµes sÃ£o fundamentais (usadas em muitos argumentos)
- Como fragilidades em proposiÃ§Ãµes base afetam a solidez geral do conhecimento

### EstratÃ©gia de Fortalecimento

Quando uma proposiÃ§Ã£o Ã© identificada como frÃ¡gil:
1. Sistema identifica todos os argumentos que dependem dela
2. Sugere buscar evidÃªncias para fortalecer a proposiÃ§Ã£o
3. Mostra impacto: "Fortalecer esta proposiÃ§Ã£o afetaria 5 argumentos"

## RelaÃ§Ã£o com Pipeline de Produtos

As entidades da ontologia fluem atravÃ©s do pipeline:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Revelar   â”‚     â”‚  Camadas da Linguagem   â”‚     â”‚ ExpressÃ£o â”‚
â”‚ Prisma Verb.â”‚     â”‚                         â”‚     â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                        â”‚                          â”‚
      â–¼                        â–¼                          â–¼
   IDEIAS               MENSAGENS                    CONTEÃšDO
 ARGUMENTOS          (seleÃ§Ã£o +                    (forma final)
 CONCEITOS            intenÃ§Ã£o)
```

### Onde Cada Entidade Ã© Criada/Usada

| Entidade | Criada em | Usada em |
|----------|-----------|----------|
| Conceito | Revelar, Prisma Verbal | Todos (biblioteca global) |
| ProposiÃ§Ã£o | Prisma Verbal | Camadas, ExpressÃ£o |
| Argumento | Revelar, Prisma Verbal | Camadas, ExpressÃ£o |
| Ideia | Revelar | Camadas |
| Mensagem | Camadas da Linguagem | ExpressÃ£o |
| ConteÃºdo | ExpressÃ£o | (usuÃ¡rio final) |

---

## ReferÃªncias

- `core/docs/vision/epistemology.md` - Fundamento filosÃ³fico da ontologia (proposiÃ§Ãµes, solidez, evidÃªncias)
- `concept_model.md` - Schema detalhado de Concept
- `idea_model.md` - Estrutura de dados tÃ©cnica de Ideia
- `argument_model.md` - Estrutura de dados tÃ©cnica de Argumento
- `message_model.md` - Estrutura de dados tÃ©cnica de Mensagem
- `core/docs/vision/communication_philosophy.md` - Base filosÃ³fica de Mensagem
- `core/docs/vision/cognitive_model/core.md` - Conceitos fundamentais (artefatos, solidez)
- `core/docs/vision/cognitive_model/evolution.md` - Como pensamento evolui e solidez Ã© calculada
- `core/docs/agents/observer.md` - DocumentaÃ§Ã£o completa do Observador
- `ROADMAP.md` - Ã‰picos 10, 12, 13 (Observador e Conceitos)
- `products/camadas-da-linguagem/docs/vision.md` - Produto que cria Mensagens
- `products/expressao/docs/vision.md` - Produto que dÃ¡ forma a Mensagens
- `products/produtor-cientifico/docs/vision.md` - EspecializaÃ§Ã£o para artigos

