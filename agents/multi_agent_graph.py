"""
Super-grafo multi-agente que integra Orquestrador, Estruturador e Metodologista.

Este m√≥dulo implementa o grafo principal do sistema Paper Agent, conectando
m√∫ltiplos agentes especializados em uma arquitetura de super-grafo.

Fluxo do sistema (√âpico 7 - Orquestrador Conversacional):
1. Orquestrador Conversacional: Analisa input + hist√≥rico e decide pr√≥ximo passo
   - next_step = "explore" ‚Üí Retorna para usu√°rio (END) - mais perguntas necess√°rias
   - next_step = "clarify" ‚Üí Retorna para usu√°rio (END) - esclarecer ambiguidade
   - next_step = "suggest_agent" ‚Üí Roteia para agente sugerido
2. Router 1: Decide destino baseado em next_step
   - "user" ‚Üí END (retorna para usu√°rio)
   - "structurer" ‚Üí Estruturador ‚Üí Metodologista
   - "methodologist" ‚Üí Metodologista direto
3. Estruturador (se chamado): Organiza ideia vaga em quest√£o estruturada
4. Metodologista (se chamado): Valida rigor cient√≠fico (3 status: approved, needs_refinement, rejected)
5. Router 2: Metodologista sempre retorna para Orquestrador (apresenta feedback ao usu√°rio)

"""

import logging
import time
import sqlite3
import threading
from pathlib import Path
from typing import Callable, Any, Optional, Dict, List
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
from langchain_core.runnables import RunnableConfig

from core.agents.orchestrator.state import MultiAgentState, create_initial_multi_agent_state
from core.agents.orchestrator.nodes import orchestrator_node
from core.agents.orchestrator.router import route_from_orchestrator
from core.agents.structurer.nodes import structurer_node
from core.agents.methodologist.nodes import decide_collaborative
from core.agents.memory.config_loader import load_all_agent_configs, ConfigLoadError

# Import EventBus para emitir eventos (√âpico 5.1)
try:
    from core.utils.event_bus import get_event_bus
    EVENT_BUS_AVAILABLE = True
except ImportError:
    EVENT_BUS_AVAILABLE = False

# Import Observer para processamento em background (√âpico 12.1)
try:
    from core.agents.observer.nodes import process_turn as observer_process_turn
    OBSERVER_AVAILABLE = True
except ImportError:
    OBSERVER_AVAILABLE = False

logger = logging.getLogger(__name__)

# Timeout para processamento do Observer em background (√âpico 12.1)
OBSERVER_TIMEOUT_SECONDS = 5.0

# === OBSERVER CALLBACK ASS√çNCRONO (√âpico 12.1) ===

def _create_observer_callback(state: MultiAgentState, result: Dict[str, Any]) -> None:
    """
    Executa Observer em background ap√≥s turno do Orquestrador (√âpico 12.1).

    Esta fun√ß√£o cria uma thread daemon que processa o turno atrav√©s do Observer,
    atualizando o cognitive_model no state sem bloquear a resposta ao usu√°rio.

    Comportamento:
    - Executa em thread separada (daemon=True para n√£o bloquear shutdown)
    - Timeout de OBSERVER_TIMEOUT_SECONDS (5s) para n√£o travar sistema
    - Publica evento cognitive_model_updated via EventBus
    - Falhas s√£o silenciosas (n√£o quebram fluxo principal)

    Args:
        state: Estado atual do sistema multi-agente (para extrair contexto)
        result: Resultado do orchestrator_node (cont√©m resposta atual)

    Notes:
        - Observer processa em paralelo, n√£o aumenta lat√™ncia do usu√°rio
        - cognitive_model √© atualizado no result dict (refer√™ncia compartilhada)
        - Eventos s√£o publicados para Timeline visual (√âpico 12.3)
    """
    if not OBSERVER_AVAILABLE:
        logger.debug("Observer n√£o dispon√≠vel. Pulando callback.")
        return

    # Extrair dados necess√°rios
    session_id = state.get("session_id", "unknown-session")
    user_input = state.get("user_input", "")
    turn_count = state.get("turn_count", 1)
    idea_id = state.get("idea_id")

    # Converter messages para formato do Observer (list of dicts)
    messages = state.get("messages", [])
    conversation_history: List[Dict[str, Any]] = []
    for msg in messages:
        if hasattr(msg, '__class__'):
            msg_type = msg.__class__.__name__
            role = "user" if msg_type == "HumanMessage" else "assistant"
            conversation_history.append({
                "role": role,
                "content": msg.content if hasattr(msg, 'content') else str(msg)
            })

    # Adicionar a resposta atual do orchestrator ao hist√≥rico
    orchestrator_message = result.get("messages", [])
    if orchestrator_message:
        for msg in orchestrator_message:
            conversation_history.append({
                "role": "assistant",
                "content": msg.content if hasattr(msg, 'content') else str(msg)
            })

    # Cognitive model anterior (se existir)
    previous_cognitive_model = state.get("cognitive_model")

    def _run_observer():
        """Thread interna que executa o Observer."""
        try:
            logger.info(f"üëÅÔ∏è Observer iniciando processamento em background (session: {session_id}, turno: {turn_count})")
            start_time = time.time()

            # Processar turno via Observer
            observer_result = observer_process_turn(
                user_input=user_input,
                conversation_history=conversation_history,
                previous_cognitive_model=previous_cognitive_model,
                session_id=session_id,
                turn_number=turn_count,
                idea_id=idea_id
            )

            processing_time = (time.time() - start_time) * 1000  # em ms

            # Extrair cognitive_model atualizado
            cognitive_model = observer_result.get("cognitive_model", {})
            metrics = observer_result.get("metrics", {})

            # Atualizar result com novo cognitive_model
            # NOTA: Isso funciona porque result √© passado por refer√™ncia
            # O state do LangGraph pode n√£o ser atualizado imediatamente,
            # mas o cognitive_model estar√° dispon√≠vel no pr√≥ximo turno
            result["cognitive_model"] = cognitive_model

            logger.info(
                f"üëÅÔ∏è Observer conclu√≠do em {processing_time:.0f}ms "
                f"(solidez: {metrics.get('solidez', 0):.0%}, "
                f"conceitos: {len(cognitive_model.get('concepts_detected', []))})"
            )

            # Publicar evento via EventBus (para Timeline - √âpico 12.3)
            if EVENT_BUS_AVAILABLE:
                try:
                    bus = get_event_bus()
                    bus.publish_cognitive_model_updated(
                        session_id=session_id,
                        turn_number=turn_count,
                        solidez=metrics.get("solidez", 0.0),
                        completude=metrics.get("completude", 0.0),
                        claims_count=1 if cognitive_model.get("claim") else 0,
                        proposicoes_count=len(cognitive_model.get("proposicoes", [])),
                        concepts_count=len(cognitive_model.get("concepts_detected", [])),
                        open_questions_count=len(cognitive_model.get("open_questions", [])),
                        contradictions_count=len(cognitive_model.get("contradictions", [])),
                        is_mature=metrics.get("solidez", 0.0) > 0.70,
                        metadata={
                            "processing_time_ms": processing_time,
                            "observer_version": "12.1"
                        }
                    )
                    logger.debug(f"üëÅÔ∏è Evento cognitive_model_updated publicado (session: {session_id})")
                except Exception as e:
                    logger.warning(f"Falha ao publicar evento Observer: {e}")

        except Exception as e:
            logger.error(f"‚ùå Erro ao executar Observer em background: {e}")
            # Silencioso: n√£o propaga erro para n√£o quebrar fluxo principal

    # Executar em thread separada (daemon = True para n√£o bloquear shutdown)
    thread = threading.Thread(target=_run_observer, daemon=True, name=f"observer-{session_id}-{turn_count}")
    thread.start()
    logger.debug(f"üëÅÔ∏è Observer thread iniciada (session: {session_id}, turno: {turn_count})")

# === INSTRUMENTA√á√ÉO COM EVENTBUS (√âpico 5.1) ===

def _get_session_id_from_config(config: Any) -> str:
    """
    Extrai session_id do config do LangGraph.

    Args:
        config: Configura√ß√£o do LangGraph

    Returns:
        str: Session ID ou fallback para thread_id
    """
    if not config:
        logger.debug("_get_session_id_from_config: config √© None/vazio")
        return "unknown-session"

    configurable = config.get("configurable", {})
    session_id = configurable.get("session_id")

    if session_id:
        logger.debug(f"_get_session_id_from_config: session_id extra√≠do = {session_id}")
        return session_id

    # Fallback: usar thread_id como session_id
    thread_id = configurable.get("thread_id", "unknown-session")
    logger.debug(f"_get_session_id_from_config: fallback para thread_id = {thread_id}")
    return thread_id

def instrument_node(node_func: Callable, agent_name: str) -> Callable:
    """
    Instrumenta um n√≥ do grafo para emitir eventos via EventBus (√âpico 5.1).

    Wrapper que:
    1. Emite evento agent_started antes da execu√ß√£o
    2. Executa o n√≥ original
    3. Emite evento agent_completed ap√≥s sucesso
    4. Emite evento agent_error em caso de falha

    Args:
        node_func (Callable): Fun√ß√£o do n√≥ original
        agent_name (str): Nome do agente (orchestrator, structurer, methodologist)

    Returns:
        Callable: N√≥ instrumentado

    Example:
        >>> instrumented_node = instrument_node(orchestrator_node, "orchestrator")
    """
    def wrapper(state: MultiAgentState, config: Optional[RunnableConfig] = None) -> MultiAgentState:
        """Wrapper instrumentado que emite eventos."""
        # Extrair session_id do state (m√©todo confi√°vel)
        # Config n√£o √© passado aos nodes pelo LangGraph, ent√£o usamos state
        session_id = state.get("session_id", "unknown-session")
        logger.debug(f"Wrapper {agent_name}: session_id do state = {session_id}")

        # Capturar tempo de in√≠cio (√âpico 8.3)
        start_time = time.time()

        # Emitir evento de in√≠cio
        if EVENT_BUS_AVAILABLE:
            try:
                bus = get_event_bus()
                bus.publish_agent_started(
                    session_id=session_id,
                    agent_name=agent_name,
                    metadata={
                        "stage": state.get("current_stage", "unknown"),
                        "reasoning": f"Iniciando processamento do agente {agent_name}"  # √âpico 8.1
                    }
                )
                logger.info(f"‚úÖ Evento agent_started publicado para {agent_name} (session: {session_id})")
            except Exception as e:
                logger.warning(f"Falha ao publicar agent_started para {agent_name}: {e}")

        # Executar n√≥ original (passando config para nodes que precisam - √âpico 6.2 MemoryManager)
        try:
            result = node_func(state, config)

            # Capturar tempo de fim e calcular dura√ß√£o (√âpico 8.3)
            end_time = time.time()
            duration = end_time - start_time

            # Emitir evento de conclus√£o
            if EVENT_BUS_AVAILABLE:
                try:
                    bus = get_event_bus()

                    # Extrair summary baseado no agente
                    summary = _extract_summary(agent_name, result)

                    # Extrair reasoning para metadata (√âpico 8.1)
                    reasoning = _extract_reasoning(agent_name, result)

                    # Extrair tokens e custo do state retornado pelo n√≥ (√âpico 8.3)
                    # IMPORTANTE: Config n√£o √© passado aos wrappers pelo LangGraph (ver linha 99)
                    # Solu√ß√£o: Cada n√≥ extrai seus tokens via token_extractor e retorna no state
                    tokens_input = result.get("last_agent_tokens_input", 0)
                    tokens_output = result.get("last_agent_tokens_output", 0)
                    tokens_total = tokens_input + tokens_output
                    cost = result.get("last_agent_cost", 0.0)

                    logger.debug(f"   Tokens extra√≠dos do state: input={tokens_input}, output={tokens_output}, total={tokens_total}, cost=${cost:.4f}")

                    bus.publish_agent_completed(
                        session_id=session_id,
                        agent_name=agent_name,
                        summary=summary,
                        tokens_input=tokens_input,
                        tokens_output=tokens_output,
                        tokens_total=tokens_total,
                        cost=cost,
                        duration=duration,
                        metadata={"reasoning": reasoning}  # √âpico 8.1: reasoning em metadata
                    )
                    logger.info(f"‚úÖ Evento agent_completed publicado para {agent_name} (session: {session_id})")
                    logger.debug(f"   Reasoning: {reasoning[:100]}...")
                    logger.debug(f"   M√©tricas: {tokens_total} tokens, ${cost:.4f}, {duration:.2f}s")
                except Exception as e:
                    logger.warning(f"Falha ao publicar agent_completed para {agent_name}: {e}")

            # √âpico 12.1: Disparar Observer em background ap√≥s Orchestrator
            # Observer processa turno de forma ass√≠ncrona, sem bloquear resposta
            if agent_name == "orchestrator" and OBSERVER_AVAILABLE:
                try:
                    _create_observer_callback(state, result)
                except Exception as e:
                    logger.warning(f"Falha ao criar callback do Observer: {e}")
                    # Silencioso: n√£o quebra fluxo se Observer falhar

            return result

        except Exception as error:
            # Capturar dura√ß√£o mesmo em caso de erro
            end_time = time.time()
            duration = end_time - start_time

            # Emitir evento de erro
            if EVENT_BUS_AVAILABLE:
                try:
                    bus = get_event_bus()
                    bus.publish_agent_error(
                        session_id=session_id,
                        agent_name=agent_name,
                        error_message=str(error),
                        error_type=type(error).__name__,
                        metadata={"duration": duration}
                    )
                except Exception as e:
                    logger.warning(f"Falha ao publicar agent_error para {agent_name}: {e}")

            # Re-lan√ßar exce√ß√£o original
            raise

    return wrapper

def _extract_summary(agent_name: str, state: MultiAgentState) -> str:
    """
    Extrai resumo da a√ß√£o do agente baseado no resultado.

    Args:
        agent_name (str): Nome do agente
        state (MultiAgentState): Estado ap√≥s execu√ß√£o

    Returns:
        str: Resumo curto da a√ß√£o
    """
    if agent_name == "orchestrator":
        # √âpico 7: Orquestrador conversacional (novos campos)
        next_step = state.get("next_step")
        if next_step:
            return f"Pr√≥ximo passo: {next_step}"
        return "Orquestrador processou"

    elif agent_name == "structurer":
        output = (state.get("structurer_output") or {})
        version = output.get("version", "unknown")
        return f"Estruturou quest√£o de pesquisa (V{version})"

    elif agent_name == "methodologist":
        output = (state.get("methodologist_output") or {})
        status = output.get("status", "unknown")
        return f"Decis√£o metodol√≥gica: {status}"

    else:
        return f"Executou {agent_name}"

def _extract_reasoning(agent_name: str, state: MultiAgentState) -> str:
    """
    Extrai reasoning detalhado da a√ß√£o do agente (√âpico 8.1).

    Este reasoning √© texto livre que explica o processo de pensamento do agente,
    permitindo transpar√™ncia completa do sistema para o usu√°rio.

    Args:
        agent_name (str): Nome do agente
        state (MultiAgentState): Estado ap√≥s execu√ß√£o

    Returns:
        str: Reasoning detalhado em texto livre
    """
    if agent_name == "orchestrator":
        # √âpico 7 MVP: Orquestrador conversacional tem analysis completo
        analysis = state.get("orchestrator_analysis", "")
        if analysis:
            return analysis
        # Fallback para compatibilidade
        return "An√°lise contextual do input do usu√°rio"

    elif agent_name == "structurer":
        # √âpico 8.1: Estruturador reasoning baseado em modo
        output = (state.get("structurer_output") or {})

        # Detectar modo: estrutura√ß√£o inicial ou refinamento
        methodologist_feedback = state.get('methodologist_output')
        is_refinement = (
            methodologist_feedback is not None and
            methodologist_feedback.get('status') == 'needs_refinement'
        )

        if is_refinement:
            # Modo refinamento
            version = output.get("version", 2)
            addressed_gaps = output.get("addressed_gaps", [])
            gaps_count = len(addressed_gaps)
            gaps_str = ", ".join(addressed_gaps) if addressed_gaps else "nenhum gap espec√≠fico"

            return (
                f"Refinando quest√£o para V{version}. "
                f"Endere√ßando {gaps_count} gap(s) do Metodologista: {gaps_str}. "
                f"Mantendo ess√™ncia da ideia original enquanto incorpora feedback cient√≠fico."
            )
        else:
            # Modo estrutura√ß√£o inicial
            elements = output.get("elements", {})
            context = elements.get("context", "N/A")[:50]
            problem = elements.get("problem", "N/A")[:50]
            contribution = elements.get("contribution", "N/A")[:50]

            return (
                f"Estruturando V1 com base em: "
                f"contexto ({context}...), "
                f"problema ({problem}...), "
                f"contribui√ß√£o potencial ({contribution}...)."
            )

    elif agent_name == "methodologist":
        # √âpico 8: Metodologista reasoning
        output = state.get("methodologist_output", {})
        status = output.get("status", "unknown")
        justification = output.get("justification", "")

        if justification:
            return f"Decis√£o: {status}. Justificativa: {justification}"
        else:
            return f"Valida√ß√£o metodol√≥gica resultou em: {status}"

    else:
        return f"Processamento do agente {agent_name}"

# SqliteSaver: Checkpointer persistente do LangGraph usando SQLite.
# Salva estado do grafo em banco de dados, permitindo:
# - Persist√™ncia entre reinicializa√ß√µes do servidor
# - Navega√ß√£o entre sess√µes passadas
# - Recupera√ß√£o de hist√≥rico completo de conversas
# MVP √âpico 9.10-9.11

# Garantir que diret√≥rio data/ existe
db_path = Path("data/checkpoints.db")
db_path.parent.mkdir(parents=True, exist_ok=True)

# Criar conex√£o SQLite (check_same_thread=False permite uso em threads m√∫ltiplas)
db_conn = sqlite3.connect(str(db_path), check_same_thread=False)

# Instanciar SqliteSaver com conex√£o
checkpointer = SqliteSaver(db_conn)

def route_after_methodologist(state: MultiAgentState) -> str:
    """
    Router que decide o fluxo ap√≥s o Metodologista processar a hip√≥tese.

    Comportamento (Refinamento Sob Demanda):
    - Sempre retorna para o Orquestrador ap√≥s o Metodologista
    - Orquestrador apresenta feedback e op√ß√µes ao usu√°rio
    - Usu√°rio decide se quer refinar, pesquisar, ou mudar de dire√ß√£o

    Args:
        state (MultiAgentState): Estado do sistema multi-agente.

    Returns:
        str: Sempre "orchestrator" (para negocia√ß√£o com usu√°rio)
    """
    methodologist_output = state.get('methodologist_output')
    if methodologist_output:
        status = methodologist_output.get('status')
        logger.info(f"Metodologista ‚Üí Orquestrador (status: {status})")
    else:
        logger.warning("methodologist_output n√£o encontrado. Retornando para Orquestrador.")
    
    return "orchestrator"

def create_multi_agent_graph():
    """
    Cria e compila o super-grafo multi-agente do sistema Paper Agent.

    Este grafo implementa o fluxo completo com loop de refinamento colaborativo (√âpico 4):

    Fluxo 1 - Ideia vaga + refinamento:
        START ‚Üí Orquestrador (classifica: "vague")
              ‚Üí Estruturador (gera V1)
              ‚Üí Metodologista (valida: "needs_refinement")
              ‚Üí Estruturador (gera V2 refinada)
              ‚Üí Metodologista (valida: "approved")
              ‚Üí END

    Fluxo 2 - Hip√≥tese ‚Üí Metodologista direto:
        START ‚Üí Orquestrador (classifica: "semi_formed" ou "complete")
              ‚Üí Metodologista (valida: "approved" ou "rejected")
              ‚Üí END

    Fluxo 3 - Refinamento sob demanda:
        ...  ‚Üí Metodologista (valida: "needs_refinement")
             ‚Üí Orquestrador (apresenta op√ß√µes ao usu√°rio)
             ‚Üí [usu√°rio decide pr√≥ximo passo]

    Estrutura do grafo (√âpico 4 - Refinamento Sob Demanda):
        - N√≥s:
            * orchestrator: Classifica maturidade do input e negocia com usu√°rio
            * structurer: Organiza/refina quest√µes (V1, V2, V3)
            * methodologist: Valida rigor (modo colaborativo)

        - Edges:
            * START ‚Üí orchestrator
            * orchestrator ‚Üí [router 1] ‚Üí structurer | methodologist
            * structurer ‚Üí methodologist
            * methodologist ‚Üí orchestrator (sempre - para negocia√ß√£o com usu√°rio)

        - State: MultiAgentState com hypothesis_versions (hist√≥rico de vers√µes)

    Registro de Mem√≥ria (√âpico 6.2):
        Para habilitar registro de tokens e custos, passe MemoryManager no config:

        >>> from core.agents.memory.memory_manager import MemoryManager
        >>> memory_manager = MemoryManager()
        >>> config = {
        ...     "configurable": {
        ...         "thread_id": "session-123",
        ...         "memory_manager": memory_manager  # Opcional (√âpico 6.2)
        ...     }
        ... }
        >>> result = graph.invoke(state, config=config)
        >>> totals = memory_manager.get_session_totals("session-123")
        >>> print(f"Total: {totals['total']} tokens")

    Returns:
        CompiledGraph: Super-grafo compilado pronto para execu√ß√£o via invoke()

    Example:
        >>> graph = create_multi_agent_graph()
        >>> state = create_initial_multi_agent_state("M√©todo X √© r√°pido")
        >>> result = graph.invoke(state, config={"configurable": {"thread_id": "1"}})
        >>> result['methodologist_output']['status']
        'approved'  # Ap√≥s 1-2 refinamentos
        >>> len(result['hypothesis_versions'])
        2  # V1 + V2
    """
    logger.info("=== CRIANDO SUPER-GRAFO MULTI-AGENTE COM LOOP DE REFINAMENTO ===")

    # Validar configura√ß√µes dos agentes (√âpico 6, Funcionalidade 6.1)
    logger.info("Validando configura√ß√µes dos agentes...")
    try:
        configs = load_all_agent_configs()
        required_agents = ["orchestrator", "structurer", "methodologist"]

        # Verificar que todos os agentes necess√°rios est√£o presentes
        for agent_name in required_agents:
            if agent_name not in configs:
                raise ConfigLoadError(
                    f"‚ö†Ô∏è Configura√ß√£o faltando para agente obrigat√≥rio: '{agent_name}'\n"
                    f"Esperado em: config/agents/{agent_name}.yaml"
                )

        logger.info(f"‚úÖ Configura√ß√µes validadas com sucesso para {len(configs)} agentes")
        logger.info(f"   Agentes configurados: {', '.join(configs.keys())}")

    except ConfigLoadError as e:
        logger.error(f"‚ùå ERRO ao carregar configura√ß√µes dos agentes: {e}")
        logger.warning("‚ö†Ô∏è ATEN√á√ÉO: Sistema continuar√° com fallback para prompts hard-coded")
        logger.warning("‚ö†Ô∏è Recomenda√ß√£o: Verifique os arquivos YAML em config/agents/")
        # N√£o levantar exce√ß√£o - permitir fallback para prompts hard-coded nos n√≥s

    # Criar o StateGraph com MultiAgentState
    graph = StateGraph(MultiAgentState)
    logger.info("StateGraph criado com MultiAgentState")

    # Adicionar n√≥s do sistema (√âpico 4 + 5.1 com instrumenta√ß√£o)
    # Instrumentar n√≥s para emitir eventos via EventBus (√âpico 5.1)
    graph.add_node("orchestrator", instrument_node(orchestrator_node, "orchestrator"))
    graph.add_node("structurer", instrument_node(structurer_node, "structurer"))
    graph.add_node("methodologist", instrument_node(decide_collaborative, "methodologist"))  # Modo colaborativo
    logger.info("N√≥s adicionados (instrumentados): orchestrator, structurer, methodologist")

    # Definir entry point
    graph.set_entry_point("orchestrator")
    logger.info("Entry point: orchestrator")

    # ROUTER 1: Orquestrador ‚Üí Estruturador | Metodologista | User
    # √âpico 7 POC: Orquestrador conversacional pode retornar "user" quando precisa explorar mais
    graph.add_conditional_edges(
        "orchestrator",
        route_from_orchestrator,
        {
            "structurer": "structurer",
            "methodologist": "methodologist",
            "user": END  # √âpico 7: Retornar para usu√°rio (mais perguntas necess√°rias)
        }
    )
    logger.info("Edge condicional: orchestrator ‚Üí [router1] ‚Üí structurer | methodologist | user (END)")

    # Estruturador ‚Üí Metodologista (sempre)
    graph.add_edge("structurer", "methodologist")
    logger.info("Edge fixo: structurer ‚Üí methodologist")

    # ROUTER 2: Metodologista ‚Üí Orquestrador (sempre - para negocia√ß√£o com usu√°rio)
    graph.add_conditional_edges(
        "methodologist",
        route_after_methodologist,
        {
            "orchestrator": "orchestrator"  # Sempre retorna para Orquestrador
        }
    )
    logger.info("Edge condicional: methodologist ‚Üí orchestrator (negocia√ß√£o com usu√°rio)")

    # Compilar o grafo com checkpointer
    compiled_graph = graph.compile(checkpointer=checkpointer)
    logger.info("Super-grafo compilado com SqliteSaver checkpointer (persistente)")

    logger.info("=== SUPER-GRAFO COM LOOP DE REFINAMENTO CRIADO COM SUCESSO ===")
    logger.info("")
    logger.info("Fluxos dispon√≠veis (√âpico 4 - Refinamento Sob Demanda):")
    logger.info("  1. Ideia vaga ‚Üí Orquestrador ‚Üí Estruturador (V1) ‚Üí Metodologista")
    logger.info("     ‚Üí Orquestrador (apresenta feedback) ‚Üí [usu√°rio decide pr√≥ximo passo]")
    logger.info("  2. Hip√≥tese ‚Üí Orquestrador ‚Üí Metodologista ‚Üí Orquestrador")
    logger.info("  3. Refinamento: controlado pelo usu√°rio (sem limite fixo)")
    logger.info("")

    return compiled_graph

# Exportar fun√ß√£o helper para criar estado inicial
__all__ = ['create_multi_agent_graph', 'create_initial_multi_agent_state']
