"""
N√≥s do grafo do agente Orquestrador.

Este m√≥dulo implementa o n√≥ principal do Orquestrador:
- orchestrator_node: Facilitador conversacional MVP com argumento focal expl√≠cito
- _build_context: Constr√≥i contexto incluindo outputs de agentes para curadoria

Vers√£o: 5.1 (√âpico 9.2 - active_idea_id via config)
Data: 05/12/2025
"""

import logging
import json
from typing import Optional, Dict, Any
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.runnables import RunnableConfig
from langchain_anthropic import ChatAnthropic
from pydantic import ValidationError

from .state import MultiAgentState
from utils.json_parser import extract_json_from_llm_response
from utils.config import get_anthropic_model, invoke_with_retry
from agents.memory.config_loader import get_agent_prompt, get_agent_model, ConfigLoadError
from agents.memory.execution_tracker import register_execution
from utils.token_extractor import extract_tokens_and_cost
from agents.models.cognitive_model import CognitiveModel

logger = logging.getLogger(__name__)


def _create_fallback_cognitive_model(state: MultiAgentState) -> Dict[str, Any]:
    """
    Cria cognitive_model de fallback quando LLM n√£o retorna ou retorna inv√°lido.

    Usa o user_input para criar um modelo m√≠nimo.

    Args:
        state: Estado atual do sistema

    Returns:
        Dict com cognitive_model m√≠nimo v√°lido
    """
    user_input = state.get("user_input", "")

    return {
        "claim": user_input[:200] if user_input else "",
        "premises": [],
        "assumptions": [],
        "open_questions": ["O que voc√™ quer explorar sobre isso?"],
        "contradictions": [],
        "solid_grounds": [],
        "context": {}
    }


def _validate_cognitive_model(
    cognitive_model_raw: Optional[Dict[str, Any]],
    state: MultiAgentState
) -> Dict[str, Any]:
    """
    Valida cognitive_model usando schema Pydantic e retorna dict v√°lido.

    Esta fun√ß√£o:
    1. Se cognitive_model_raw for None, cria fallback
    2. Valida contra schema CognitiveModel (Pydantic)
    3. Se valida√ß√£o falhar, loga erro e cria fallback
    4. Retorna dict (n√£o inst√¢ncia Pydantic) para compatibilidade com state

    Args:
        cognitive_model_raw: Dict extra√≠do do JSON do LLM (pode ser None)
        state: Estado atual do sistema (para criar fallback)

    Returns:
        Dict[str, Any]: cognitive_model validado como dict

    Example:
        >>> raw = {"claim": "LLMs aumentam produtividade", "premises": [], ...}
        >>> validated = _validate_cognitive_model(raw, state)
        >>> validated["claim"]
        'LLMs aumentam produtividade'
    """
    # Se n√£o veio cognitive_model, cria fallback
    if not cognitive_model_raw:
        logger.warning("cognitive_model n√£o fornecido pelo LLM. Usando fallback.")
        return _create_fallback_cognitive_model(state)

    # Tentar validar com Pydantic
    try:
        # Garantir que contradictions tenha estrutura correta
        # LLM pode retornar contradictions vazio como [] ou com items sem confidence
        contradictions = cognitive_model_raw.get("contradictions", [])
        validated_contradictions = []
        for c in contradictions:
            if isinstance(c, dict):
                # Garantir confidence >= 0.80 (regra do schema)
                confidence = c.get("confidence", 0.85)
                if confidence >= 0.80:
                    validated_contradictions.append({
                        "description": c.get("description", ""),
                        "confidence": confidence,
                        "suggested_resolution": c.get("suggested_resolution")
                    })

        # Construir dict para valida√ß√£o
        model_dict = {
            "claim": cognitive_model_raw.get("claim", ""),
            "premises": cognitive_model_raw.get("premises", []),
            "assumptions": cognitive_model_raw.get("assumptions", []),
            "open_questions": cognitive_model_raw.get("open_questions", []),
            "contradictions": validated_contradictions,
            "solid_grounds": cognitive_model_raw.get("solid_grounds", []),
            "context": cognitive_model_raw.get("context", {})
        }

        # Validar com Pydantic
        validated_model = CognitiveModel.model_validate(model_dict)
        logger.info(f"‚úÖ cognitive_model validado: claim={validated_model.claim[:50]}...")

        # Retornar como dict para compatibilidade com TypedDict state
        return validated_model.model_dump()

    except ValidationError as e:
        logger.error(f"‚ùå Falha na valida√ß√£o do cognitive_model: {e}")
        logger.warning("Usando cognitive_model fallback.")
        return _create_fallback_cognitive_model(state)
    except Exception as e:
        logger.error(f"‚ùå Erro inesperado ao validar cognitive_model: {e}")
        return _create_fallback_cognitive_model(state)


def _build_context(state: MultiAgentState) -> str:
    """
    Constr√≥i contexto completo para o Orquestrador, incluindo outputs de agentes.

    Esta fun√ß√£o helper constr√≥i o contexto que ser√° enviado ao LLM, incluindo:
    - Input inicial do usu√°rio
    - Hist√≥rico de mensagens da conversa
    - Outputs de agentes (para curadoria - √âpico 1.1)

    Quando structurer_output ou methodologist_output existem no state,
    o Orquestrador est√° em MODO CURADORIA e deve apresentar o resultado
    ao usu√°rio de forma coesa.

    Args:
        state (MultiAgentState): Estado atual do sistema multi-agente.

    Returns:
        str: Contexto formatado para an√°lise pelo LLM.
            Formato:
            ```
            INPUT INICIAL DO USU√ÅRIO:
            {user_input}

            HIST√ìRICO DA CONVERSA:
            [Usu√°rio]: {mensagem 1}
            [Assistente]: {resposta 1}
            ...

            RESULTADO DO ESTRUTURADOR (voc√™ deve fazer curadoria):
            {structurer_output em JSON}

            RESULTADO DO METODOLOGISTA (voc√™ deve fazer curadoria):
            {methodologist_output em JSON}
            ```

    Example:
        >>> state = create_initial_multi_agent_state("Observei X", "session-123")
        >>> context = _build_context(state)
        >>> "INPUT INICIAL DO USU√ÅRIO" in context
        True

        >>> # Com output de agente (modo curadoria)
        >>> state['structurer_output'] = {"research_question": "Como X impacta Y?"}
        >>> context = _build_context(state)
        >>> "RESULTADO DO ESTRUTURADOR" in context
        True

    Notes:
        - Se n√£o houver mensagens, retorna apenas o input inicial
        - Se houver outputs de agentes, Orquestrador deve fazer curadoria
        - Formato √© otimizado para an√°lise contextual pelo LLM
    """
    # Input inicial do usu√°rio
    context_parts = [
        "INPUT INICIAL DO USU√ÅRIO:",
        state["user_input"],
        ""  # linha em branco
    ]

    # Hist√≥rico de mensagens (se houver)
    messages = state.get("messages", [])
    if messages:
        context_parts.append("HIST√ìRICO DA CONVERSA:")

        for msg in messages:
            # Identificar tipo de mensagem
            if hasattr(msg, '__class__'):
                msg_type = msg.__class__.__name__
            else:
                msg_type = "Unknown"

            # Formatar conforme tipo
            if msg_type == "HumanMessage":
                context_parts.append(f"[Usu√°rio]: {msg.content}")
            elif msg_type == "AIMessage":
                context_parts.append(f"[Assistente]: {msg.content}")
            else:
                # Fallback para outros tipos de mensagem
                context_parts.append(f"[{msg_type}]: {msg.content}")

        context_parts.append("")  # linha em branco final

    # Output do Estruturador (se existir - √âpico 1.1 Curadoria)
    structurer_output = state.get("structurer_output")
    if structurer_output:
        context_parts.append("RESULTADO DO ESTRUTURADOR (voc√™ deve fazer curadoria):")
        context_parts.append(json.dumps(structurer_output, indent=2, ensure_ascii=False))
        context_parts.append("")

    # Output do Metodologista (se existir - √âpico 1.1 Curadoria)
    methodologist_output = state.get("methodologist_output")
    if methodologist_output:
        context_parts.append("RESULTADO DO METODOLOGISTA (voc√™ deve fazer curadoria):")
        context_parts.append(json.dumps(methodologist_output, indent=2, ensure_ascii=False))
        context_parts.append("")

    return "\n".join(context_parts)


def orchestrator_node(state: MultiAgentState, config: Optional[RunnableConfig] = None) -> dict:
    """
    N√≥ socr√°tico que facilita di√°logo provocativo com exposi√ß√£o de assumptions impl√≠citas.

    Este n√≥ √© o facilitador inteligente do sistema multi-agente (√âpico 7 MVP). Ele:
    1. Analisa input + hist√≥rico completo da conversa
    2. Extrai e atualiza ARGUMENTO FOCAL expl√≠cito a cada turno (7.8)
    3. Explora contexto atrav√©s de perguntas abertas
    4. Provoca REFLEX√ÉO sobre lacunas quando relevante (7.9)
    5. Detecta EMERG√äNCIA de novo est√°gio naturalmente (7.10)
    6. Sugere pr√≥ximos passos com justificativas claras
    7. Negocia com o usu√°rio antes de chamar agentes
    8. Detecta mudan√ßas de dire√ß√£o comparando focal_argument (7.8)
    9. Registra execu√ß√£o no MemoryManager (se configurado - √âpico 6.2)

    NOVIDADES MVP (√âpico 7.8-7.10):
    - focal_argument: Campo expl√≠cito extra√≠do a cada turno (intent, subject, population, metrics, article_type)
    - reflection_prompt: Provoca√ß√£o de reflex√£o quando lacuna clara detectada
    - stage_suggestion: Sugest√£o emergente quando est√°gio evolui (exploration ‚Üí hypothesis)

    Comportamento Conversacional:
    - "explore": Fazer perguntas abertas para entender contexto
    - "suggest_agent": Sugerir agente espec√≠fico com justificativa
    - "clarify": Esclarecer ambiguidade ou contradi√ß√£o detectada

    Args:
        state (MultiAgentState): Estado atual do sistema multi-agente.
        config (RunnableConfig, optional): Configura√ß√£o do LangGraph.
            Campos suportados em config["configurable"]:
            - memory_manager: MemoryManager para tracking de tokens (√âpico 6.2)
            - active_idea_id: UUID da ideia ativa para persist√™ncia (√âpico 9.2)

    Returns:
        dict: Dicion√°rio com updates incrementais do estado:
            - orchestrator_analysis: Racioc√≠nio detalhado sobre contexto e hist√≥rico
            - focal_argument: Argumento focal extra√≠do/atualizado (OBRIGAT√ìRIO)
            - cognitive_model: Modelo cognitivo do argumento (√âpico 9.1 - OBRIGAT√ìRIO)
            - next_step: Pr√≥xima a√ß√£o ("explore", "suggest_agent", "clarify")
            - agent_suggestion: Sugest√£o de agente com justificativa (se next_step="suggest_agent")
            - reflection_prompt: Provoca√ß√£o de reflex√£o (se lacuna detectada)
            - stage_suggestion: Sugest√£o de mudan√ßa de est√°gio (se evolu√ß√£o detectada)
            - messages: Mensagem conversacional adicionada ao hist√≥rico

    Example:
        >>> state = create_initial_multi_agent_state("Observei que LLMs aumentam produtividade", "session-1")
        >>> result = orchestrator_node(state)
        >>> result['focal_argument']['intent']
        'unclear'
        >>> result['focal_argument']['subject']
        'LLMs impact on productivity'
        >>> result['next_step']
        'explore'
    """
    logger.info("=== N√ì ORCHESTRATOR SOCR√ÅTICO: Iniciando an√°lise contextual (√âpico 10) ===")
    logger.info(f"Input do usu√°rio: {state['user_input']}")

    # Verificar se j√° existe argumento focal anterior (para detectar mudan√ßa de dire√ß√£o)
    previous_focal = state.get("focal_argument")
    if previous_focal:
        logger.info(f"Argumento focal anterior: intent={previous_focal.get('intent')}, subject={previous_focal.get('subject')}")

    # Usar prompt socr√°tico do √âpico 10
    from utils.prompts import ORCHESTRATOR_SOCRATIC_PROMPT_V1

    # Construir contexto completo (hist√≥rico + input atual)
    full_context = _build_context(state)
    logger.info("Contexto constru√≠do com hist√≥rico completo")
    logger.debug(f"Contexto:\n{full_context}")

    # Adicionar argumento focal anterior ao contexto (se existir)
    focal_context = ""
    if previous_focal:
        focal_context = f"""
ARGUMENTO FOCAL ANTERIOR:
{json.dumps(previous_focal, indent=2, ensure_ascii=False)}

(Compare com novo input para detectar mudan√ßa de dire√ß√£o)
"""

    # Construir prompt completo
    conversational_prompt = f"""{ORCHESTRATOR_SOCRATIC_PROMPT_V1}

CONTEXTO DA CONVERSA:
{full_context}
{focal_context}
Analise o contexto completo acima e responda APENAS com JSON estruturado conforme especificado."""

    # Chamar LLM para an√°lise conversacional
    # DECIS√ÉO: Tentar usar modelo mais potente para racioc√≠nio complexo (√âpico 7)
    # Fallback: Se n√£o dispon√≠vel, usa modelo do YAML (config/agents/orchestrator.yaml)
    # Raz√£o: An√°lise contextual complexa requer racioc√≠nio avan√ßado
    #        (detec√ß√£o de mudan√ßa de dire√ß√£o, reconstru√ß√£o de argumento focal)
    try:
        # Tentar carregar modelo do YAML primeiro (mais flex√≠vel)
        model_name = get_agent_model("orchestrator")
        logger.info(f"Usando modelo do YAML: {model_name}")
    except ConfigLoadError:
        # Fallback: modelo padr√£o Haiku (mais econ√¥mico e sempre dispon√≠vel)
        model_name = "claude-3-5-haiku-20241022"
        logger.warning(f"Config YAML n√£o dispon√≠vel. Usando fallback: {model_name}")

    llm = ChatAnthropic(model=model_name, temperature=0)
    messages = [HumanMessage(content=conversational_prompt)]
    response = invoke_with_retry(llm=llm, messages=messages, agent_name="orchestrator")

    logger.info(f"Resposta do LLM (primeiros 200 chars): {response.content[:200]}...")

    # Registrar execu√ß√£o no MemoryManager (√âpico 6.2)
    if config:
        memory_manager = config.get("configurable", {}).get("memory_manager")
        if memory_manager:
            # Extrair next_step antes de registrar (ser√° usada no summary)
            try:
                temp_data = extract_json_from_llm_response(response.content)
                temp_next_step = temp_data.get("next_step", "unknown")
            except:
                temp_next_step = "unknown"

            register_execution(
                memory_manager=memory_manager,
                config=config,
                agent_name="orchestrator",
                response=response,
                summary=f"Pr√≥ximo passo: {temp_next_step}",
                model_name=model_name,
                extra_metadata={
                    "next_step": temp_next_step,
                    "context_length": len(full_context)
                }
            )

    # Extrair active_idea_id do config (√âpico 9.2)
    # Usado pelo SnapshotManager para persist√™ncia (√âpico 9.3)
    active_idea_id = None
    if config:
        active_idea_id = config.get("configurable", {}).get("active_idea_id")
        if active_idea_id:
            logger.info(f"üìù Processando ideia: {active_idea_id[:8]}...")
        else:
            logger.debug("active_idea_id n√£o fornecido no config (opcional)")

    # Parse da resposta JSON
    try:
        orchestrator_response = extract_json_from_llm_response(response.content)

        reasoning = orchestrator_response.get("reasoning", "Racioc√≠nio n√£o fornecido")
        focal_argument = orchestrator_response.get("focal_argument")
        cognitive_model_raw = orchestrator_response.get("cognitive_model")
        next_step = orchestrator_response.get("next_step", "explore")
        message = orchestrator_response.get("message", "Entendi. Como posso ajudar?")
        agent_suggestion = orchestrator_response.get("agent_suggestion", None)
        reflection_prompt = orchestrator_response.get("reflection_prompt", None)
        stage_suggestion = orchestrator_response.get("stage_suggestion", None)

        # Validar e processar cognitive_model (√âpico 9.1 - OBRIGAT√ìRIO)
        cognitive_model_dict = _validate_cognitive_model(cognitive_model_raw, state)

        # Validar focal_argument (OBRIGAT√ìRIO no MVP)
        if not focal_argument:
            logger.error("ERRO: focal_argument √© obrigat√≥rio no MVP mas n√£o foi fornecido pelo LLM!")
            # Fallback: criar focal_argument m√≠nimo
            focal_argument = {
                "intent": "unclear",
                "subject": "not specified",
                "population": "not specified",
                "metrics": "not specified",
                "article_type": "unclear"
            }
            logger.warning(f"Usando focal_argument fallback: {focal_argument}")

        # Validar next_step
        valid_next_steps = ["explore", "suggest_agent", "clarify"]
        if next_step not in valid_next_steps:
            logger.warning(f"next_step inv√°lido '{next_step}'. Usando 'explore' como padr√£o.")
            next_step = "explore"

        # Validar consist√™ncia: se next_step="suggest_agent", agent_suggestion deve existir
        if next_step == "suggest_agent" and not agent_suggestion:
            logger.warning("next_step='suggest_agent' mas agent_suggestion √© None. Mudando para 'explore'.")
            next_step = "explore"
            message = "Preciso entender melhor o contexto. Me conta mais sobre sua ideia?"

        # Detectar mudan√ßa de dire√ß√£o (7.8)
        if previous_focal and focal_argument:
            prev_intent = previous_focal.get('intent')
            new_intent = focal_argument.get('intent')
            if prev_intent and new_intent and prev_intent != new_intent and prev_intent != 'unclear' and new_intent != 'unclear':
                logger.info(f"üîÑ MUDAN√áA DE DIRE√á√ÉO DETECTADA: {prev_intent} ‚Üí {new_intent}")

        # Logs MVP
        logger.info(f"Racioc√≠nio: {reasoning[:100]}...")
        logger.info(f"Argumento focal: intent={focal_argument.get('intent')}, subject={focal_argument.get('subject', 'N/A')[:50]}")
        logger.info(f"üß† Modelo cognitivo: claim={cognitive_model_dict.get('claim', 'N/A')[:50]}...")
        logger.info(f"Pr√≥ximo passo: {next_step}")
        logger.info(f"Mensagem ao usu√°rio: {message[:100]}...")
        if agent_suggestion:
            logger.info(f"Sugest√£o de agente: {agent_suggestion.get('agent', 'N/A')}")
        if reflection_prompt:
            logger.info(f"üí≠ Provoca√ß√£o de reflex√£o: {reflection_prompt[:80]}...")
        if stage_suggestion:
            logger.info(f"üéØ Sugest√£o de est√°gio: {stage_suggestion.get('from_stage')} ‚Üí {stage_suggestion.get('to_stage')}")

    except json.JSONDecodeError as e:
        logger.error(f"Falha ao parsear JSON do orquestrador: {e}")
        logger.error(f"Resposta recebida: {response.content[:300]}...")
        # Fallback seguro
        reasoning = "Erro ao processar resposta do orquestrador"
        focal_argument = {
            "intent": "unclear",
            "subject": "not specified",
            "population": "not specified",
            "metrics": "not specified",
            "article_type": "unclear"
        }
        cognitive_model_dict = _create_fallback_cognitive_model(state)
        next_step = "explore"
        message = "Desculpe, tive dificuldade em processar. Pode reformular sua ideia?"
        agent_suggestion = None
        reflection_prompt = None
        stage_suggestion = None

    # Extrair tokens e custo da resposta (√âpico 8.3)
    try:
        logger.debug(f"[TOKEN EXTRACTION] Tentando extrair tokens de response (tipo: {type(response)})")
        metrics = extract_tokens_and_cost(response, model_name)
        logger.debug(f"[TOKEN EXTRACTION] ‚úÖ M√©tricas extra√≠das: {metrics['tokens_total']} tokens, ${metrics['cost']:.6f}")
    except Exception as e:
        logger.error(f"[TOKEN EXTRACTION] ‚ùå Erro ao extrair tokens: {e}")
        import traceback
        traceback.print_exc()
        # Fallback: m√©tricas zeradas
        metrics = {"tokens_input": 0, "tokens_output": 0, "tokens_total": 0, "cost": 0.0}

    logger.info("=== N√ì ORCHESTRATOR SOCR√ÅTICO: Finalizado ===\n")

    # Criar AIMessage com a mensagem conversacional para hist√≥rico
    ai_message = AIMessage(content=message)

    return {
        "orchestrator_analysis": reasoning,
        "focal_argument": focal_argument,
        "cognitive_model": cognitive_model_dict,
        "next_step": next_step,
        "agent_suggestion": agent_suggestion,
        "reflection_prompt": reflection_prompt,
        "stage_suggestion": stage_suggestion,
        "last_agent_tokens_input": metrics["tokens_input"],
        "last_agent_tokens_output": metrics["tokens_output"],
        "last_agent_cost": metrics["cost"],
        "messages": [ai_message]
    }
