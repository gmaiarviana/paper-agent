# Statement do Problema: Agente de Mem√≥ria para Otimiza√ß√£o de Contexto

**Data:** 2025-01-27  
**Contexto:** Otimiza√ß√£o de uso de tokens atrav√©s de sele√ß√£o inteligente de contexto  
**Status:** Proposta arquitetural para discuss√£o

---

## üéØ Problema Atual

### Situa√ß√£o

O Orquestrador envia **TODO o hist√≥rico de mensagens** a cada turno para o LLM:

```python
# agents/orchestrator/nodes.py:600-620
def _build_context(state: MultiAgentState) -> str:
    messages = state.get("messages", [])
    if messages:
        context_parts.append("HIST√ìRICO DA CONVERSA:")
        for msg in messages:  # ‚ùå TODAS as mensagens, sem limite
            context_parts.append(f"[Usu√°rio]: {msg.content}")
```

### Impacto

- **Conversas longas (>10 turnos):** ~10k tokens de hist√≥rico repetido a cada chamada
- **Custo exponencial:** 20 turnos = 200k tokens de hist√≥rico acumulado
- **Dilema:**
  - ‚ùå Truncar tudo = risco de perder detalhes importantes
  - ‚ùå Manter tudo = custo proibitivo

### Infraestrutura Existente

**J√° temos:**
- ‚úÖ **Observer:** Extrai sem√¢ntica (claims, conceitos, proposi√ß√µes)
- ‚úÖ **Cognitive Model:** Representa√ß√£o condensada do argumento (j√° limitado: 5 proposi√ß√µes, 10 conceitos)
- ‚úÖ **focal_argument:** Resumo estruturado (intent, subject, population, metrics)
- ‚úÖ **Embeddings:** Observer j√° extrai conceitos (pode usar para busca sem√¢ntica)

**N√£o temos:**
- ‚ùå Sele√ß√£o inteligente de mensagens relevantes
- ‚ùå Agente dedicado para gerenciar mem√≥ria/contexto
- ‚ùå Mecanismo para recuperar mensagens antigas por relev√¢ncia sem√¢ntica

---

## üí° Proposta: Agente de Mem√≥ria Dedicado

### Arquitetura Proposta

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Orquestrador‚îÇ ‚îÄ‚îÄ> "Preciso contexto para responder ao usu√°rio"
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Memory Agent‚îÇ ‚îÄ‚îÄ> Seleciona contexto relevante
‚îÇ             ‚îÇ     1. Analisa user_input atual
‚îÇ             ‚îÇ     2. Identifica conceitos-chave (via Observer)
‚îÇ             ‚îÇ     3. Busca mensagens relevantes (sem√¢ntica + temporal)
‚îÇ             ‚îÇ     4. Retorna contexto otimizado
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Contexto  ‚îÇ ‚îÄ‚îÄ> Apenas mensagens relevantes
‚îÇ  Selecionado‚îÇ     + Cognitive Model (j√° condensado)
‚îÇ             ‚îÇ     + focal_argument (resumo estruturado)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Responsabilidades do Memory Agent

1. **Sele√ß√£o Temporal:**
   - √öltimas N mensagens (sempre recente)
   - Mensagens antigas apenas se relevantes

2. **Sele√ß√£o Sem√¢ntica:**
   - Usar conceitos do Cognitive Model
   - Buscar mensagens por similaridade (embeddings)
   - Priorizar mensagens que mencionam conceitos-chave

3. **Resumo Incremental:**
   - A cada 10 turnos, resumir mensagens antigas
   - Manter resumo + √∫ltimas N mensagens completas

4. **Preserva√ß√£o de Detalhes:**
   - Mensagens que definem conceitos importantes (n√£o perder)
   - Mensagens que estabelecem contexto (popula√ß√£o, m√©tricas)
   - Mensagens que resolvem contradi√ß√µes

### Interface Proposta

```python
class MemoryAgent:
    def select_context(
        self,
        user_input: str,
        all_messages: List[Message],
        cognitive_model: Dict[str, Any],
        focal_argument: Dict[str, Any],
        max_tokens: int = 4000
    ) -> Dict[str, Any]:
        """
        Seleciona contexto relevante para o Orquestrador.
        
        Returns:
            {
                "recent_messages": List[Message],  # √öltimas 10
                "relevant_old_messages": List[Message],  # Por sem√¢ntica
                "summary_old_messages": str,  # Resumo de mensagens antigas
                "cognitive_model_snapshot": Dict,  # J√° limitado
                "focal_argument": Dict,  # Resumo estruturado
                "selection_reasoning": str  # Por que selecionou essas mensagens
            }
        """
```

---

## ‚öñÔ∏è Trade-offs

### Pr√≥s

‚úÖ **Sele√ß√£o Contextual Inteligente**
- N√£o perde detalhes importantes
- Remove ru√≠do de mensagens irrelevantes
- Escal√°vel para conversas muito longas

‚úÖ **Economia de Tokens**
- Envia apenas o necess√°rio
- Reduz custo exponencialmente em conversas longas
- Mant√©m qualidade (n√£o perde contexto relevante)

‚úÖ **Separa√ß√£o de Responsabilidades**
- Memory Agent = gerenciar contexto
- Orchestrator = facilitar conversa
- Observer = extrair sem√¢ntica

### Contras

‚ùå **Complexidade Adicional**
- Novo agente para manter
- Nova interface para testar
- Mais pontos de falha

‚ùå **Custo de Sele√ß√£o**
- Se usar LLM para sele√ß√£o: custo adicional
- Se usar embeddings: lat√™ncia adicional
- Trade-off: custo de sele√ß√£o vs economia de tokens

‚ùå **Risco de Sele√ß√£o Errada**
- Pode omitir mensagem importante
- Pode incluir mensagem irrelevante
- Requer valida√ß√£o/testes extensivos

---

## üîç Quest√µes para Decis√£o

### 1. M√©todo de Sele√ß√£o

**Op√ß√£o A: LLM-based (mais inteligente, mais caro)**
- LLM analisa user_input e seleciona mensagens relevantes
- Custo: ~500-1000 tokens por sele√ß√£o
- Vantagem: Entende contexto sem√¢ntico profundo

**Op√ß√£o B: Embedding-based (mais r√°pido, menos inteligente)**
- Busca por similaridade de embeddings
- Custo: ~100 tokens (apenas busca)
- Vantagem: R√°pido e barato

**Op√ß√£o C: H√≠brida**
- Embeddings para pr√©-sele√ß√£o
- LLM para valida√ß√£o/refinamento
- Custo: ~300-500 tokens

### 2. Quando Selecionar

**Op√ß√£o A: Sempre (todo turno)**
- M√°xima otimiza√ß√£o
- Custo de sele√ß√£o em todo turno

**Op√ß√£o B: Condicional (apenas se >N mensagens)**
- Sele√ß√£o apenas quando necess√°rio
- Exemplo: Se >15 mensagens, ent√£o seleciona

**Op√ß√£o C: Incremental (a cada N turnos)**
- Resumo a cada 10 turnos
- Sele√ß√£o apenas quando hist√≥rico cresce muito

### 3. Integra√ß√£o com Observer

**Op√ß√£o A: Memory Agent independente**
- N√£o depende do Observer
- Pode usar Observer como fonte de conceitos

**Op√ß√£o B: Memory Agent como extens√£o do Observer**
- Observer j√° tem sem√¢ntica
- Memory Agent usa Cognitive Model do Observer

**Op√ß√£o C: Observer como Memory Agent**
- Observer assume responsabilidade de sele√ß√£o
- Menos separa√ß√£o de responsabilidades

---

## üìä Estimativa de Impacto

### Cen√°rio: Conversa de 20 turnos

**Atual (sem sele√ß√£o):**
- Input: ~15k tokens/turno (hist√≥rico completo)
- 20 turnos = 300k tokens de input
- Custo: $0.24 (Haiku)

**Com Memory Agent (sele√ß√£o inteligente):**
- Input: ~8k tokens/turno (contexto selecionado)
- 20 turnos = 160k tokens de input
- Custo de sele√ß√£o: ~200 tokens √ó 20 = 4k tokens (se embedding-based)
- **Total: 164k tokens = $0.13**
- **Economia: ~45%**

**Com Memory Agent (LLM-based):**
- Custo de sele√ß√£o: ~800 tokens √ó 20 = 16k tokens
- **Total: 176k tokens = $0.14**
- **Economia: ~42%**

---

## üéØ Recomenda√ß√£o Inicial

### Fase 1: MVP Simples (sem novo agente)

1. **Truncamento inteligente b√°sico:**
   - √öltimas 10 mensagens (sempre)
   - Cognitive Model (j√° condensado)
   - focal_argument (resumo estruturado)

2. **Avaliar impacto:**
   - Medir economia real
   - Validar que n√£o perde contexto cr√≠tico

### Fase 2: Memory Agent (se necess√°rio)

Se Fase 1 n√£o for suficiente:

1. **Memory Agent com embeddings:**
   - Busca sem√¢ntica por conceitos
   - Custo baixo (~100 tokens)
   - Implementa√ß√£o simples

2. **Avaliar necessidade de LLM:**
   - Se embeddings n√£o forem suficientes
   - Adicionar LLM para refinamento

---

## ‚ùì Quest√µes para Discuss√£o

1. **Vale a pena a complexidade?**
   - Truncamento simples resolve 80% do problema?
   - Memory Agent resolve os 20% restantes?

2. **Qual m√©todo de sele√ß√£o?**
   - Embeddings s√£o suficientes?
   - LLM √© necess√°rio para qualidade?

3. **Quando implementar?**
   - Agora (otimiza√ß√£o cr√≠tica)?
   - Depois (ap√≥s validar truncamento simples)?

4. **Como validar?**
   - M√©tricas de qualidade (n√£o perder contexto)?
   - M√©tricas de economia (tokens reduzidos)?

---

## üìö Refer√™ncias

- Arquitetura atual: `agents/orchestrator/nodes.py:_build_context()`
- Observer: `agents/observer/` (j√° extrai sem√¢ntica)
- Cognitive Model: `agents/models/cognitive_model.py`
- An√°lise de tokens: `docs/analysis/token_cost_optimization.md`

