# Ã‰pico 12: Observer - IntegraÃ§Ã£o BÃ¡sica (MVP)

## Contexto

O Observer jÃ¡ estÃ¡ implementado em `agents/observer/` mas nÃ£o integrado ao fluxo principal. Este Ã©pico integra o Observer ao multi-agent graph de forma que processe cada turno automaticamente em background, enriquecendo o Orquestrador com cognitive_model sem adicionar latÃªncia perceptÃ­vel.

## DecisÃµes TÃ©cnicas (Spikes 2025-12-08)

### Spike 1: Paralelismo LangGraph
**Resultado:** âŒ NÃƒO suportado
- `add_edge(START, ["orchestrator", "observer"])` falhou
- Erro: `unhashable type: 'list'`
- **DecisÃ£o:** Usar callback assÃ­ncrono (threading)

### Spike 2: CognitiveModel via Prompt
**Resultado:** âœ… VIÃVEL (80% score)
- Claude usa cognitive_model naturalmente via prompt
- Mencionou: solidez, completude, contradiÃ§Ãµes, conceitos
- **DecisÃ£o:** Leitura de estado Ã© SUFICIENTE (sem tool explÃ­cita)

## Arquitetura

### Fluxo Proposto
```
User input
â†“
[Orchestrator] â†’ Response (3s, latÃªncia principal)
â†“
[Observer callback] â†’ Background thread (2s, assÃ­ncrono)
â†“
Atualiza state["cognitive_model"]
â†“
Publica CognitiveModelUpdatedEvent
```

### Componentes Afetados

1. **`agents/multi_agent_graph.py`:**
   - Adicionar Observer como nÃ³
   - Implementar callback assÃ­ncrono via modificaÃ§Ã£o do `instrument_node` para orchestrator

2. **`agents/orchestrator/nodes.py`:**
   - Prompt atualizado para mencionar cognitive_model disponÃ­vel
   - Claude analisa cognitive_model naturalmente no reasoning

3. **`agents/observer/nodes.py`:**
   - JÃ¡ implementado, sem mudanÃ§as necessÃ¡rias
   - FunÃ§Ã£o `process_turn()` pronta para uso

4. **`app/components/backstage/timeline.py`:**
   - Adicionar indicador visual quando Observer processar turno
   - Consome evento `cognitive_model_updated` do EventBus

## Entregas

### 12.1: Callback AssÃ­ncrono Observer

**Objetivo:** Observer roda automaticamente apÃ³s cada turno do Orquestrador (background)

**ImplementaÃ§Ã£o:**
```python
# agents/multi_agent_graph.py

import threading
from agents.observer.nodes import process_turn
from utils.event_bus import get_event_bus

def _create_observer_callback(state: MultiAgentState) -> None:
    """Executa Observer em background apÃ³s turno do Orquestrador"""
    def _run_observer():
        try:
            # Extrair dados necessÃ¡rios do state
            user_input = state.get("user_input", "")
            conversation_history = state.get("conversation_history", [])
            previous_cognitive_model = state.get("cognitive_model")
            session_id = state.get("session_id", "unknown-session")
            turn_number = state.get("turn_count", 1)
            
            # Processar turno via Observer
            result = process_turn(
                user_input=user_input,
                conversation_history=conversation_history,
                previous_cognitive_model=previous_cognitive_model,
                session_id=session_id,
                turn_number=turn_number,
                idea_id=state.get("idea_id")  # Opcional
            )
            
            # Atualizar estado (thread-safe via lock ou state manager)
            # NOTA: LangGraph state pode ser thread-safe dependendo do checkpoint
            # Para MVP, usar acesso direto ao state (testar comportamento)
            cognitive_model = result.get("cognitive_model", {})
            state["cognitive_model"] = cognitive_model
            
            # Publicar evento via EventBus
            try:
                bus = get_event_bus()
                bus.publish_cognitive_model_updated(
                    session_id=session_id,
                    turn_number=turn_number,
                    solidez=cognitive_model.get("overall_solidez", 0.0),
                    completude=cognitive_model.get("overall_completude", 0.0),
                    claims_count=1 if cognitive_model.get("claim") else 0,
                    proposicoes_count=len(cognitive_model.get("proposicoes", [])),
                    concepts_count=len(cognitive_model.get("concepts_detected", [])),
                    open_questions_count=len(cognitive_model.get("open_questions", [])),
                    contradictions_count=len(cognitive_model.get("contradictions", [])),
                    is_mature=cognitive_model.get("overall_solidez", 0.0) > 0.70,
                    metadata={
                        "processing_time_ms": result.get("processing_time_ms", 0),
                        "observer_version": "1.0"
                    }
                )
            except Exception as e:
                logger.warning(f"Falha ao publicar evento Observer: {e}")
                
        except Exception as e:
            logger.error(f"Erro ao executar Observer em background: {e}")
    
    # Executar em thread separada (daemon = True para nÃ£o bloquear shutdown)
    thread = threading.Thread(target=_run_observer, daemon=True)
    thread.start()
    logger.debug(f"Observer iniciado em background thread (session: {session_id})")

# Modificar instrument_node para adicionar callback apÃ³s orchestrator
def instrument_node(node_func: Callable, agent_name: str) -> Callable:
    """Wrapper existente modificado para incluir Observer callback"""
    def wrapper(state: MultiAgentState, config: Optional[RunnableConfig] = None) -> MultiAgentState:
        # ... cÃ³digo existente de instrumentaÃ§Ã£o ...
        
        # Executar nÃ³ original
        try:
            result = node_func(state, config)
            
            # ... cÃ³digo existente de eventos ...
            
            # DISPARAR OBSERVER APÃ“S ORCHESTRATOR
            if agent_name == "orchestrator":
                _create_observer_callback(result)  # Usar result (state atualizado)
            
            return result
        except Exception as error:
            # ... cÃ³digo existente de tratamento de erro ...
```

**ConsideraÃ§Ãµes:**
- Thread daemon nÃ£o bloqueia shutdown do processo
- State atualizaÃ§Ã£o: Verificar se LangGraph state Ã© thread-safe
- Fallback: Se state nÃ£o for thread-safe, usar evento assÃ­ncrono para atualizaÃ§Ã£o

**Testes:**
- `tests/unit/test_observer_callback.py`: Testa callback disparado apÃ³s orchestrator
- `tests/integration/test_observer_state_update.py`: Valida atualizaÃ§Ã£o de state em thread separada
- `tests/integration/test_observer_event_publishing.py`: Verifica publicaÃ§Ã£o de eventos

**ValidaÃ§Ã£o:**
```bash
python scripts/validate_observer_integration.py
# Espera: Observer processa em <3s apÃ³s resposta do Orquestrador
# Espera: cognitive_model atualizado no state
# Espera: Evento publicado no EventBus
```

---

### 12.2: CognitiveModel no Estado e Prompt do Orquestrador

**Objetivo:** Orquestrador acessa cognitive_model via prompt e usa naturalmente

**ImplementaÃ§Ã£o:**

1. **Garantir que cognitive_model estÃ¡ no MultiAgentState:**
   - Campo jÃ¡ existe em `agents/orchestrator/state.py` (linha 114)
   - Tipo: `Optional[dict]`
   - Inicializado como `None`

2. **Atualizar prompt do Orquestrador:**
```python
# agents/orchestrator/nodes.py

def _build_context(state: MultiAgentState) -> str:
    """ConstrÃ³i contexto incluindo cognitive_model quando disponÃ­vel"""
    context_parts = []
    
    # ... cÃ³digo existente de contexto ...
    
    # ADICIONAR SEÃ‡ÃƒO DE COGNITIVE MODEL
    cognitive_model = state.get("cognitive_model")
    if cognitive_model:
        context_parts.append(_build_cognitive_model_context(cognitive_model))
    
    return "\n".join(context_parts)

def _build_cognitive_model_context(cognitive_model: dict) -> str:
    """Formata cognitive_model para o prompt"""
    parts = ["## COGNITIVE MODEL DISPONÃVEL"]
    parts.append("\nO Observador analisou o diÃ¡logo e extraiu:")
    parts.append("")
    
    # AfirmaÃ§Ã£o atual
    claim = cognitive_model.get("claim", "")
    if claim:
        parts.append(f"**AfirmaÃ§Ã£o atual:** {claim}")
        parts.append("")
    
    # Fundamentos (proposiÃ§Ãµes)
    proposicoes = cognitive_model.get("proposicoes", [])
    if proposicoes:
        parts.append("**Fundamentos (com solidez):**")
        for prop in proposicoes[:5]:  # Limitar a 5 para nÃ£o sobrecarregar prompt
            texto = prop.get("texto", "") if isinstance(prop, dict) else getattr(prop, "texto", "")
            solidez = prop.get("solidez", 0.0) if isinstance(prop, dict) else getattr(prop, "solidez", 0.0)
            parts.append(f"- {texto} (solidez: {solidez:.2f})")
        if len(proposicoes) > 5:
            parts.append(f"- ... e mais {len(proposicoes) - 5} fundamentos")
        parts.append("")
    
    # Conceitos
    concepts = cognitive_model.get("concepts_detected", [])
    if concepts:
        parts.append(f"**Conceitos detectados:** {', '.join(concepts[:10])}")
        parts.append("")
    
    # ContradiÃ§Ãµes
    contradictions = cognitive_model.get("contradictions", [])
    if contradictions:
        parts.append("**ContradiÃ§Ãµes detectadas:**")
        for c in contradictions[:3]:  # Limitar a 3
            desc = c.get("description", "") if isinstance(c, dict) else str(c)
            parts.append(f"- {desc}")
        parts.append("")
    
    # QuestÃµes em aberto
    open_questions = cognitive_model.get("open_questions", [])
    if open_questions:
        parts.append("**QuestÃµes em aberto:**")
        for q in open_questions[:5]:  # Limitar a 5
            parts.append(f"- {q}")
        parts.append("")
    
    # MÃ©tricas
    solidez = cognitive_model.get("overall_solidez", 0.0)
    completude = cognitive_model.get("overall_completude", 0.0)
    parts.append("**MÃ©tricas:**")
    parts.append(f"- Solidez: {solidez:.2f} (quÃ£o bem fundamentada estÃ¡ a afirmaÃ§Ã£o)")
    parts.append(f"- Completude: {completude:.2f} (quanto do argumento foi desenvolvido)")
    parts.append("")
    parts.append("Analise naturalmente e use quando Ãºtil para decidir prÃ³ximo passo.")
    
    return "\n".join(parts)
```

**Prompt do Orquestrador (adicionar instruÃ§Ã£o):**
```python
# agents/orchestrator/prompts.py ou similar

ORCHESTRATOR_SYSTEM_PROMPT = """
VocÃª Ã© o Orquestrador SocrÃ¡tico...

## USO DO COGNITIVE MODEL

Quando o Cognitive Model estiver disponÃ­vel no contexto, use-o para:
- Entender a evoluÃ§Ã£o do argumento
- Identificar lacunas e contradiÃ§Ãµes
- Decidir se aprofundar ou esclarecer
- Sugerir prÃ³ximo passo baseado em solidez/completude

O Cognitive Model Ã© uma anÃ¡lise automÃ¡tica do diÃ¡logo. Use-o como insight, nÃ£o como restriÃ§Ã£o.
"""
```

**Testes:**
- `tests/unit/test_orchestrator_cognitive_access.py`: Valida leitura de cognitive_model do state
- `tests/integration/test_orchestrator_uses_cognitive_model.py`: Verifica que Claude menciona cognitive_model no reasoning

---

### 12.3: Timeline Visual

**Objetivo:** Mostrar quando Observer processou turno na timeline

**ImplementaÃ§Ã£o:**
```python
# app/components/backstage/timeline.py

def render_agent_timeline(session_id: str) -> None:
    """Renderiza histÃ³rico incluindo eventos do Observer"""
    try:
        bus = get_event_bus()
        events = bus.get_session_events(session_id)
        
        # Filtrar eventos agent_completed E cognitive_model_updated
        completed_events = [e for e in events if e.get("event_type") == "agent_completed"]
        observer_events = [e for e in events if e.get("event_type") == "cognitive_model_updated"]
        
        # ... cÃ³digo existente para completed_events ...
        
        # ADICIONAR EVENTOS DO OBSERVER
        if observer_events:
            st.markdown("---")
            st.markdown("**ğŸ‘ï¸ Observador**")
            
            for event in observer_events[-3:]:  # Ãšltimos 3 eventos do Observer
                turn_number = event.get("metadata", {}).get("turn_number", 0)
                solidez = event.get("metadata", {}).get("solidez", 0.0)
                concepts_count = event.get("metadata", {}).get("concepts_count", 0)
                timestamp = event.get("timestamp", "")
                
                st.markdown(f"ğŸ‘ï¸ **Turno {turn_number}** processado")
                st.caption(f"ğŸ§  {concepts_count} conceitos Â· Solidez: {solidez:.2f} Â· {timestamp}")
                
except Exception as e:
    logger.error(f"Erro ao renderizar timeline: {e}")
```

**Alternativa (seÃ§Ã£o separada):**
```python
# Adicionar seÃ§Ã£o colapsÃ¡vel "ğŸ‘ï¸ Observador" separada
with st.expander("ğŸ‘ï¸ Observador", expanded=False):
    if observer_events:
        for event in observer_events[-5:]:  # Ãšltimos 5 eventos
            # ... renderizar evento ...
    else:
        st.caption("Observer ainda nÃ£o processou turnos")
```

**Testes:**
- ValidaÃ§Ã£o visual manual (testar em interface web)
- `tests/integration/test_timeline_observer_events.py`: Verifica que eventos sÃ£o renderizados

## Estimativas

- **LOC:** ~600 linhas
- **Tempo:** 2h
- **Risco:** Baixo (spikes validaram viabilidade)

## CritÃ©rios de AceitaÃ§Ã£o

1. âœ… Observer processa cada turno automaticamente apÃ³s Orquestrador
2. âœ… LatÃªncia do usuÃ¡rio nÃ£o aumenta (Observer em background, <3s)
3. âœ… cognitive_model atualizado no state apÃ³s processamento
4. âœ… Orquestrador menciona cognitive_model no reasoning quando disponÃ­vel
5. âœ… Timeline mostra atividade do Observer
6. âœ… Eventos `cognitive_model_updated` publicados no EventBus
7. âœ… Testes passam (unit + integration)

## Riscos e MitigaÃ§Ãµes

### Risco 1: State nÃ£o thread-safe
**MitigaÃ§Ã£o:** 
- Testar comportamento com LangGraph checkpoint
- Se nÃ£o for thread-safe, usar fila de eventos para atualizaÃ§Ã£o assÃ­ncrona
- Alternativa: Usar asyncio ao invÃ©s de threading

### Risco 2: LatÃªncia perceptÃ­vel
**MitigaÃ§Ã£o:**
- Observer roda em background (nÃ£o bloqueia resposta)
- Se latÃªncia for >3s, considerar otimizaÃ§Ãµes (processar apenas conceitos essenciais)
- Adicionar timeout (5s) para nÃ£o travar sistema

### Risco 3: Observer falha silenciosamente
**MitigaÃ§Ã£o:**
- Try/except completo no callback
- Logging de erros
- Evento de erro publicado no EventBus
- Fallback: continuar sem cognitive_model (nÃ£o quebra sistema)

## ReferÃªncias

- CÃ³digo Observer: `agents/observer/`
- Multi-agent graph: `agents/multi_agent_graph.py`
- Estado: `agents/orchestrator/state.py`
- Spikes: 
  - `scripts/spikes/validate_langgraph_parallel.py`
  - `scripts/spikes/validate_cognitive_model_access.py`
- EventBus: `utils/event_bus/`
- Timeline: `app/components/backstage/timeline.py`
- DocumentaÃ§Ã£o Observer: `docs/agents/observer.md`


