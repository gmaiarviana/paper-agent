# Observador - Mente Anal√≠tica

**Status:** ‚úÖ Implementado (√âpico 10 + 11.4 Completos)
**Vers√£o:** 2.3
**Data:** 08/12/2025

## Resumo

Agente especializado em observar e catalogar a evolu√ß√£o do racioc√≠nio durante conversas. Trabalha **silenciosamente em paralelo** ao Orquestrador, atualizando o CognitiveModel e extraindo conceitos automaticamente.

**Analogia:**
```
Orquestrador = Ator principal (fala, age, decide)
Observador = Testemunha silenciosa (v√™ tudo, cataloga, n√£o interfere)
```

---

## Mitose do Orquestrador

### Por Que Separar?

**Antes (Orquestrador monol√≠tico):**
- Facilitava conversa E observava racioc√≠nio
- Duas responsabilidades conflitantes
- Complexidade crescente

**Depois (Separa√ß√£o clara):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ORQUESTRADOR               ‚îÇ  ‚îÇ   OBSERVADOR                 ‚îÇ
‚îÇ   (Facilitador)              ‚îÇ  ‚îÇ   (Mente Anal√≠tica)          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Facilita conversa          ‚îÇ  ‚îÇ ‚Ä¢ Monitora TODA conversa     ‚îÇ
‚îÇ ‚Ä¢ Negocia caminhos           ‚îÇ  ‚îÇ ‚Ä¢ Atualiza CognitiveModel    ‚îÇ
‚îÇ ‚Ä¢ Apresenta op√ß√µes           ‚îÇ  ‚îÇ ‚Ä¢ Extrai conceitos           ‚îÇ
‚îÇ ‚Ä¢ Provoca reflex√£o           ‚îÇ  ‚îÇ ‚Ä¢ Avalia evolu√ß√£o            ‚îÇ
‚îÇ ‚Ä¢ Consulta Observador ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚Ä¢ Detecta lacunas            ‚îÇ
‚îÇ ‚Ä¢ Decide next_step           ‚îÇ  ‚îÇ ‚Ä¢ Responde consultas ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Responsabilidades

### O que FAZ

- ‚úÖ **Monitorar TODA conversa** (todo turno, n√£o apenas snapshots)
- ‚úÖ **Atualizar CognitiveModel completo:**
  - Claims emergentes (proposi√ß√µes centrais)
  - Fundamentos (argumentos de suporte)
  - Contradi√ß√µes (inconsist√™ncias detectadas)
  - Conceitos (ess√™ncias sem√¢nticas - ChromaDB + SQLite)
  - Open questions (lacunas a investigar)
  - Context (dom√≠nio, popula√ß√£o, tecnologia)
- ‚úÖ **Avaliar evolu√ß√£o** de ideias e argumentos
- ‚úÖ **Detectar lacunas** e inconsist√™ncias
- ‚úÖ **Calcular m√©tricas** (solidez, completude)
- ‚úÖ **Responder consultas** do Orquestrador (insights, n√£o comandos)
- ‚úÖ **Publicar eventos** para Dashboard (silencioso)

### O que N√ÉO FAZ

- ‚ùå Decidir next_step (quem decide: Orquestrador)
- ‚ùå Falar com usu√°rio (quem fala: Orquestrador)
- ‚ùå Negociar caminhos (quem negocia: Orquestrador)
- ‚ùå Interromper fluxo conversacional

---

## Timing: Todo Turno (Sempre)

**Decis√£o:** Observador processa **TODOS os turnos**, n√£o apenas snapshots.

**Por qu√™?**
- Garante que nada √© perdido
- CognitiveModel sempre atualizado
- Conceitos detectados continuamente
- N√£o depende de eventos externos (snapshots)

**Custo vs Completude:**
- ‚úÖ Completude m√°xima (nunca perde conceito)
- ‚ö†Ô∏è Custo constante (LLM em todo turno)
- ‚ö†Ô∏è Mas: Observador usa modelo eficiente (Haiku) e processamento √© r√°pido

---

## CognitiveModel Completo

### Estrutura Atualizada pelo Observador

> **√âpico 11.4:** Estrutura migrada de `premises`/`assumptions` para `proposicoes` unificadas.

```python
CognitiveModel:
  # Claim (afirma√ß√£o central)
  claim: str

  # Proposi√ß√µes (fundamentos com solidez vari√°vel)
  # Substitui distin√ß√£o bin√°ria premise/assumption
  proposicoes: list[Proposicao]  # {texto, solidez, evidencias}

  # Contradi√ß√µes (inconsist√™ncias)
  contradictions: list[Contradiction]  # {description, confidence, suggested_resolution}

  # Conceitos (ess√™ncias sem√¢nticas)
  concepts_detected: list[str]  # Labels detectados (ChromaDB)

  # Open questions (lacunas)
  open_questions: list[str]

  # Context (contexto evolutivo)
  context: dict  # {domain, population, technology}

  # Solid grounds (evid√™ncias bibliogr√°ficas - futuro)
  solid_grounds: list[SolidGround]  # {claim, evidence, source}
```

**Proposicao:**
```python
class Proposicao:
    texto: str          # Enunciado da proposi√ß√£o
    solidez: float|None # 0-1 (None = n√£o avaliada)
    evidencias: list    # IDs de evid√™ncias (futuro)
```

### Atualiza√ß√£o a Cada Turno

```python
def process_turn(user_input: str, conversation_history: list):
    """Observador processa cada turno (√âpico 11.4)."""

    # 1. Extra√ß√£o sem√¢ntica via LLM
    extracted = extract_all(user_input, conversation_history)
    # extracted = {
    #     "claims": [...],
    #     "concepts": [...],
    #     "proposicoes": [Proposicao(texto=..., solidez=None), ...],
    #     "contradictions": [...],
    #     "open_questions": [...]
    # }

    # 2. Mescla com CognitiveModel anterior
    cognitive_model = merge_cognitive_model(previous, extracted)
    # proposicoes acumulam por similaridade de texto

    # 3. Calcula m√©tricas (via LLM)
    metrics = calculate_metrics(
        claim=cognitive_model["claim"],
        proposicoes=cognitive_model["proposicoes"],  # Lista unificada
        open_questions=cognitive_model["open_questions"],
        contradictions=cognitive_model["contradictions"]
    )

    # 4. Persiste conceitos no cat√°logo
    persist_concepts_batch(extracted["concepts"], idea_id)

    # 5. Publica eventos (silencioso)
    event_bus.publish(CognitiveModelUpdatedEvent(cognitive_model, metrics))
```

---

## Interface de Consulta (N√£o-Determin√≠stica)

### Filosofia

**N√ÉO √© command & control:**
```python
# ‚ùå ERRADO: Observador d√° ordens
solidez = observador.get_solidez()
if solidez < 0.7:
    next_step = "explore"  # Orquestrador perde autonomia
```

**√â di√°logo contextual:**
```python
# ‚úÖ CERTO: Observador d√° insights
insight = observador.what_do_you_see(
    context="Usu√°rio mudou de dire√ß√£o",
    question="Conceitos anteriores ainda relevantes?"
)
# Retorna: {
#   "relevance": "Parcial - LLMs ainda central, mas bugs √© novo foco",
#   "suggestion": "Pode conectar: bugs como m√©trica de produtividade",
#   "confidence": 0.8
# }

# Orquestrador decide autonomamente baseado em insight
decision = decide_with_insight(my_analysis, insight)
```

### Quando Orquestrador Consulta?

**Gatilhos naturais** (n√£o regras fixas):

1. **Mudan√ßa de dire√ß√£o detectada:**
   ```
   Usu√°rio (turno 1): "LLMs aumentam produtividade"
   Usu√°rio (turno 5): "Na verdade, quero focar em bugs"
   
   Orquestrador: "Hmm, percebi mudan√ßa. Deixa eu verificar contexto..."
   ‚Üí Consulta: "O que mudou? Conceitos anteriores ainda relevantes?"
   ```

2. **Contradi√ß√£o aparente:**
   ```
   Usu√°rio (turno 3): "Claude Code √© mais r√°pido"
   Usu√°rio (turno 8): "Mas velocidade n√£o importa tanto"
   
   Orquestrador: "Voc√™ mencionou velocidade antes de forma diferente..."
   ‚Üí Consulta: "H√° contradi√ß√£o? Claim evoluiu ou h√° inconsist√™ncia?"
   ```

3. **Incerteza sobre profundidade:**
   ```
   Usu√°rio: "Produtividade depende de muitos fatores"
   
   Orquestrador: "Quantos fundamentos j√° temos? Vale aprofundar mais?"
   ‚Üí Consulta: "Fundamentos atuais cobrem o claim?"
   ```

4. **Checagem de completude:**
   ```
   Orquestrador: "Acho que temos claim + fundamentos s√≥lidos..."
   ‚Üí Consulta: "Solidez suficiente? H√° gaps cr√≠ticos?"
   ```

### API de Consulta

```python
class ObservadorAPI:
    def what_do_you_see(self, context: str, question: str) -> dict:
        """
        Responde consulta contextual do Orquestrador.
        
        Args:
            context: Contexto da consulta (ex: "mudan√ßa de dire√ß√£o")
            question: Pergunta espec√≠fica (ex: "conceitos ainda relevantes?")
            
        Returns:
            {
                "insight": str,         # Observa√ß√£o principal
                "suggestion": str,      # Sugest√£o de a√ß√£o (opcional)
                "confidence": float,    # 0-1
                "evidence": dict        # Dados do CognitiveModel que sustentam
            }
        """
        pass
    
    def get_current_state(self) -> dict:
        """
        Retorna estado atual completo do CognitiveModel.
        
        Usado quando Orquestrador precisa de vis√£o geral,
        n√£o apenas insight espec√≠fico.
        """
        return cognitive_model.to_dict()
    
    def has_contradiction(self) -> bool:
        """Check r√°pido: h√° contradi√ß√µes detectadas?"""
        return len(cognitive_model.contradictions) > 0
    
    def get_solidez(self) -> float:
        """Check r√°pido: solidez geral atual."""
        return cognitive_model.solidez_geral
```

---

## Visualiza√ß√£o nos Bastidores

### Layout (Ambos Colaps√°veis)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     üìä BASTIDORES                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  [‚ñ∂ Timeline] (colapsado)      ‚îÇ  [‚ñ∂ Observador] (colapsado)   ‚îÇ
‚îÇ                                ‚îÇ                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Estado padr√£o:** Ambos colapsados (interface limpa)

### Timeline (Esquerda - Colaps√°vel)

**Quando expandido:**
```
[‚ñº Timeline]
12:34:01 üéØ Orquestrador analisa input
12:34:02 üéØ Orquestrador consulta Observador
12:34:03 üëÅÔ∏è Observador atualizou modelo (2 conceitos novos)
12:34:04 üéØ Orquestrador decide: explore
12:34:05 üìê Estruturador estrutura quest√£o
```

**Quando mostrar Observador na timeline?**

Apenas quando **relevante:**
- ‚úÖ Conceito novo detectado: "üëÅÔ∏è Observador detectou 2 conceitos: LLMs, Produtividade"
- ‚úÖ Contradi√ß√£o detectada: "üëÅÔ∏è Observador detectou contradi√ß√£o entre X e Y"
- ‚úÖ Solidez mudou significativamente: "üëÅÔ∏è Solidez aumentou: 0.65 ‚Üí 0.80"
- ‚ùå Atualiza√ß√£o rotineira sem novidades

### Painel Observador (Direita - Colaps√°vel)

**Quando expandido:**
```
[‚ñº Observador - Mente Anal√≠tica]

üìã Estado atual do racioc√≠nio:

Conceitos detectados:
‚Ä¢ LLMs (agora)
‚Ä¢ Produtividade (2 turnos atr√°s)
‚Ä¢ Claude Code (agora) üÜï

Claims atuais:
‚Ä¢ "LLMs aumentam produtividade"

Solidez geral: 0.65 ‚ö†Ô∏è

Open questions:
‚Ä¢ Como medir produtividade?
‚Ä¢ Qual popula√ß√£o-alvo?

[‚ñº Ver reasoning completo]
  (expande para mostrar prompt usado, an√°lise LLM)
```

**Informa√ß√µes vis√≠veis:**
- Conceitos detectados (com timing)
- Claims atuais
- Solidez geral (visual: üü¢ alta, üü° m√©dia, üî¥ baixa)
- Open questions pendentes
- Contradi√ß√µes (se houver)

**Modo debug (colaps√°vel dentro do painel):**
- Prompt completo enviado ao LLM
- Resposta bruta do LLM
- Reasoning detalhado
- Embeddings gerados (ChromaDB)

---

## Extra√ß√£o de Conceitos

### Pipeline

```python
def extract_concepts(user_input: str) -> list[Concept]:
    """
    Extrai conceitos-chave do turno atual.
    
    Pipeline:
    1. LLM extrai conceitos (prompt espec√≠fico)
    2. Gera embeddings (sentence-transformers)
    3. Busca similares no cat√°logo (ChromaDB)
    4. Deduplica ou cria novo (threshold 0.80)
    5. Salva metadados (SQLite)
    """
    
    # 1. LLM extrai
    concepts_text = llm.invoke(EXTRACT_CONCEPTS_PROMPT.format(input=user_input))
    
    # 2. Para cada conceito
    for concept_label in concepts_text:
        # Gera embedding
        embedding = sentence_transformer.encode(concept_label)
        
        # Busca similares
        similar = chromadb.query(embedding, top_k=3)
        
        # Deduplica ou cria
        if similar and similar[0].similarity > 0.80:
            # Mesmo conceito, adiciona variation
            concept = similar[0]
            concept.variations.append(concept_label)
        else:
            # Conceito novo
            concept = Concept(
                label=concept_label,
                embedding=embedding
            )
            chromadb.save(concept)
            sqlite.save(concept)
    
    return concepts
```

### Deduplica√ß√£o (Threshold)

- **> 0.80:** Mesmo conceito (adiciona como variation)
- **0.75-0.80:** Zona cinzenta (pergunta ao usu√°rio no futuro)
- **< 0.75:** Conceito diferente (cria novo)

### Exemplo

```
Turno 1: "LLMs aumentam produtividade"
‚Üí Detecta: ["LLMs", "Produtividade"]
‚Üí Salva ambos no cat√°logo

Turno 3: "Language models s√£o eficientes"
‚Üí Detecta: ["Language models", "Efici√™ncia"]
‚Üí "Language models" similar a "LLMs" (0.92)
‚Üí Adiciona "Language models" como variation de "LLMs"
‚Üí "Efici√™ncia" similar a "Produtividade" (0.85)
‚Üí Adiciona "Efici√™ncia" como variation de "Produtividade"

Cat√°logo final:
‚Ä¢ LLMs (variations: ["Language models"])
‚Ä¢ Produtividade (variations: ["Efici√™ncia"])
```

---

## Integra√ß√£o com CognitiveModel

### Rela√ß√£o com √âpico 9 (Snapshots)

**√âpico 9:** Snapshots de Idea (quando argumento amadurece)
**√âpico 10:** Observador processa TODOS os turnos

**Complementaridade:**
- Snapshots = marcos importantes (salva progresso)
- Observador = monitoramento cont√≠nuo (cataloga conceitos)

**Fluxo:**
```
Turno 1-5: Observador cataloga conceitos
Turno 5: Argumento amadurece ‚Üí Snapshot criado
         ‚Üí Snapshot referencia conceitos catalogados
Turno 6-10: Observador continua catalogando
Turno 10: Novo snapshot ‚Üí referencia conceitos novos
```

### Atualiza√ß√£o do Snapshot

```python
# Quando snapshot √© criado
def create_snapshot(idea_id: UUID):
    # Pega conceitos detectados pelo Observador
    conceitos = cognitive_model.conceitos
    
    # Associa ao snapshot
    snapshot = Snapshot(
        idea_id=idea_id,
        concept_ids=conceitos,  # Refer√™ncia N:N
        focal_argument=cognitive_model.claims[0],
        solidez=cognitive_model.solidez_geral
    )
    
    db.save(snapshot)
```

---

## Tecnologias

### LLM
- **Modelo:** claude-3-5-haiku-20241022
- **Justificativa:** Custo-efetivo, r√°pido, suficiente para extra√ß√£o
- **Temperature:** 0 (determin√≠stico)

### ChromaDB
- **Tipo:** Local, persistente
- **Path:** `./data/chroma`
- **Collection:** `concepts`
- **Embedding:** sentence-transformers (all-MiniLM-L6-v2, 384 dim)

### SQLite
- **Tabelas:**
  - `concepts` (id, label, essence, variations JSON, chroma_id)
  - `concept_variations` (concept_id, variation)
  - `idea_concepts` (idea_id, concept_id)

---

## Evolu√ß√£o (√âpicos)

### ‚úÖ √âpico 10: Observador - Mente Anal√≠tica (POC) - COMPLETO
- ‚úÖ **10.1 Mitose do Orquestrador** - IMPLEMENTADO
  - Estrutura `agents/observer/` criada
  - ObservadorAPI com interface de consulta
  - Separa√ß√£o de responsabilidades documentada
- ‚úÖ **10.2 Processamento via LLM** - IMPLEMENTADO
  - Extratores sem√¢nticos (claims, concepts, fundamentos, contradictions)
  - M√©tricas via LLM (solidez, completude)
  - `process_turn()` + `ObserverProcessor`
  - `CognitiveModelUpdatedEvent` no EventBus
- ‚úÖ **10.3 ChromaDB + SQLite setup** - IMPLEMENTADO
  - ChromaDB persistente com cosine distance (`data/chroma/`)
  - SQLite com tabelas: concepts, concept_variations, idea_concepts
  - Embedding model: all-MiniLM-L6-v2 (384 dim)
  - `ConceptCatalog` com deduplica√ß√£o autom√°tica
- ‚úÖ **10.4 Pipeline de conceitos** - IMPLEMENTADO
  - `persist_concepts()` e `persist_concepts_batch()`
  - Integra√ß√£o com `process_turn()` via `persist_concepts_flag`
  - Link N:N entre Idea e Concept via `idea_id`
  - Par√¢metros opcionais para Agentic RAG (Epic 12)
- ‚úÖ **10.5 Busca sem√¢ntica** - IMPLEMENTADO
  - `find_similar_concepts()` com threshold configur√°vel
  - Similaridade cosseno ordenada descendente
  - Thresholds: 0.80 (mesmo conceito), 0.90 (auto-variation)
- ‚úÖ **10.6 Testes POC** - IMPLEMENTADO
  - 22 testes unit√°rios em `tests/unit/test_observer.py`
  - Cobertura: ConceptCatalog, Pipeline, Embeddings, Deduplica√ß√£o
  - Mocks para LLM, vetores fixos para busca sem√¢ntica
### ‚úÖ √âpico 12: Observador Integrado ao Fluxo - COMPLETO

Observer integrado ao grafo multi-agente via callback ass√≠ncrono.

**Implementa√ß√£o:**
- ‚úÖ **12.1 Callback Ass√≠ncrono** - IMPLEMENTADO
  - `_create_observer_callback()` em `agents/multi_agent_graph.py`
  - Thread daemon ap√≥s `orchestrator_node` (n√£o bloqueia shutdown)
  - Atualiza `state["cognitive_model"]` com an√°lise sem√¢ntica
  - Tempo de processamento: <3s em background
  - Publica `CognitiveModelUpdatedEvent` via EventBus

- ‚úÖ **12.2 CognitiveModel no Prompt** - IMPLEMENTADO
  - `_build_cognitive_model_context()` em `agents/orchestrator/nodes.py`
  - Formata claim, proposi√ß√µes (top 5 por solidez), conceitos (max 10)
  - Inclui contradi√ß√µes (max 3), quest√µes abertas (max 5), m√©tricas
  - Orquestrador usa naturalmente via prompt context

- ‚úÖ **12.3 Timeline Visual** - IMPLEMENTADO
  - `render_observer_section()` em `app/components/backstage/timeline.py`
  - Se√ß√£o colaps√°vel "üëÅÔ∏è Observador" com √∫ltimos turnos
  - M√©tricas: conceitos, proposi√ß√µes, solidez, maturidade
  - Modal "üëÅÔ∏è An√°lise do Observador" com hist√≥rico completo

- ‚úÖ **12.4 Testes** - IMPLEMENTADO
  - 9 testes em `tests/unit/test_observer_callback.py`
  - 19 testes em `tests/unit/agents/orchestrator/test_cognitive_context.py`
  - Script `scripts/validate_observer_integration.py`

**Fluxo de integra√ß√£o:**
```
User Input ‚Üí Orchestrator ‚Üí Response
                  ‚Üì
           [Background]
                  ‚Üì
             Observer ‚Üí cognitive_model
                  ‚Üì
         EventBus ‚Üí Timeline
```

**Detalhes:** Ver `docs/epics/epic-12-observer-integration.md`

### √âpico 13: Cat√°logo de Conceitos (Interface)
- ‚úÖ P√°gina `/catalogo` (busca, filtros, analytics)
- ‚úÖ Preview na p√°gina da ideia
- ‚úÖ Navega√ß√£o: conceito ‚Üí ideias ‚Üí detalhes
- ‚úÖ Export/import de biblioteca

---

## Refer√™ncias

- `docs/architecture/observer_architecture.md` - Arquitetura t√©cnica
- `docs/architecture/ontology.md` - CognitiveModel e Conceitos
- `docs/architecture/concept_model.md` - Schema de Concept
- `docs/vision/cognitive_model/core.md` - Fundamentos epistemol√≥gicos
- `ROADMAP.md` - √âpicos 10, 12, 13

---

**Vers√£o:** 2.3
**Data:** 08/12/2025
**Status:** ‚úÖ √âpico 10 Completo (POC) | ‚úÖ √âpico 11.4 Completo (Migra√ß√£o Proposi√ß√µes) | Pr√≥ximo: √âpico 12

