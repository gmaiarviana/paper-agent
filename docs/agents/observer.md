# Observador - Mente AnalÃ­tica

**Status:** âœ… Implementado (Ã‰pico 10 Completo - POC)
**VersÃ£o:** 2.2
**Data:** 07/12/2025

## Resumo

Agente especializado em observar e catalogar a evoluÃ§Ã£o do raciocÃ­nio durante conversas. Trabalha **silenciosamente em paralelo** ao Orquestrador, atualizando o CognitiveModel e extraindo conceitos automaticamente.

**Analogia:**
```
Orquestrador = Ator principal (fala, age, decide)
Observador = Testemunha silenciosa (vÃª tudo, cataloga, nÃ£o interfere)
```

---

## Mitose do Orquestrador

### Por Que Separar?

**Antes (Orquestrador monolÃ­tico):**
- Facilitava conversa E observava raciocÃ­nio
- Duas responsabilidades conflitantes
- Complexidade crescente

**Depois (SeparaÃ§Ã£o clara):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ORQUESTRADOR               â”‚  â”‚   OBSERVADOR                 â”‚
â”‚   (Facilitador)              â”‚  â”‚   (Mente AnalÃ­tica)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Facilita conversa          â”‚  â”‚ â€¢ Monitora TODA conversa     â”‚
â”‚ â€¢ Negocia caminhos           â”‚  â”‚ â€¢ Atualiza CognitiveModel    â”‚
â”‚ â€¢ Apresenta opÃ§Ãµes           â”‚  â”‚ â€¢ Extrai conceitos           â”‚
â”‚ â€¢ Provoca reflexÃ£o           â”‚  â”‚ â€¢ Avalia evoluÃ§Ã£o            â”‚
â”‚ â€¢ Consulta Observador â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â€¢ Detecta lacunas            â”‚
â”‚ â€¢ Decide next_step           â”‚  â”‚ â€¢ Responde consultas â—€â”€â”€â”€â”€â”€â”€â”€â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Responsabilidades

### O que FAZ

- âœ… **Monitorar TODA conversa** (todo turno, nÃ£o apenas snapshots)
- âœ… **Atualizar CognitiveModel completo:**
  - Claims emergentes (proposiÃ§Ãµes centrais)
  - Fundamentos (argumentos de suporte)
  - ContradiÃ§Ãµes (inconsistÃªncias detectadas)
  - Conceitos (essÃªncias semÃ¢nticas - ChromaDB + SQLite)
  - Open questions (lacunas a investigar)
  - Context (domÃ­nio, populaÃ§Ã£o, tecnologia)
- âœ… **Avaliar evoluÃ§Ã£o** de ideias e argumentos
- âœ… **Detectar lacunas** e inconsistÃªncias
- âœ… **Calcular mÃ©tricas** (solidez, completude)
- âœ… **Responder consultas** do Orquestrador (insights, nÃ£o comandos)
- âœ… **Publicar eventos** para Dashboard (silencioso)

### O que NÃƒO FAZ

- âŒ Decidir next_step (quem decide: Orquestrador)
- âŒ Falar com usuÃ¡rio (quem fala: Orquestrador)
- âŒ Negociar caminhos (quem negocia: Orquestrador)
- âŒ Interromper fluxo conversacional

---

## Timing: Todo Turno (Sempre)

**DecisÃ£o:** Observador processa **TODOS os turnos**, nÃ£o apenas snapshots.

**Por quÃª?**
- Garante que nada Ã© perdido
- CognitiveModel sempre atualizado
- Conceitos detectados continuamente
- NÃ£o depende de eventos externos (snapshots)

**Custo vs Completude:**
- âœ… Completude mÃ¡xima (nunca perde conceito)
- âš ï¸ Custo constante (LLM em todo turno)
- âš ï¸ Mas: Observador usa modelo eficiente (Haiku) e processamento Ã© rÃ¡pido

---

## CognitiveModel Completo

### Estrutura Atualizada pelo Observador

```python
CognitiveModel:
  # Claims (proposiÃ§Ãµes centrais)
  claims: list[str]
  
  # Fundamentos (argumentos de suporte)
  fundamentos: list[str]
  
  # ContradiÃ§Ãµes (inconsistÃªncias)
  contradictions: list[dict]  # {claim_a, claim_b, explanation}
  
  # Conceitos (essÃªncias semÃ¢nticas)
  conceitos: list[UUID]  # ReferÃªncias a Concept (ChromaDB)
  
  # Open questions (lacunas)
  open_questions: list[str]
  
  # Context (contexto evolutivo)
  context: dict  # {domain, population, technology}
  
  # MÃ©tricas (calculadas)
  solidez_geral: float  # 0-1
  completude: float     # 0-1
```

### AtualizaÃ§Ã£o a Cada Turno

```python
def process_turn(user_input: str, conversation_history: list):
    """Observador processa cada turno."""
    
    # 1. AnÃ¡lise completa
    claims = extract_claims(user_input)
    conceitos = extract_concepts(user_input)
    fundamentos = identify_fundamentos(conversation_history)
    contradictions = detect_contradictions(claims, fundamentos)
    open_questions = identify_gaps(claims, fundamentos)
    
    # 2. Atualiza CognitiveModel
    cognitive_model.update({
        "claims": claims,
        "conceitos": conceitos,
        "fundamentos": fundamentos,
        "contradictions": contradictions,
        "open_questions": open_questions
    })
    
    # 3. Calcula mÃ©tricas
    solidez = calculate_solidez(fundamentos)
    completude = calculate_completude(open_questions)
    
    # 4. Salva conceitos no catÃ¡logo
    for conceito in conceitos:
        chromadb.save(conceito)
        sqlite.save_metadata(conceito)
    
    # 5. Publica eventos (silencioso)
    event_bus.publish(ConceptsDetectedEvent(conceitos))
    event_bus.publish(CognitiveModelUpdatedEvent(cognitive_model))
```

---

## Interface de Consulta (NÃ£o-DeterminÃ­stica)

### Filosofia

**NÃƒO Ã© command & control:**
```python
# âŒ ERRADO: Observador dÃ¡ ordens
solidez = observador.get_solidez()
if solidez < 0.7:
    next_step = "explore"  # Orquestrador perde autonomia
```

**Ã‰ diÃ¡logo contextual:**
```python
# âœ… CERTO: Observador dÃ¡ insights
insight = observador.what_do_you_see(
    context="UsuÃ¡rio mudou de direÃ§Ã£o",
    question="Conceitos anteriores ainda relevantes?"
)
# Retorna: {
#   "relevance": "Parcial - LLMs ainda central, mas bugs Ã© novo foco",
#   "suggestion": "Pode conectar: bugs como mÃ©trica de produtividade",
#   "confidence": 0.8
# }

# Orquestrador decide autonomamente baseado em insight
decision = decide_with_insight(my_analysis, insight)
```

### Quando Orquestrador Consulta?

**Gatilhos naturais** (nÃ£o regras fixas):

1. **MudanÃ§a de direÃ§Ã£o detectada:**
   ```
   UsuÃ¡rio (turno 1): "LLMs aumentam produtividade"
   UsuÃ¡rio (turno 5): "Na verdade, quero focar em bugs"
   
   Orquestrador: "Hmm, percebi mudanÃ§a. Deixa eu verificar contexto..."
   â†’ Consulta: "O que mudou? Conceitos anteriores ainda relevantes?"
   ```

2. **ContradiÃ§Ã£o aparente:**
   ```
   UsuÃ¡rio (turno 3): "Claude Code Ã© mais rÃ¡pido"
   UsuÃ¡rio (turno 8): "Mas velocidade nÃ£o importa tanto"
   
   Orquestrador: "VocÃª mencionou velocidade antes de forma diferente..."
   â†’ Consulta: "HÃ¡ contradiÃ§Ã£o? Claim evoluiu ou hÃ¡ inconsistÃªncia?"
   ```

3. **Incerteza sobre profundidade:**
   ```
   UsuÃ¡rio: "Produtividade depende de muitos fatores"
   
   Orquestrador: "Quantos fundamentos jÃ¡ temos? Vale aprofundar mais?"
   â†’ Consulta: "Fundamentos atuais cobrem o claim?"
   ```

4. **Checagem de completude:**
   ```
   Orquestrador: "Acho que temos claim + fundamentos sÃ³lidos..."
   â†’ Consulta: "Solidez suficiente? HÃ¡ gaps crÃ­ticos?"
   ```

### API de Consulta

```python
class ObservadorAPI:
    def what_do_you_see(self, context: str, question: str) -> dict:
        """
        Responde consulta contextual do Orquestrador.
        
        Args:
            context: Contexto da consulta (ex: "mudanÃ§a de direÃ§Ã£o")
            question: Pergunta especÃ­fica (ex: "conceitos ainda relevantes?")
            
        Returns:
            {
                "insight": str,         # ObservaÃ§Ã£o principal
                "suggestion": str,      # SugestÃ£o de aÃ§Ã£o (opcional)
                "confidence": float,    # 0-1
                "evidence": dict        # Dados do CognitiveModel que sustentam
            }
        """
        pass
    
    def get_current_state(self) -> dict:
        """
        Retorna estado atual completo do CognitiveModel.
        
        Usado quando Orquestrador precisa de visÃ£o geral,
        nÃ£o apenas insight especÃ­fico.
        """
        return cognitive_model.to_dict()
    
    def has_contradiction(self) -> bool:
        """Check rÃ¡pido: hÃ¡ contradiÃ§Ãµes detectadas?"""
        return len(cognitive_model.contradictions) > 0
    
    def get_solidez(self) -> float:
        """Check rÃ¡pido: solidez geral atual."""
        return cognitive_model.solidez_geral
```

---

## VisualizaÃ§Ã£o nos Bastidores

### Layout (Ambos ColapsÃ¡veis)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ğŸ“Š BASTIDORES                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  [â–¶ Timeline] (colapsado)      â”‚  [â–¶ Observador] (colapsado)   â”‚
â”‚                                â”‚                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Estado padrÃ£o:** Ambos colapsados (interface limpa)

### Timeline (Esquerda - ColapsÃ¡vel)

**Quando expandido:**
```
[â–¼ Timeline]
12:34:01 ğŸ¯ Orquestrador analisa input
12:34:02 ğŸ¯ Orquestrador consulta Observador
12:34:03 ğŸ‘ï¸ Observador atualizou modelo (2 conceitos novos)
12:34:04 ğŸ¯ Orquestrador decide: explore
12:34:05 ğŸ“ Estruturador estrutura questÃ£o
```

**Quando mostrar Observador na timeline?**

Apenas quando **relevante:**
- âœ… Conceito novo detectado: "ğŸ‘ï¸ Observador detectou 2 conceitos: LLMs, Produtividade"
- âœ… ContradiÃ§Ã£o detectada: "ğŸ‘ï¸ Observador detectou contradiÃ§Ã£o entre X e Y"
- âœ… Solidez mudou significativamente: "ğŸ‘ï¸ Solidez aumentou: 0.65 â†’ 0.80"
- âŒ AtualizaÃ§Ã£o rotineira sem novidades

### Painel Observador (Direita - ColapsÃ¡vel)

**Quando expandido:**
```
[â–¼ Observador - Mente AnalÃ­tica]

ğŸ“‹ Estado atual do raciocÃ­nio:

Conceitos detectados:
â€¢ LLMs (agora)
â€¢ Produtividade (2 turnos atrÃ¡s)
â€¢ Claude Code (agora) ğŸ†•

Claims atuais:
â€¢ "LLMs aumentam produtividade"

Solidez geral: 0.65 âš ï¸

Open questions:
â€¢ Como medir produtividade?
â€¢ Qual populaÃ§Ã£o-alvo?

[â–¼ Ver reasoning completo]
  (expande para mostrar prompt usado, anÃ¡lise LLM)
```

**InformaÃ§Ãµes visÃ­veis:**
- Conceitos detectados (com timing)
- Claims atuais
- Solidez geral (visual: ğŸŸ¢ alta, ğŸŸ¡ mÃ©dia, ğŸ”´ baixa)
- Open questions pendentes
- ContradiÃ§Ãµes (se houver)

**Modo debug (colapsÃ¡vel dentro do painel):**
- Prompt completo enviado ao LLM
- Resposta bruta do LLM
- Reasoning detalhado
- Embeddings gerados (ChromaDB)

---

## ExtraÃ§Ã£o de Conceitos

### Pipeline

```python
def extract_concepts(user_input: str) -> list[Concept]:
    """
    Extrai conceitos-chave do turno atual.
    
    Pipeline:
    1. LLM extrai conceitos (prompt especÃ­fico)
    2. Gera embeddings (sentence-transformers)
    3. Busca similares no catÃ¡logo (ChromaDB)
    4. Deduplica ou cria novo (threshold 0.80)
    5. Salva metadados (SQLite)
    """
    
    # 1. LLM extrai
    concepts_text = llm.invoke(EXTRACT_CONCEPTS_PROMPT.format(input=user_input))
    
    # 2. Para cada conceito
    for concept_label in concepts_text:
        # Gera embedding
        embedding = sentence_transformer.encode(concept_label)
        
        # Busca similares
        similar = chromadb.query(embedding, top_k=3)
        
        # Deduplica ou cria
        if similar and similar[0].similarity > 0.80:
            # Mesmo conceito, adiciona variation
            concept = similar[0]
            concept.variations.append(concept_label)
        else:
            # Conceito novo
            concept = Concept(
                label=concept_label,
                embedding=embedding
            )
            chromadb.save(concept)
            sqlite.save(concept)
    
    return concepts
```

### DeduplicaÃ§Ã£o (Threshold)

- **> 0.80:** Mesmo conceito (adiciona como variation)
- **0.75-0.80:** Zona cinzenta (pergunta ao usuÃ¡rio no futuro)
- **< 0.75:** Conceito diferente (cria novo)

### Exemplo

```
Turno 1: "LLMs aumentam produtividade"
â†’ Detecta: ["LLMs", "Produtividade"]
â†’ Salva ambos no catÃ¡logo

Turno 3: "Language models sÃ£o eficientes"
â†’ Detecta: ["Language models", "EficiÃªncia"]
â†’ "Language models" similar a "LLMs" (0.92)
â†’ Adiciona "Language models" como variation de "LLMs"
â†’ "EficiÃªncia" similar a "Produtividade" (0.85)
â†’ Adiciona "EficiÃªncia" como variation de "Produtividade"

CatÃ¡logo final:
â€¢ LLMs (variations: ["Language models"])
â€¢ Produtividade (variations: ["EficiÃªncia"])
```

---

## IntegraÃ§Ã£o com CognitiveModel

### RelaÃ§Ã£o com Ã‰pico 9 (Snapshots)

**Ã‰pico 9:** Snapshots de Idea (quando argumento amadurece)
**Ã‰pico 10:** Observador processa TODOS os turnos

**Complementaridade:**
- Snapshots = marcos importantes (salva progresso)
- Observador = monitoramento contÃ­nuo (cataloga conceitos)

**Fluxo:**
```
Turno 1-5: Observador cataloga conceitos
Turno 5: Argumento amadurece â†’ Snapshot criado
         â†’ Snapshot referencia conceitos catalogados
Turno 6-10: Observador continua catalogando
Turno 10: Novo snapshot â†’ referencia conceitos novos
```

### AtualizaÃ§Ã£o do Snapshot

```python
# Quando snapshot Ã© criado
def create_snapshot(idea_id: UUID):
    # Pega conceitos detectados pelo Observador
    conceitos = cognitive_model.conceitos
    
    # Associa ao snapshot
    snapshot = Snapshot(
        idea_id=idea_id,
        concept_ids=conceitos,  # ReferÃªncia N:N
        focal_argument=cognitive_model.claims[0],
        solidez=cognitive_model.solidez_geral
    )
    
    db.save(snapshot)
```

---

## Tecnologias

### LLM
- **Modelo:** claude-3-5-haiku-20241022
- **Justificativa:** Custo-efetivo, rÃ¡pido, suficiente para extraÃ§Ã£o
- **Temperature:** 0 (determinÃ­stico)

### ChromaDB
- **Tipo:** Local, persistente
- **Path:** `./data/chroma`
- **Collection:** `concepts`
- **Embedding:** sentence-transformers (all-MiniLM-L6-v2, 384 dim)

### SQLite
- **Tabelas:**
  - `concepts` (id, label, essence, variations JSON, chroma_id)
  - `concept_variations` (concept_id, variation)
  - `idea_concepts` (idea_id, concept_id)

---

## EvoluÃ§Ã£o (Ã‰picos)

### âœ… Ã‰pico 10: Observador - Mente AnalÃ­tica (POC) - COMPLETO
- âœ… **10.1 Mitose do Orquestrador** - IMPLEMENTADO
  - Estrutura `agents/observer/` criada
  - ObservadorAPI com interface de consulta
  - SeparaÃ§Ã£o de responsabilidades documentada
- âœ… **10.2 Processamento via LLM** - IMPLEMENTADO
  - Extratores semÃ¢nticos (claims, concepts, fundamentos, contradictions)
  - MÃ©tricas via LLM (solidez, completude)
  - `process_turn()` + `ObserverProcessor`
  - `CognitiveModelUpdatedEvent` no EventBus
- âœ… **10.3 ChromaDB + SQLite setup** - IMPLEMENTADO
  - ChromaDB persistente com cosine distance (`data/chroma/`)
  - SQLite com tabelas: concepts, concept_variations, idea_concepts
  - Embedding model: all-MiniLM-L6-v2 (384 dim)
  - `ConceptCatalog` com deduplicaÃ§Ã£o automÃ¡tica
- âœ… **10.4 Pipeline de conceitos** - IMPLEMENTADO
  - `persist_concepts()` e `persist_concepts_batch()`
  - IntegraÃ§Ã£o com `process_turn()` via `persist_concepts_flag`
  - Link N:N entre Idea e Concept via `idea_id`
  - ParÃ¢metros opcionais para Agentic RAG (Epic 12)
- âœ… **10.5 Busca semÃ¢ntica** - IMPLEMENTADO
  - `find_similar_concepts()` com threshold configurÃ¡vel
  - Similaridade cosseno ordenada descendente
  - Thresholds: 0.80 (mesmo conceito), 0.90 (auto-variation)
- âœ… **10.6 Testes POC** - IMPLEMENTADO
  - 22 testes unitÃ¡rios em `tests/unit/test_observer.py`
  - Cobertura: ConceptCatalog, Pipeline, Embeddings, DeduplicaÃ§Ã£o
  - Mocks para LLM, vetores fixos para busca semÃ¢ntica
- âŒ NÃƒO integrado ao grafo ainda (chamada manual - Epic 12)

### Ã‰pico 12: Observador Integrado ao Fluxo
- âœ… IntegraÃ§Ã£o ao grafo (paralelo ou callback)
- âœ… Interface de consulta (nÃ£o-determinÃ­stica)
- âœ… VisualizaÃ§Ã£o nos Bastidores (timeline + painel)
- âœ… DetecÃ§Ã£o de variations automÃ¡tica
- âœ… Orquestrador usa insights para decisÃµes

### Ã‰pico 13: CatÃ¡logo de Conceitos (Interface)
- âœ… PÃ¡gina `/catalogo` (busca, filtros, analytics)
- âœ… Preview na pÃ¡gina da ideia
- âœ… NavegaÃ§Ã£o: conceito â†’ ideias â†’ detalhes
- âœ… Export/import de biblioteca

---

## ReferÃªncias

- `docs/architecture/observer_architecture.md` - Arquitetura tÃ©cnica
- `docs/architecture/ontology.md` - CognitiveModel e Conceitos
- `docs/architecture/concept_model.md` - Schema de Concept
- `docs/vision/cognitive_model/core.md` - Fundamentos epistemolÃ³gicos
- `ROADMAP.md` - Ã‰picos 10, 12, 13

---

**VersÃ£o:** 2.2
**Data:** 07/12/2025
**Status:** âœ… Ã‰pico 10 Completo (POC) | PrÃ³ximo: Ã‰pico 12 (IntegraÃ§Ã£o ao Fluxo)

