# Implementa√ß√£o T√©cnica

## Mudan√ßas no C√≥digo

**Arquivo:** `agents/orchestrator/nodes.py`

**Antes:**
```python
def orchestrator_node(state: MultiAgentState, ...):
    # Classifica: vague/semi_formed/complete
    # Roteia automaticamente
```

**Depois:**
```python
def orchestrator_node(state: MultiAgentState, ...):
    # Analisa contexto (input + hist√≥rico)
    # Faz pergunta aberta OU sugere op√ß√µes
    # Negocia com usu√°rio antes de chamar agentes
```

## Estado (MultiAgentState)

**Mant√©m:**
- `user_input`: Input atual do usu√°rio
- `conversation_history`: Hist√≥rico completo
- `messages`: Mensagens LangGraph

**Remove (POC):**
- `orchestrator_classification`: N√£o classifica mais
- `current_stage`: N√£o usa est√°gios fixos

**Adiciona (futuro - Prot√≥tipo/MVP):**
- `orchestrator_suggestions`: Op√ß√µes oferecidas ao usu√°rio
- `user_choices`: Hist√≥rico de decis√µes do usu√°rio

## Prompt do Sistema (ORCHESTRATOR_CONVERSATIONAL_PROMPT_V1)

### Estrutura do Prompt

O prompt do Orquestrador conversacional deve guiar os seguintes comportamentos:

**1. EXPLORA√á√ÉO INICIAL**
- Perguntas abertas para entender inten√ß√£o
- N√£o classificar automaticamente (vague/completo)
- Oferecer op√ß√µes claras

**2. AN√ÅLISE CONTEXTUAL**
- Analisar input + TODO o hist√≥rico da conversa
- Identificar o que est√° claro e o que falta
- Detectar padr√µes: cren√ßa vs observa√ß√£o vs hip√≥tese

**3. CHAMADA AUTOM√ÅTICA DE AGENTE**
- Quando contexto suficiente, CHAMAR o agente automaticamente
- N√£o pedir permiss√£o, agir proativamente
- Decidir qual agente chamar baseado no contexto acumulado

**4. CURADORIA DA RESPOSTA**
- Receber resultado do agente
- Fazer curadoria: apresentar resultado como se fosse voc√™, em tom coeso
- Primeira pessoa: "Organizei...", "Validei...", "Identifiquei..."
- N√ÉO mencionar agente na conversa principal
- Coeso com conversa anterior

**5. CONFIRMA√á√ÉO DE ENTENDIMENTO**
- Confirmar entendimento: "Isso captura o que voc√™ quer?"
- N√ÉO pedir permiss√£o: "Posso chamar agente?" ‚ùå
- Usu√°rio ajusta se necess√°rio, sistema adapta

**6. DETEC√á√ÉO DE MUDAN√áA**
- Comparar novo input com hist√≥rico
- Se detectar contradi√ß√£o ou mudan√ßa de foco, adaptar sem questionar
- Atualizar "argumento focal" impl√≠cito

**7. CONVERSA√á√ÉO NATURAL**
- Linguagem clara e acess√≠vel
- Evitar jarg√µes desnecess√°rios
- Perguntar quantas vezes precisar (sem limite artificial)

### Agentes Dispon√≠veis
- **Estruturador**: transforma ideias vagas em quest√µes estruturadas
- **Metodologista**: valida rigor cient√≠fico
- **Pesquisador**: busca literatura
- **Escritor**: compila artigo

### Output Esperado (JSON)
```json
{
  "reasoning": "An√°lise do contexto e hist√≥rico",
  "next_step": "explore" | "call_agent" | "clarify",
  "message": "Mensagem ao usu√°rio (pergunta ou resultado curado)",
  "agent_call": null | {
    "agent": "nome", 
    "justification": "por que faz sentido"
  }
}
```

**Nota:** `next_step: "call_agent"` significa chamar automaticamente (n√£o sugerir).

### Exemplos de Output

**Exemplo 1: Explora√ß√£o inicial**
```
Input: "Observei que LLMs aumentam produtividade"

Output:
{
  "reasoning": "Usu√°rio tem observa√ß√£o mas n√£o especificou: contexto, m√©tricas, popula√ß√£o. Pode querer testar ou verificar literatura. Preciso explorar inten√ß√£o.",
  "next_step": "explore",
  "message": "Interessante observa√ß√£o! Me conta mais: voc√™ quer VER o que j√° existe sobre isso, ou quer TESTAR uma hip√≥tese sua?",
  "agent_suggestion": null
}
```

**Exemplo 2: Transi√ß√£o fluida para agente**
```
Input hist√≥rico: [conversa sobre hip√≥tese com popula√ß√£o e m√©tricas definidas]
Input: "Sim, quero validar essa hip√≥tese"

Output:
{
  "reasoning": "Usu√°rio definiu hip√≥tese com popula√ß√£o (equipes 2-5 devs) e m√©tricas (tempo por sprint). Estrutura test√°vel. Contexto suficiente. Chamando Metodologista automaticamente.",
  "next_step": "call_agent",
  "message": "Validei sua hip√≥tese: ela atende crit√©rios de testabilidade, falseabilidade e operacionaliza√ß√£o. Isso captura o que voc√™ quer explorar?",
  "agent_call": {
    "agent": "methodologist",
    "justification": "Hip√≥tese estruturada com popula√ß√£o e m√©tricas definidas, pronta para valida√ß√£o metodol√≥gica"
  }
}
[Bastidores: üî¨ Metodologista validou ‚Üí üéØ Orquestrador curou]
```

**Nota:** O `message` √© a resposta curada ap√≥s o agente trabalhar, n√£o uma pergunta de permiss√£o.

**Exemplo 3: Detec√ß√£o de mudan√ßa de dire√ß√£o**
```
Input hist√≥rico: [conversa sobre teste de hip√≥tese em andamento]
Input: "Na verdade, quero fazer revis√£o de literatura"

Output:
{
  "reasoning": "Detecto mudan√ßa de dire√ß√£o: de teste de hip√≥tese para revis√£o de literatura. Usu√°rio mudou de ideia. Adaptar sem questionar. Chamando Estruturador automaticamente para criar quest√£o PICO/SPIDER.",
  "next_step": "call_agent",
  "message": "Sem problema! Vamos adaptar. Organizei uma quest√£o de pesquisa estruturada (PICO/SPIDER) para a revis√£o: [resultado]. Isso direciona bem o que voc√™ quer buscar?",
  "agent_call": {
    "agent": "structurer",
    "justification": "Revis√£o de literatura precisa de quest√£o estruturada. PICO/SPIDER s√£o frameworks adequados."
  }
}
[Bastidores: üìù Estruturador estruturou ‚Üí üéØ Orquestrador curou]
```

### Implementa√ß√£o
- **Localiza√ß√£o futura**: `utils/prompts.py`
- **Constante**: `ORCHESTRATOR_CONVERSATIONAL_PROMPT_V1`
- **Modelo**: Claude Sonnet 4 (para racioc√≠nio complexo)

---

**Pr√≥ximas se√ß√µes:**
- [Exemplos](./examples.md) - Exemplos concretos de implementa√ß√£o
- [Curadoria](./curation.md) - Modelo de curadoria

