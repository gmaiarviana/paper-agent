# Modelo Cognitivo

## Vis√£o Geral

Este documento complementa `vision.md`, focando em **COMO** o pensamento do usu√°rio evolui ao longo da conversa. Enquanto `vision.md` descreve o que o sistema faz e para quem, este documento explora a evolu√ß√£o dos artefatos cognitivos que representam o entendimento progressivo do argumento cient√≠fico.

> **Nota:** Este documento descreve como pensamento **evolui** durante conversa.
> Para estrutura de dados t√©cnica de Argumento, consulte `docs/architecture/argument_model.md`.
> Para ontologia completa (Conceito/Ideia/Argumento), consulte `docs/architecture/ontology.md`.

**Foco**: Evolu√ß√£o cognitiva durante conversa, n√£o apenas funcionalidades ou fluxos.

**Relacionamento:**
- **cognitive_model.md (este doc):** Processo cognitivo (como pensamento evolui)
- **argument_model.md:** Estrutura t√©cnica (como Argumento √© persistido)
- **ontology.md:** Defini√ß√µes filos√≥ficas (o que √© Argumento)
- **epistemology.md:** Base filos√≥fica (proposi√ß√µes, solidez, evid√™ncias)

**Relacionamento com vision.md**:
- `vision.md`: O que √©, para quem, jornada do usu√°rio, tipos de artigo
- `cognitive_model.md`: Como o pensamento evolui, quais artefatos cognitivos s√£o constru√≠dos, como sistema provoca reflex√£o

## Artefatos Cognitivos Expl√≠citos

O sistema mant√©m um modelo expl√≠cito do pensamento do usu√°rio, representado pelos seguintes campos:

### `claim`
**O que √©**: O que o usu√°rio est√° tentando dizer/defender no momento atual.

**Caracter√≠sticas**:
- Evolui a cada turno (pode mudar radicalmente)
- Pode come√ßar vago ("LLMs aumentam produtividade")
- Pode se tornar espec√≠fico ("Claude Code reduz tempo de sprint de 2h para 30min em equipes Python de 2-5 devs")
- N√£o √© fixo: mudan√ßas de dire√ß√£o s√£o naturais

**Exemplo de evolu√ß√£o**:
- Turno 1: "LLMs aumentam produtividade"
- Turno 3: "Claude Code aumenta produtividade em equipes Python"
- Turno 5: "Claude Code reduz tempo de sprint em 30% em equipes de 2-5 devs"

### `claim_history`
**O que √©**: Hist√≥rico de evolu√ß√£o do claim (sistema maduro).

**Caracter√≠sticas**:
- Registra mudan√ßas significativas do claim
- Permite rastreabilidade: "Como chegamos aqui?"
- √ötil para detectar padr√µes de mudan√ßa de dire√ß√£o
- N√£o √© preenchido em vers√µes iniciais do sistema

**Estrutura** (futuro):
```python
claim_history: [
  {
    "turn": 1,
    "claim": "LLMs aumentam produtividade",
    "reason": "Input inicial do usu√°rio"
  },
  {
    "turn": 3,
    "claim": "Claude Code aumenta produtividade em equipes Python",
    "reason": "Usu√°rio especificou ferramenta e contexto"
  },
  {
    "turn": 5,
    "claim": "Claude Code reduz tempo de sprint em 30% em equipes de 2-5 devs",
    "reason": "Usu√°rio forneceu m√©tricas e popula√ß√£o"
  }
]
```

### `fundamentos`
**O que √©**: Proposi√ß√µes que sustentam o argumento, cada uma com sua solidez derivada de evid√™ncias.

**Caracter√≠sticas**:
- Lista de refer√™ncias a Proposi√ß√µes (Proposi√ß√£oRef)
- Come√ßa vazio, preenchido conforme conversa
- Representa fundamentos do argumento
- **N√£o h√° distin√ß√£o entre "premise" e "assumption"**: Todas s√£o proposi√ß√µes com solidez vari√°vel
- **Solidez √© derivada automaticamente**: N√£o √© definida manualmente, mas calculada a partir das evid√™ncias que apoiam cada proposi√ß√£o
- Proposi√ß√µes de baixa solidez (< 0.4) s√£o equivalentes ao que antes eram "assumptions"
- Proposi√ß√µes de alta solidez (> 0.7) s√£o equivalentes ao que antes eram "premises"
- Exemplos: "Equipes Python existem", "Tempo de sprint √© mensur√°vel", "Claude Code √© usado em desenvolvimento"

**Exemplo**:
```python
fundamentos: [
  Proposi√ß√£oRef(
    id="prop-1",
    enunciado="Equipes de desenvolvimento Python usam ferramentas de IA",
    solidez=0.75  # Derivado de evid√™ncias: estudos + exemplos
  ),
  Proposi√ß√£oRef(
    id="prop-2",
    enunciado="Tempo de sprint √© uma m√©trica v√°lida de produtividade",
    solidez=0.65  # Algumas evid√™ncias, mas debate metodol√≥gico
  ),
  Proposi√ß√£oRef(
    id="prop-3",
    enunciado="Redu√ß√£o de tempo n√£o compromete qualidade do c√≥digo",
    solidez=0.35  # Poucas evid√™ncias = proposi√ß√£o fr√°gil (equivalente a "assumption")
  )
]
```

**Importante**: Solidez evolui dinamicamente. Conforme evid√™ncias s√£o adicionadas, a solidez aumenta ou diminui automaticamente. N√£o h√° processo de "virar premissa ap√≥s valida√ß√£o" - h√° "aumentar solidez com evid√™ncias".

### `open_questions`
**O que √©**: O que n√£o sabemos ainda, mas √© relevante para o argumento.

**Caracter√≠sticas**:
- Lacunas identificadas pelo sistema
- Sistema provoca para preencher
- Podem ser respondidas pelo usu√°rio ou pela pesquisa
- Exemplos: "Qual √© o baseline?", "Como medir qualidade?", "Qual √© o tamanho da amostra?"

**Exemplo**:
```python
open_questions: [
  "Qual √© o baseline de tempo de sprint sem Claude Code?",
  "Como medir qualidade do c√≥digo al√©m de tempo?",
  "Qual √© o tamanho da amostra necess√°ria para generaliza√ß√£o?"
]
```

### `contradictions`
**O que √©**: Conflitos entre proposi√ß√µes detectados pelo sistema.

**Caracter√≠sticas**:
- N√£o determin√≠stico: LLM julga confian√ßa (confidence > 80% ‚Üí menciona)
- Sistema menciona de forma natural, n√£o bloqueia
- **N√£o h√° "isso est√° errado"**: H√° "estas proposi√ß√µes parecem em tens√£o"
- Sistema mapeia contextos que geram cada perspectiva
- Exemplos: "Proposi√ß√£o sobre aumento de produtividade vs. proposi√ß√£o sobre aumento de bugs", "Proposi√ß√£o sobre popula√ß√£o espec√≠fica vs. proposi√ß√£o sobre generaliza√ß√£o"

**Exemplo**:
```python
contradictions: [
  {
    "description": "Proposi√ß√£o 'Claude Code aumenta produtividade' parece em tens√£o com proposi√ß√£o 'Claude Code aumenta bugs'",
    "proposicoes_envolvidas": ["prop-1", "prop-4"],
    "confidence": 0.85,
    "contextos": {
      "prop-1": "Contexto: m√©tricas de tempo de sprint",
      "prop-4": "Contexto: m√©tricas de qualidade de c√≥digo"
    },
    "suggested_resolution": "Produtividade pode incluir qualidade? Ou s√£o m√©tricas separadas? Como mapear contextos onde cada proposi√ß√£o se aplica?"
  }
]
```

### `evid√™ncias`
**O que √©**: Evid√™ncias que apoiam ou refutam as proposi√ß√µes dos fundamentos.

**Caracter√≠sticas**:
- Preenchido pelo Pesquisador ap√≥s busca bibliogr√°fica
- Representa evid√™ncia encontrada na literatura ou fornecida pelo usu√°rio
- **Vinculadas a proposi√ß√µes**: Cada evid√™ncia apoia ou refuta proposi√ß√µes espec√≠ficas
- **Afetam solidez automaticamente**: Quando evid√™ncias s√£o adicionadas, a solidez das proposi√ß√µes relacionadas √© recalculada
- Diferencia argumento de opini√£o vs. argumento fundamentado
- Exemplos: "Estudo X mostra que...", "Meta-an√°lise Y confirma que...", "Experi√™ncia pessoal indica que..."

**Exemplo** (ap√≥s pesquisa):
```python
evid√™ncias: [
  {
    "id": "evid-1",
    "descricao": "Smith et al. (2023) encontraram redu√ß√£o de 25-40% em tempo de tarefa",
    "fonte": "doi:10.1234/example",
    "forca": "forte",
    "tipo": "estudo",
    "apoia": ["prop-1"],  # Apoia proposi√ß√£o sobre produtividade
    "refuta": []
  },
  {
    "id": "evid-2",
    "descricao": "Experi√™ncia pessoal: aumento de bugs em 15% dos casos",
    "fonte": "conversa com usu√°rio",
    "forca": "fraca",
    "tipo": "experi√™ncia",
    "apoia": [],
    "refuta": ["prop-3"]  # Refuta proposi√ß√£o sobre qualidade n√£o comprometida
  }
]
# Ap√≥s adicionar evid√™ncias, solidez de prop-1 aumenta, solidez de prop-3 diminui
```

### `context`
**O que √©**: Dom√≠nio, tecnologia, popula√ß√£o inferidos pelo sistema.

**Caracter√≠sticas**:
- Inferido pelo Orquestrador a partir da conversa
- Evolui conforme usu√°rio fornece mais informa√ß√£o
- Exemplos: dom√≠nio="desenvolvimento de software", tecnologia="Python + Claude Code", popula√ß√£o="equipes de 2-5 devs"

**Exemplo**:
```python
context: {
  "domain": "software development",
  "technology": "Python, Claude Code",
  "population": "teams of 2-5 developers",
  "metrics": "time per sprint",
  "article_type": "empirical"
}
```

## Evolu√ß√£o do Modelo

### Campos Come√ßam Vazios

No in√≠cio da conversa, a maioria dos campos est√° vazia ou com valores gen√©ricos:

```python
# Turno 1 (in√≠cio)
claim: "LLMs aumentam produtividade"  # vago
fundamentos: []  # Ainda sem proposi√ß√µes identificadas
open_questions: []
contradictions: []
evid√™ncias: []  # Ainda sem evid√™ncias
context: {
  "domain": "unclear",
  "technology": "unclear",
  "population": "not specified"
}
```

### Preenchimento Progressivo

Conforme a conversa evolui, campos s√£o preenchidos:

```python
# Turno 3
claim: "Claude Code aumenta produtividade em equipes Python"
fundamentos: [
  Proposi√ß√£oRef(
    id="prop-1",
    enunciado="Equipes Python existem",
    solidez=0.90  # Alta solidez: evid√™ncia direta da conversa
  ),
  Proposi√ß√£oRef(
    id="prop-2",
    enunciado="Claude Code √© usado em desenvolvimento",
    solidez=0.85  # Alta solidez: evid√™ncia direta
  ),
  Proposi√ß√£oRef(
    id="prop-3",
    enunciado="Produtividade √© mensur√°vel",
    solidez=0.50  # Solidez m√©dia: algumas evid√™ncias, mas debate metodol√≥gico
  ),
  Proposi√ß√£oRef(
    id="prop-4",
    enunciado="Resultado √© generaliz√°vel",
    solidez=0.30  # Baixa solidez: poucas evid√™ncias (equivalente a "assumption")
  )
]
open_questions: ["Como medir produtividade?", "Qual √© o baseline?"]
evid√™ncias: []  # Ainda sem evid√™ncias bibliogr√°ficas
context: {
  "domain": "software development",
  "technology": "Python, Claude Code",
  "population": "not specified"
}
```

### Claim Pode Mudar Radicalmente

Mudan√ßas de dire√ß√£o s√£o naturais e o sistema adapta:

```python
# Turno 5: Mudan√ßa de dire√ß√£o
claim: "Quero fazer revis√£o de literatura sobre LLMs e produtividade"
# Claim anterior abandonado, n√£o mesclado
fundamentos: []  # Resetado para novo contexto
open_questions: ["Qual √© o estado da arte?", "Quais s√£o as lacunas na literatura?"]
evid√™ncias: []  # Resetado para novo contexto
context: {
  "domain": "software development",
  "technology": "LLMs, code assistants",
  "population": "not applicable for literature review",
  "article_type": "review"
}
```

### Sistema Provoca para Preencher Lacunas

O sistema identifica lacunas e provoca reflex√£o:

- **Lacuna detectada**: `open_questions` tem itens n√£o respondidos
- **A√ß√£o**: Sistema pergunta: "Voc√™ mencionou produtividade, mas e QUALIDADE do c√≥digo? Isso importa para sua pesquisa?"
- **Resultado**: Usu√°rio responde ‚Üí novas proposi√ß√µes adicionadas a `fundamentos` (com solidez inicial baixa se n√£o houver evid√™ncias)

### Solidez Aumenta com Evid√™ncias

Conforme evid√™ncias s√£o adicionadas, a solidez das proposi√ß√µes aumenta dinamicamente:

```python
# Estado inicial: proposi√ß√£o com baixa solidez (poucas evid√™ncias)
fundamentos: [
  Proposi√ß√£oRef(
    id="prop-3",
    enunciado="Redu√ß√£o de tempo n√£o compromete qualidade",
    solidez=0.25  # Baixa: apenas infer√™ncia do usu√°rio
  )
]

# Ap√≥s Pesquisador adicionar evid√™ncias bibliogr√°ficas
evid√™ncias: [
  {
    "id": "evid-5",
    "descricao": "Meta-an√°lise de 15 estudos mostra correla√ß√£o positiva entre uso de IA e qualidade",
    "fonte": "doi:10.5678/example",
    "forca": "forte",
    "tipo": "estudo",
    "apoia": ["prop-3"]
  }
]

# Solidez recalculada automaticamente
fundamentos: [
  Proposi√ß√£oRef(
    id="prop-3",
    enunciado="Redu√ß√£o de tempo n√£o compromete qualidade",
    solidez=0.70  # Aumentou: evid√™ncia forte adicionada
  )
]
```

**Importante**: N√£o h√° processo de "virar premissa ap√≥s valida√ß√£o". H√° evolu√ß√£o cont√≠nua de solidez conforme evid√™ncias s√£o acumuladas.

## Responsabilidades (Quem Atualiza Cada Campo)

| Campo | Respons√°vel | Quando Atualiza |
|-------|-------------|-----------------|
| `claim` | Orquestrador | Extrai a cada turno da conversa |
| `claim_history` | Orquestrador | Quando claim muda significativamente (sistema maduro) |
| `fundamentos` | Estruturador | Identifica proposi√ß√µes que sustentam o argumento |
| `solidez` (de cada fundamento) | Sistema | Derivado automaticamente de evid√™ncias |
| `evid√™ncias` | Pesquisador | Ap√≥s busca bibliogr√°fica ou fornecida pelo usu√°rio |
| `open_questions` | Orquestrador + Metodologista | Identifica lacunas |
| `contradictions` | Metodologista | Detecta conflitos entre proposi√ß√µes |
| `context` | Orquestrador | Infere dom√≠nio, tecnologia, popula√ß√£o da conversa |

### Detalhamento das Responsabilidades

**Orquestrador**:
- Extrai `claim` a cada turno analisando input + hist√≥rico
- Atualiza `claim_history` quando detecta mudan√ßa significativa
- Identifica `open_questions` quando detecta lacunas
- Infere `context` a partir de men√ß√µes na conversa

**Estruturador**:
- Identifica proposi√ß√µes que sustentam o argumento e adiciona a `fundamentos`
- Organiza fundamentos l√≥gicos do argumento
- Pode sugerir `open_questions` quando estrutura quest√£o de pesquisa

**Metodologista**:
- Detecta `contradictions` (conflitos entre proposi√ß√µes)
- Pode identificar `open_questions` relacionadas a rigor cient√≠fico
- Sugere refinamentos que podem resultar em novas proposi√ß√µes em `fundamentos`

**Pesquisador**:
- Adiciona `evid√™ncias` ap√≥s busca bibliogr√°fica
- Evid√™ncias s√£o vinculadas a proposi√ß√µes espec√≠ficas
- **N√£o valida/refuta**: Fortalece ou enfraquece proposi√ß√µes atrav√©s de evid√™ncias
- Pode identificar novas `open_questions` baseadas em lacunas da literatura

**Sistema** (autom√°tico):
- Calcula `solidez` de cada proposi√ß√£o em `fundamentos` baseado nas evid√™ncias que a apoiam/refutam
- Recalcula solidez dinamicamente quando novas evid√™ncias s√£o adicionadas

## Conex√£o com Argumento (Entidade T√©cnica)

> **Nota:** Para schema completo de Argument, consulte `docs/architecture/argument_model.md`.

O modelo cognitivo descrito aqui √© materializado tecnicamente como entidade `Argument`:
```python
# Durante conversa (em mem√≥ria)
cognitive_model = {
  "claim": "...",
  "fundamentos": [...],  # Lista de Proposi√ß√£oRef
  "open_questions": [...],
  "contradictions": [...],
  "evid√™ncias": [...]  # Lista de Evid√™ncia
}

# Ao persistir (banco de dados)
argument = Argument(
  id=UUID,
  idea_id=UUID,
  claim=cognitive_model["claim"],
  fundamentos=cognitive_model["fundamentos"],  # Refer√™ncias a Proposi√ß√µes
  evidencias=cognitive_model["evid√™ncias"]  # Refer√™ncias a Evid√™ncias
)
```

**Diferen√ßa:**
- **cognitive_model:** Estado vol√°til durante conversa
- **Argument:** Entidade persistida no banco

Uma **Ideia** pode ter m√∫ltiplos **Argumentos** (diferentes lentes do mesmo territ√≥rio).

## Dial√©tica: Provoca√ß√£o + Estrutura√ß√£o

O sistema opera em um ciclo dial√©tico: **provoca√ß√£o** (identificar lacunas) + **estrutura√ß√£o** (organizar ideias).

### Detec√ß√£o Autom√°tica de Lacunas

**Op√ß√£o A: LLM Analisa e Sugere** (implementa√ß√£o atual)
- Orquestrador analisa conversa e identifica lacunas
- Gera `reflection_prompt` quando detecta aspecto n√£o explorado
- Exemplo: "Voc√™ mencionou produtividade, mas e QUALIDADE do c√≥digo? Isso importa para sua pesquisa?"

**Op√ß√£o B: Regras Determin√≠sticas** (futuro, se necess√°rio)
- Regras baseadas em tipo de artigo
- Exemplo: Artigo emp√≠rico requer popula√ß√£o + m√©tricas + baseline

### Estruturador Proativo Quando Contexto Claro

Quando contexto est√° claro o suficiente, Estruturador pode ser proativo:
- Sistema detecta: `claim` espec√≠fico + `context` completo
- Sugere: "Posso chamar o Estruturador para organizar essa ideia em uma quest√£o de pesquisa estruturada?"
- Usu√°rio aprova ‚Üí Estruturador identifica proposi√ß√µes e adiciona a `fundamentos`

### Fortalecimento/Enfraquecimento com Evid√™ncias

**Sistema n√£o valida proposi√ß√µes**: Em vez de validar/refutar, o sistema fortalece ou enfraquece proposi√ß√µes atrav√©s de evid√™ncias:
- Pesquisador adiciona evid√™ncias que apoiam ou refutam proposi√ß√µes
- Solidez √© recalculada automaticamente
- Sistema alerta sobre fragilidades: "3 proposi√ß√µes t√™m solidez < 0.4"
- Pesquisador abre conversa sobre evid√™ncias, n√£o retorna veredicto bin√°rio

### A√ß√µes Baratas vs. Caras

**A√ß√µes Baratas (Proativas)**:
- Organizar ideias (Estruturador)
- Detectar lacunas (Orquestrador)
- Validar l√≥gica (Metodologista)
- Sistema pode sugerir sem pedir permiss√£o expl√≠cita

**A√ß√µes Caras (Pedir Permiss√£o)**:
- Pesquisar literatura (Pesquisador - custo de API + tempo)
- Gerar rascunho completo (Escritor - custo alto)
- Sistema sempre pede permiss√£o antes de executar

## Detec√ß√£o de Contradi√ß√µes (N√£o Determin√≠stico)

### Processo de Detec√ß√£o

1. **Metodologista analisa argumento**:
   - Compara proposi√ß√µes em `fundamentos`
   - Identifica conflitos entre proposi√ß√µes
   - Mapeia contextos que geram cada perspectiva
   - Calcula confian√ßa (0-1)

2. **Se confidence > 80%**:
   - Sistema menciona conflito de forma natural
   - N√£o bloqueia ou imp√µe
   - Apenas provoca reflex√£o
   - **N√£o diz "isso est√° errado"**: Diz "estas proposi√ß√µes parecem em tens√£o"

3. **Formato da men√ß√£o**:
   - Conversacional, n√£o acusat√≥rio
   - Mapeia contextos: "A proposi√ß√£o X se aplica no contexto A, enquanto a proposi√ß√£o Y se aplica no contexto B"
   - Exemplo: "Notei que a proposi√ß√£o sobre aumento de produtividade parece em tens√£o com a proposi√ß√£o sobre aumento de bugs. Como voc√™ v√™ essa rela√ß√£o? S√£o m√©tricas separadas ou produtividade inclui qualidade? Em que contextos cada proposi√ß√£o se aplica?"

### Exemplo de Contradi√ß√£o Detectada

```python
# Estado atual
claim: "Claude Code aumenta produtividade em 30%"
fundamentos: [
  Proposi√ß√£oRef(id="prop-1", enunciado="Produtividade √© medida por tempo de sprint", solidez=0.70),
  Proposi√ß√£oRef(id="prop-2", enunciado="Qualidade n√£o √© afetada", solidez=0.35)
]

# Metodologista detecta
contradictions: [
  {
    "description": "Proposi√ß√£o 'Claude Code aumenta produtividade' parece em tens√£o com proposi√ß√£o 'Claude Code aumenta bugs'",
    "proposicoes_envolvidas": ["prop-1", "prop-3"],
    "confidence": 0.85,
    "contextos": {
      "prop-1": "Contexto: m√©tricas de tempo de sprint",
      "prop-3": "Contexto: m√©tricas de qualidade de c√≥digo (bugs)"
    },
    "suggested_resolution": "Produtividade pode incluir qualidade? Ou s√£o m√©tricas separadas? Como mapear contextos onde cada proposi√ß√£o se aplica?"
  }
]

# Sistema menciona (n√£o bloqueia)
"Notei que a proposi√ß√£o sobre aumento de produtividade parece em tens√£o com a proposi√ß√£o sobre aumento de bugs. Como voc√™ v√™ essa rela√ß√£o? S√£o m√©tricas separadas ou produtividade inclui qualidade?"
```

## Objetivo Final: "Flecha Penetrante"

O objetivo do sistema √© ajudar o usu√°rio a construir um **argumento s√≥lido com respaldo bibliogr√°fico**, sem premissas fr√°geis, sem d√∫vidas n√£o examinadas. A clareza emerge da elabora√ß√£o.

### Caracter√≠sticas do Argumento Maduro

- **`claim` est√°vel e espec√≠fico**: N√£o muda radicalmente a cada turno
- **`fundamentos` com solidez m√©dia-alta**: Proposi√ß√µes principais com solidez > 0.6
- **Evid√™ncias suficientes**: Fundamentos principais t√™m evid√™ncias que os sustentam
- **`open_questions` respondidas**: Lacunas foram exploradas
- **`contradictions` resolvidas**: Tens√µes entre proposi√ß√µes foram endere√ßadas
- **`evid√™ncias` presente**: Evid√™ncia bibliogr√°fica encontrada e vinculada a proposi√ß√µes

### Exemplo de Argumento Maduro

```python
claim: "Claude Code reduz tempo de sprint em 30% (de 2h para 1.4h) em equipes Python de 2-5 devs, sem comprometer qualidade do c√≥digo (medida por bugs por sprint)"

fundamentos: [
  Proposi√ß√£oRef(
    id="prop-1",
    enunciado="Equipes Python de 2-5 devs existem e s√£o representativas",
    solidez=0.85  # Alta: evid√™ncia direta da conversa
  ),
  Proposi√ß√£oRef(
    id="prop-2",
    enunciado="Tempo de sprint √© m√©trica v√°lida de produtividade",
    solidez=0.75  # Alta: evid√™ncias bibliogr√°ficas
  ),
  Proposi√ß√£oRef(
    id="prop-3",
    enunciado="Bugs por sprint √© m√©trica v√°lida de qualidade",
    solidez=0.70  # Alta: evid√™ncias bibliogr√°ficas
  ),
  Proposi√ß√£oRef(
    id="prop-4",
    enunciado="Redu√ß√£o de tempo n√£o compromete qualidade",
    solidez=0.75  # Alta: evid√™ncias bibliogr√°ficas + dados do usu√°rio
  ),
  Proposi√ß√£oRef(
    id="prop-5",
    enunciado="Resultado √© generaliz√°vel para outras linguagens",
    solidez=0.40  # M√©dia-baixa: poucas evid√™ncias (hip√≥tese a testar)
  )
]

open_questions: []  # Todas respondidas

contradictions: []  # Nenhuma detectada

evid√™ncias: [
  {
    "id": "evid-1",
    "descricao": "Smith et al. (2023) encontraram redu√ß√£o de 25-40% em tempo de tarefa",
    "fonte": "doi:10.1234/example",
    "forca": "forte",
    "tipo": "estudo",
    "apoia": ["prop-2", "prop-4"]
  },
  {
    "id": "evid-2",
    "descricao": "Meta-an√°lise de 15 estudos mostra correla√ß√£o positiva entre uso de IA e qualidade",
    "fonte": "doi:10.5678/example",
    "forca": "forte",
    "tipo": "estudo",
    "apoia": ["prop-4"]
  }
]

context: {
  "domain": "software development",
  "technology": "Python, Claude Code",
  "population": "teams of 2-5 developers",
  "metrics": "time per sprint, bugs per sprint",
  "article_type": "empirical"
}
```

## Indicadores de Maturidade (Internos)

Os indicadores de maturidade s√£o **n√£o determin√≠sticos** e **n√£o avisam o usu√°rio diretamente**. O sistema usa para sugerir pr√≥ximos passos, n√£o para impor.

### Sinais de Maturidade

1. **`claim` est√°vel**: N√£o muda significativamente por 3+ turnos
2. **Fundamentos com solidez m√©dia-alta**: Proposi√ß√µes principais com solidez > 0.6
3. **Evid√™ncias suficientes**: Fundamentos principais t√™m evid√™ncias que os sustentam
4. **`open_questions` respondidas**: Lista vazia ou apenas quest√µes secund√°rias
5. **`contradictions` resolvidas**: Nenhum conflito entre proposi√ß√µes detectado
6. **`evid√™ncias` presente**: Evid√™ncia bibliogr√°fica encontrada e vinculada a proposi√ß√µes (quando aplic√°vel)

### Como Sistema Usa Indicadores

Sistema n√£o diz: "Seu argumento est√° maduro!"  
Sistema apresenta resultado: "Validei o rigor cient√≠fico: [resultado]. Faz sentido?" ou "Temos uma boa base. Para compilar o artigo completo, preciso fazer chamadas de API que podem ter custo. Quer que eu chame o Escritor agora?"

**Exemplo de sugest√£o baseada em maturidade**:
```python
# Sistema detecta maturidade
claim_stable: True
fundamentos_solidos: True  # Proposi√ß√µes principais com solidez > 0.6
evidencias_suficientes: True  # Fundamentos principais t√™m evid√™ncias
open_questions_empty: True
contradictions_resolved: True

# Sistema sugere (n√£o imp√µe)
"Parece que temos uma hip√≥tese bem estruturada. Quer validar rigor cient√≠fico com o Metodologista?"
```

## Exemplo Completo: "Levantamento de Obra com IA"

### Turno 1: Claim Vago, Assumptions Detectadas

**Input do usu√°rio**: "Quero fazer um artigo sobre levantamento de obra com IA"

**Estado cognitivo**:
```python
claim: "Artigo sobre levantamento de obra com IA"
fundamentos: [
  Proposi√ß√£oRef(
    id="prop-1",
    enunciado="Levantamento de obra √© um problema relevante",
    solidez=0.30  # Baixa: apenas infer√™ncia inicial
  ),
  Proposi√ß√£oRef(
    id="prop-2",
    enunciado="IA pode ajudar em levantamento de obra",
    solidez=0.25  # Baixa: hip√≥tese inicial
  ),
  Proposi√ß√£oRef(
    id="prop-3",
    enunciado="H√° contribui√ß√£o acad√™mica poss√≠vel",
    solidez=0.20  # Muito baixa: hip√≥tese n√£o explorada
  )
]
open_questions: [
  "O que √© levantamento de obra?",
  "Como IA pode ajudar?",
  "Qual √© o problema espec√≠fico?",
  "Qual tipo de artigo? (emp√≠rico, revis√£o, te√≥rico)"
]
contradictions: []
evid√™ncias: []
context: {
  "domain": "construction",
  "technology": "AI (unclear which)",
  "population": "not specified",
  "article_type": "unclear"
}
```

**A√ß√£o do sistema**: Orquestrador explora contexto
- "Interessante! Me conta mais: o que √© levantamento de obra para voc√™? E como voc√™ imagina que IA pode ajudar?"

### Turno 3: Claim Muda, Fundamentos Adicionados, Sistema Provoca

**Input do usu√°rio**: "Levantamento de obra √© medir quantidades de materiais. Quero usar vis√£o computacional para automatizar"

**Estado cognitivo**:
```python
claim: "Usar vis√£o computacional para automatizar levantamento de quantidades de materiais em obras"
fundamentos: [
  Proposi√ß√£oRef(
    id="prop-4",
    enunciado="Levantamento de obra envolve medir quantidades de materiais",
    solidez=0.70  # M√©dia-alta: evid√™ncia direta da conversa
  ),
  Proposi√ß√£oRef(
    id="prop-5",
    enunciado="Vis√£o computacional pode identificar materiais em imagens",
    solidez=0.60  # M√©dia: conhecimento t√©cnico geral
  ),
  Proposi√ß√£oRef(
    id="prop-6",
    enunciado="Automatiza√ß√£o √© desej√°vel",
    solidez=0.50  # M√©dia: infer√™ncia do contexto
  ),
  Proposi√ß√£oRef(
    id="prop-7",
    enunciado="Vis√£o computacional √© precisa o suficiente para quantificar materiais",
    solidez=0.35  # Baixa: hip√≥tese n√£o verificada
  ),
  Proposi√ß√£oRef(
    id="prop-8",
    enunciado="Automatiza√ß√£o reduz tempo/custo sem comprometer precis√£o",
    solidez=0.30  # Baixa: hip√≥tese n√£o verificada
  ),
  Proposi√ß√£oRef(
    id="prop-9",
    enunciado="H√° contribui√ß√£o acad√™mica (n√£o √© apenas aplica√ß√£o direta)",
    solidez=0.25  # Baixa: hip√≥tese n√£o explorada
  )
]
open_questions: [
  "Qual √© a precis√£o atual de m√©todos manuais?",
  "Qual √© o baseline de tempo/custo?",
  "Como validar precis√£o da IA?",
  "Qual tipo de materiais? (tijolos, concreto, etc.)"
]
contradictions: []
evid√™ncias: []
context: {
  "domain": "construction, quantity surveying",
  "technology": "computer vision, AI",
  "population": "not specified",
  "article_type": "unclear"  # Pode ser emp√≠rico (testar) ou metodol√≥gico (validar m√©todo)
}
```

**A√ß√£o do sistema**: Orquestrador provoca reflex√£o
- "Voc√™ mencionou automatiza√ß√£o, mas e a PRECIS√ÉO? Como voc√™ validaria que a IA √© t√£o precisa quanto m√©todos manuais?"

### Turno 5: Pesquisador Busca, Evid√™ncias Adicionadas, Modelo Amadurece

**Input do usu√°rio**: "Quero testar se vis√£o computacional √© mais r√°pida e precisa que m√©todos manuais"

**Estado cognitivo** (ap√≥s Pesquisador buscar literatura):
```python
claim: "Vis√£o computacional √© mais r√°pida e precisa que m√©todos manuais para levantamento de quantidades de materiais em obras"
fundamentos: [
  Proposi√ß√£oRef(
    id="prop-4",
    enunciado="Levantamento de obra envolve medir quantidades de materiais",
    solidez=0.70  # Mantida: evid√™ncia direta
  ),
  Proposi√ß√£oRef(
    id="prop-5",
    enunciado="Vis√£o computacional pode identificar materiais em imagens",
    solidez=0.75  # Aumentou: evid√™ncia bibliogr√°fica adicionada
  ),
  Proposi√ß√£oRef(
    id="prop-10",
    enunciado="M√©todos manuais existem e t√™m precis√£o conhecida",
    solidez=0.80  # Alta: evid√™ncia bibliogr√°fica forte
  ),
  Proposi√ß√£oRef(
    id="prop-11",
    enunciado="Compara√ß√£o de m√©todos √© v√°lida academicamente",
    solidez=0.70  # M√©dia-alta: padr√£o metodol√≥gico
  ),
  Proposi√ß√£oRef(
    id="prop-7",
    enunciado="Vis√£o computacional √© precisa o suficiente para quantificar materiais",
    solidez=0.65  # Aumentou: evid√™ncia bibliogr√°fica (85% precis√£o)
  ),
  Proposi√ß√£oRef(
    id="prop-12",
    enunciado="Resultado √© generaliz√°vel para diferentes tipos de obras",
    solidez=0.40  # M√©dia-baixa: poucas evid√™ncias
  ),
  Proposi√ß√£oRef(
    id="prop-13",
    enunciado="Precis√£o da IA √© suficiente para uso pr√°tico",
    solidez=0.60  # M√©dia: evid√™ncia parcial (85% √© alto, mas contexto espec√≠fico)
  )
]
open_questions: [
  "Qual √© o tamanho da amostra necess√°ria?",
  "Como definir 'mais preciso'? (margem de erro aceit√°vel?)",
  "Quais tipos de materiais testar? (tijolos, concreto, a√ßo?)"
]
contradictions: []
evid√™ncias: [
  {
    "id": "evid-3",
    "descricao": "Zhang et al. (2022) aplicaram YOLO para detec√ß√£o de materiais com 85% de precis√£o",
    "fonte": "doi:10.1234/construction-ai",
    "forca": "forte",
    "tipo": "estudo",
    "apoia": ["prop-5", "prop-7", "prop-13"]
  },
  {
    "id": "evid-4",
    "descricao": "Revis√£o sistem√°tica de 20 estudos mostra erro m√©dio de 7.5% em levantamentos manuais",
    "fonte": "doi:10.5678/manual-survey",
    "forca": "forte",
    "tipo": "estudo",
    "apoia": ["prop-10"]
  }
]
# Solidez de prop-5, prop-7 e prop-13 aumentou ap√≥s adicionar evid-3
# Solidez de prop-10 aumentou ap√≥s adicionar evid-4
context: {
  "domain": "construction, quantity surveying",
  "technology": "computer vision, YOLO, deep learning",
  "population": "construction projects (not specified: residential, commercial, etc.)",
  "metrics": "speed (time), accuracy (error margin)",
  "article_type": "empirical"  # Agora claro: quer testar hip√≥tese
}
```

**A√ß√£o do sistema**: Orquestrador apresenta resultado
- "Temos uma boa base! Encontrei estudos relevantes. Validei o desenho experimental dessa compara√ß√£o: [resultado]. Faz sentido?"
[Bastidores: üî¨ Metodologista validou ‚Üí üéØ Orquestrador curou]

### Turno 7: Modelo Maduro, Pronto para Estrutura√ß√£o

**Estado cognitivo** (ap√≥s Metodologista validar):
```python
claim: "Vis√£o computacional (YOLO) √© mais r√°pida (redu√ß√£o de 60% no tempo) e mais precisa (erro de 3% vs 7.5% manual) que m√©todos manuais para levantamento de quantidades de tijolos em obras residenciais"

fundamentos: [
  Proposi√ß√£oRef(
    id="prop-4",
    enunciado="Levantamento de obra envolve medir quantidades de materiais",
    solidez=0.70  # Mantida
  ),
  Proposi√ß√£oRef(
    id="prop-14",
    enunciado="Vis√£o computacional (YOLO) pode identificar tijolos em imagens",
    solidez=0.80  # Alta: evid√™ncias + valida√ß√£o metodol√≥gica
  ),
  Proposi√ß√£oRef(
    id="prop-10",
    enunciado="M√©todos manuais t√™m erro m√©dio de 7.5%",
    solidez=0.80  # Alta: evid√™ncia bibliogr√°fica forte
  ),
  Proposi√ß√£oRef(
    id="prop-11",
    enunciado="Compara√ß√£o experimental √© v√°lida academicamente",
    solidez=0.75  # Alta: valida√ß√£o metodol√≥gica
  ),
  Proposi√ß√£oRef(
    id="prop-15",
    enunciado="Obras residenciais s√£o contexto representativo",
    solidez=0.65  # M√©dia-alta: justificativa metodol√≥gica
  ),
  Proposi√ß√£oRef(
    id="prop-16",
    enunciado="Resultado √© generaliz√°vel para outros materiais",
    solidez=0.35  # Baixa: hip√≥tese futura, poucas evid√™ncias
  )
]

open_questions: []  # Todas respondidas

contradictions: []  # Nenhuma detectada

evid√™ncias: [
  # ... (mesmo do turno 5, mais evid√™ncias adicionadas)
]

context: {
  "domain": "construction, quantity surveying",
  "technology": "computer vision, YOLO, deep learning",
  "population": "residential construction projects",
  "metrics": "speed (time reduction %), accuracy (error margin %)",
  "article_type": "empirical"
}
```

**A√ß√£o do sistema**: Apresenta√ß√£o de resultado
- "Hip√≥tese validada! Organizei em uma quest√£o de pesquisa estruturada: [resultado]. Podemos seguir com: 1) definir desenho experimental, 2) pesquisar literatura, ou 3) algo diferente?"
[Bastidores: üìù Estruturador estruturou ‚Üí üéØ Orquestrador curou]

## Persist√™ncia Silenciosa (Snapshots)

O sistema mant√©m uma estrat√©gia de **persist√™ncia silenciosa** que captura o progresso do pensamento do usu√°rio sem interromper o fluxo conversacional. A cada mensagem, o sistema avalia se o `CognitiveModel` contribuiu com algo novo e, caso positivo, cria ou atualiza um snapshot automaticamente.

### O que √© um Snapshot

Um **snapshot** √© a persist√™ncia do `CognitiveModel` quando ele contribui com algo novo ao argumento em constru√ß√£o. Representa um ponto de salvamento do progresso cognitivo, permitindo que o usu√°rio retome a conversa de onde parou sem perder evolu√ß√£o significativa.

**Caracter√≠sticas**:
- **Persist√™ncia autom√°tica**: Sistema avalia e decide criar snapshot sem interven√ß√£o do usu√°rio
- **Versionamento autom√°tico**: Cada snapshot recebe vers√£o incremental (V1, V2, V3...)
- **Silencioso**: Usu√°rio n√£o v√™ notifica√ß√£o ou interrup√ß√£o no fluxo conversacional
- **Materializa√ß√£o**: Snapshot vira entidade `Argument` no banco de dados

### Avalia√ß√£o Cont√≠nua

A cada mensagem do usu√°rio, o sistema avalia se deve criar ou atualizar snapshot:

```python
# Fluxo de avalia√ß√£o (a cada turno)
1. Usu√°rio envia mensagem
2. Sistema atualiza CognitiveModel (claim, fundamentos, etc.)
3. Sistema avalia maturidade do modelo:
   - CognitiveModel contribuiu com algo novo?
   - Argumento atingiu maturidade suficiente?
   - H√° crit√©rios que impedem snapshot?
4. Se avalia√ß√£o positiva ‚Üí cria/atualiza snapshot silenciosamente
```

### Crit√©rios para N√ÉO Atualizar Snapshot

O sistema **n√£o cria ou atualiza** snapshot quando detecta:

1. **Usu√°rio fugiu do assunto**:
   - Mudan√ßa radical de t√≥pico n√£o relacionada ao argumento atual
   - Claim muda para √°rea completamente diferente
   - Contexto n√£o relacionado ao progresso cognitivo anterior

2. **Repetiu sem novidade**:
   - Mesma informa√ß√£o j√° capturada em snapshot anterior
   - Reafirma√ß√£o sem novos detalhes ou refinamentos
   - `claim` id√™ntico ao snapshot mais recente

3. **Pergunta sem contribui√ß√£o**:
   - Perguntas que n√£o agregam ao argumento em constru√ß√£o
   - D√∫vidas que n√£o levam a evolu√ß√£o do pensamento
   - Explora√ß√£o que n√£o resulta em novos `fundamentos` ou refinamento de `claim`

**Exemplo de avalia√ß√£o**:
```python
# Turno anterior: Snapshot V2 criado
cognitive_model.claim = "LLMs aumentam produtividade em equipes Python"

# Turno atual: Usu√°rio pergunta sem agregar
user_input = "Como funciona Python?"
# Sistema avalia: n√£o h√° novidade ao argumento ‚Üí n√£o cria snapshot

# Turno seguinte: Usu√°rio refina claim
user_input = "Especificamente, Claude Code reduz tempo de sprint em 30%"
cognitive_model.claim = "Claude Code reduz tempo de sprint em 30% em equipes Python"
# Sistema avalia: contribui√ß√£o nova ‚Üí cria Snapshot V3
```

### Sil√™ncio no Fluxo Conversacional

Snapshots s√£o **completamente silenciosos** do ponto de vista do usu√°rio:

- **Sem notifica√ß√µes**: Usu√°rio n√£o √© informado quando snapshot √© criado
- **Sem interrup√ß√µes**: Fluxo conversacional continua normalmente
- **Sem confirma√ß√µes**: Sistema n√£o pede permiss√£o para persistir
- **Transparente**: Persist√™ncia acontece em background

O objetivo √© capturar progresso sem quebrar o ritmo do pensamento do usu√°rio. Ele continua explorando e refinando ideias enquanto o sistema salva automaticamente pontos de maturidade.

### Versionamento Autom√°tico

Cada snapshot recebe uma vers√£o autom√°tica e incremental:

- **V1**: Primeiro snapshot criado quando argumento atinge maturidade inicial
- **V2**: Snapshot subsequente quando argumento evolui significativamente
- **V3, V4, V5...**: Vers√µes seguintes conforme argumento amadurece

O versionamento permite:
- **Rastreabilidade**: Ver evolu√ß√£o do argumento ao longo do tempo
- **Compara√ß√£o**: Comparar diferentes vers√µes do mesmo argumento
- **Recupera√ß√£o**: Retomar conversa de qualquer vers√£o anterior

```python
# Exemplo de versionamento
idea_id = "uuid-idea-123"
snapshot_v1 = create_snapshot(idea_id, cognitive_model_v1)  # version=1
snapshot_v2 = create_snapshot(idea_id, cognitive_model_v2)  # version=2
snapshot_v3 = create_snapshot(idea_id, cognitive_model_v3)  # version=3
```

### Trigger para √âpico 13: Detec√ß√£o de Conceitos

Quando um snapshot √© criado, o sistema automaticamente dispara o **pipeline de detec√ß√£o de conceitos** (√âpico 13):

```python
# Fluxo completo
1. Snapshot √© criado (CognitiveModel ‚Üí Argument persistido)
2. Pipeline de detec√ß√£o √© acionado automaticamente
3. LLM extrai conceitos-chave do snapshot
4. Sistema gera embeddings e busca conceitos similares
5. Cria novos conceitos ou vincula a conceitos existentes
6. Links Idea ‚Üî Concept s√£o criados
```

Esta integra√ß√£o permite que conceitos sejam detectados e organizados automaticamente sempre que um argumento atinge maturidade, construindo progressivamente a biblioteca global de conceitos do sistema.

> **Nota t√©cnica**: Para detalhes sobre implementa√ß√£o t√©cnica de snapshots, crit√©rios de maturidade e integra√ß√£o com detec√ß√£o de conceitos, consulte `docs/architecture/snapshot_strategy.md`.

## Refer√™ncias

- `docs/vision/epistemology.md` - Base filos√≥fica (proposi√ß√µes, solidez, evid√™ncias)
- `docs/architecture/ontology.md` - Ontologia: Conceito, Ideia, Argumento, Proposi√ß√£o, Evid√™ncia
- `docs/architecture/argument_model.md` - Estrutura t√©cnica de Argument
- `docs/architecture/idea_model.md` - Como Ideia possui Argumentos
- `docs/product/vision.md` (Se√ß√£o 4) - Entidade Ideia

