# √âPICO 8: Valida√ß√£o de Maturidade do Sistema - Automa√ß√£o

> **Objetivo:** Automatizar valida√ß√£o de qualidade conversacional com LLM-as-Judge para prevenir regress√µes futuras.

---

## üìã Vis√£o Geral

**Depend√™ncia:** √âpico 7 deve estar conclu√≠do (identificar problemas reais primeiro)

**Problema:**
- √âpico 7 validou sistema manualmente e identificou problemas reais
- Valida√ß√£o manual n√£o √© escal√°vel (n√£o previne regress√µes)
- Precisamos garantir que corre√ß√µes n√£o quebrem comportamentos que funcionam

**Solu√ß√£o:**
- Implementar infraestrutura LLM-as-Judge
- Criar testes automatizados para problemas identificados no √âpico 7
- Testes validam **qualidade conversacional**, n√£o apenas estrutura

**Resultado Esperado:**
- Testes automatizados que previnem regress√µes
- Valida√ß√£o de qualidade (n√£o apenas presen√ßa de campos)
- Execu√ß√£o r√°pida e custo baixo (~$0.01-0.02 por execu√ß√£o completa)

---

## üéØ O Que Automatizar

**Princ√≠pio:** Automatizar valida√ß√£o de **problemas reais identificados no √âpico 7**

**N√ÉO automatizar:**
- ‚ùå Problemas hipot√©ticos n√£o encontrados no √âpico 7
- ‚ùå Valida√ß√£o de estrutura (testes unit√°rios j√° fazem isso)
- ‚ùå Testes determin√≠sticos (usar testes de integra√ß√£o normais)

**Automatizar:**
- ‚úÖ Qualidade conversacional (fluidez, integra√ß√£o)
- ‚úÖ Comportamento socr√°tico (provoca√ß√£o genu√≠na)
- ‚úÖ Preserva√ß√£o de contexto (n√£o se perde entre transi√ß√µes)
- ‚úÖ Decis√µes coerentes (n√£o arbitr√°rias)

---

## üõ†Ô∏è Infraestrutura LLM-as-Judge

### 1. Fixture `llm_judge`

**Localiza√ß√£o:** `tests/conftest.py`

**Especifica√ß√£o:**
```python
@pytest.fixture
def llm_judge():
    """
    Fixture para LLM-as-judge (avaliador de qualidade).
    
    Usa Claude Haiku para custo-benef√≠cio.
    Temperature=0 para determinismo.
    """
    import os
    from langchain_anthropic import ChatAnthropic
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        pytest.skip("LLM-as-judge test skipped: ANTHROPIC_API_KEY not set")
    
    return ChatAnthropic(
        model="claude-3-5-haiku-20241022",
        temperature=0
    )
```

**Caracter√≠sticas:**
- Usa Haiku (custo-benef√≠cio)
- Temperature=0 (determin√≠stico)
- Pula testes se API key n√£o est√° definida (n√£o falha)

---

### 2. Prompts de Avalia√ß√£o

**Localiza√ß√£o:** `utils/test_prompts.py`

**5 Prompts Necess√°rios:**

#### 2.1 Fluidez Conversacional
```python
FLUENCY_PROMPT = """
Avalie a fluidez da mensagem do sistema:

1. N√£o pergunta permiss√£o ("Posso chamar X?")
2. Integra√ß√£o natural de outputs de agentes
3. Tom conversacional (n√£o burocr√°tico)

Mensagem: {message}

Avalie de 1-5 (5 = completamente fluida):
Justificativa:
"""
```

#### 2.2 Integra√ß√£o Entre Agentes
```python
INTEGRATION_QUALITY_PROMPT = """
Avalie a qualidade da integra√ß√£o entre agentes:

1. Transi√ß√µes naturais (sem quebras)
2. Contexto preservado (refer√™ncias a turnos anteriores)
3. Experi√™ncia coesa (n√£o parece sistema desconexo)

Orquestrador: {orchestrator_output}
Estruturador: {structurer_output}
Metodologista: {methodologist_output}
Mensagens ao usu√°rio: {messages}

Avalie de 1-5 (5 = integra√ß√£o excelente):
Justificativa:
"""
```

#### 2.3 Provoca√ß√£o Socr√°tica
```python
SOCRATIC_BEHAVIOR_PROMPT = """
Avalie se a resposta do sistema demonstra comportamento socr√°tico genu√≠no:

1. Provoca√ß√£o genu√≠na (exp√µe assumptions, n√£o coleta burocr√°tica)
2. Timing natural (n√£o regras fixas)
3. Parada inteligente (n√£o insiste infinitamente)

Resposta: {response}
Reflection prompt: {reflection_prompt}

Avalie de 1-5 (5 = excelente comportamento socr√°tico):
Justificativa:
"""
```

#### 2.4 Preserva√ß√£o de Contexto
```python
CONTEXT_PRESERVATION_PROMPT = """
Avalie se o contexto foi preservado entre transi√ß√µes de agentes:

1. Focal argument evolui coerentemente
2. Informa√ß√µes de turnos anteriores s√£o referenciadas
3. N√£o h√° perda de contexto (agente n√£o "esquece" informa√ß√µes)

Focal argument (antes): {focal_before}
Focal argument (depois): {focal_after}
Mensagens: {messages}

Avalie de 1-5 (5 = contexto perfeitamente preservado):
Justificativa:
"""
```

#### 2.5 Qualidade de Decis√µes
```python
DECISION_QUALITY_PROMPT = """
Avalie a qualidade da decis√£o do agente:

1. Decis√£o √© coerente com contexto fornecido
2. Justificativa √© clara e espec√≠fica
3. N√£o √© arbitr√°ria (usa crit√©rios expl√≠citos)

Contexto: {context}
Decis√£o: {decision}
Justificativa: {justification}

Avalie de 1-5 (5 = decis√£o excelente):
Justificativa:
"""
```

---

### 3. Helper `extract_score`

**Localiza√ß√£o:** `utils/test_helpers.py`

**Especifica√ß√£o:**
```python
import re

def extract_score(evaluation_content: str) -> int:
    """
    Extrai score (1-5) da avalia√ß√£o do LLM-as-judge.
    
    Procura por padr√µes:
    - "Avalie de 1-5: 4"
    - "score: 3"
    - "4/5"
    - Apenas n√∫mero na linha
    
    Args:
        evaluation_content: Conte√∫do da avalia√ß√£o do LLM
        
    Returns:
        int: Score de 1-5
        
    Raises:
        ValueError: Se n√£o encontrar score v√°lido
    """
    patterns = [
        r"Avalie de 1-5.*?(\d)",
        r"score.*?(\d)",
        r"(\d)\s*/\s*5",
        r"(\d)\s*=\s*(?:excelente|√≥timo|bom)",
        r"^(\d)$"  # Apenas n√∫mero na linha
    ]
    
    for pattern in patterns:
        match = re.search(pattern, evaluation_content, re.IGNORECASE | re.MULTILINE)
        if match:
            score = int(match.group(1))
            if 1 <= score <= 5:
                return score
    
    raise ValueError(f"N√£o foi poss√≠vel extrair score v√°lido de: {evaluation_content}")
```

---

### 4. Marker no `pytest.ini`

**Adicionar:**
```ini
[pytest]
markers =
    unit: Testes unit√°rios (mocks)
    integration: Testes de integra√ß√£o (API real)
    llm_judge: Testes que usam LLM-as-judge (requer API key)
    slow: Testes lentos (opcional)
```

---

## üìù Testes Automatizados

### Princ√≠pio: Adicionar Valida√ß√£o de Qualidade

**N√ÉO substituir testes existentes**  
**ADICIONAR** fun√ß√£o de teste com `@pytest.mark.llm_judge`

**Exemplo:**
```python
# Teste existente (estrutura)
def test_multi_agent_flow(multi_agent_graph):
    result = multi_agent_graph.invoke(state)
    assert result["orchestrator_analysis"] is not None
    assert result["next_step"] in ["explore", "suggest_agent"]

# ADICIONAR: Teste de qualidade
@pytest.mark.llm_judge
def test_multi_agent_flow_quality(multi_agent_graph, llm_judge):
    """Valida qualidade da experi√™ncia conversacional."""
    result = multi_agent_graph.invoke(state)
    
    # Valida√ß√£o estrutural (mant√©m)
    assert result["orchestrator_analysis"] is not None
    
    # NOVO: Valida√ß√£o de qualidade
    evaluation = llm_judge.invoke(
        CONVERSATION_QUALITY_PROMPT.format(
            response=result.get("messages", [])[-1].content,
            history=result.get("conversation_history", [])
        )
    )
    score = extract_score(evaluation.content)
    assert score >= 4, f"Qualidade conversacional insuficiente (score: {score})"
```

---

### Arquivos a Adicionar Testes

Baseado no **√âpico 7** (problemas identificados), adicionar testes em:

#### 1. `tests/integration/test_multi_agent_smoke.py`
**Validar:**
- Fluidez conversacional (sem "Posso chamar X?")
- Integra√ß√£o entre agentes (transi√ß√µes naturais)
- Preserva√ß√£o de contexto (focal_argument evolui)

**Exemplo:**
```python
@pytest.mark.llm_judge
def test_conversational_fluency(multi_agent_graph, llm_judge):
    """Valida que sistema n√£o pede permiss√£o para transi√ß√µes."""
    state = create_initial_multi_agent_state(
        "Observei que LLMs aumentam produtividade",
        session_id="test-fluency-1"
    )
    
    result = multi_agent_graph.invoke(state)
    
    # Extrair mensagens ao usu√°rio
    user_messages = [
        msg.content for msg in result.get("messages", [])
        if isinstance(msg, AIMessage)
    ]
    
    # Validar cada mensagem
    for message in user_messages:
        evaluation = llm_judge.invoke(
            FLUENCY_PROMPT.format(message=message)
        )
        score = extract_score(evaluation.content)
        assert score >= 4, f"Mensagem n√£o √© fluida: {message[:50]}... (score: {score})"
```

---

#### 2. `tests/integration/test_methodologist_smoke.py`
**Validar:**
- Perguntas s√£o socr√°ticas (n√£o burocr√°ticas)
- Decis√µes t√™m crit√©rios claros (n√£o arbitr√°rias)

**Exemplo:**
```python
@pytest.mark.llm_judge
def test_socratic_questions_quality(methodologist_graph, llm_judge):
    """Valida que perguntas do Metodologista s√£o socr√°ticas."""
    state = create_initial_methodologist_state(
        "Caf√© aumenta produtividade"
    )
    
    result = methodologist_graph.invoke(state)
    
    if result.get("status") == "pending":
        clarifications = result.get("clarifications", {})
        
        for question in clarifications.keys():
            evaluation = llm_judge.invoke(
                SOCRATIC_QUESTION_PROMPT.format(question=question)
            )
            score = extract_score(evaluation.content)
            assert score >= 4, f"Pergunta n√£o √© socr√°tica: {question} (score: {score})"
```

---

#### 3. `scripts/flows/validate_socratic_behavior.py` ‚Üí Converter para teste automatizado
**Validar:**
- Provoca√ß√£o socr√°tica genu√≠na (exp√µe assumptions)
- Timing natural (n√£o regras fixas)
- Parada inteligente (n√£o insiste infinitamente)

**Exemplo:**
```python
@pytest.mark.llm_judge
def test_socratic_provocation_quality(orchestrator_node, llm_judge):
    """Valida que provoca√ß√£o socr√°tica √© genu√≠na."""
    state = create_state_with_vague_metric(
        "Quero medir produtividade"
    )
    
    result = orchestrator_node(state)
    
    reflection_prompt = result.get("reflection_prompt", "")
    response = result.get("messages", [])[-1].content
    
    evaluation = llm_judge.invoke(
        SOCRATIC_BEHAVIOR_PROMPT.format(
            response=response,
            reflection_prompt=reflection_prompt
        )
    )
    score = extract_score(evaluation.content)
    assert score >= 4, f"Provoca√ß√£o n√£o √© socr√°tica (score: {score})"
```

---

#### 4. `scripts/flows/validate_conversation_flow.py` ‚Üí Converter para teste automatizado
**Validar:**
- Fluidez conversacional end-to-end
- N√£o h√° quebras entre transi√ß√µes

---

#### 5. `scripts/flows/validate_multi_agent_flow.py` ‚Üí Converter para teste automatizado
**Validar:**
- Integra√ß√£o natural entre agentes
- Contexto preservado durante transi√ß√µes

---

#### 6. `scripts/flows/validate_refinement_loop.py` ‚Üí Converter para teste automatizado
**Validar:**
- Refinamentos endere√ßam gaps de forma significativa
- Evolu√ß√£o √© coerente (n√£o apenas mudan√ßa cosm√©tica)

---

## üìä Estrat√©gia de Execu√ß√£o

### Desenvolvimento Local
```bash
# Rodar apenas testes LLM-as-Judge
pytest -m llm_judge

# Rodar testes LLM-as-Judge + estruturais
pytest tests/integration/ -m "integration or llm_judge"
```

### CI/CD (futuro - n√£o implementado)
- Rodar LLM-as-Judge apenas em PRs relevantes (quando toca c√≥digo de agentes)
- Usar `ANTHROPIC_API_KEY` de teste via GitHub Secrets
- Limite de custo: ~$0.02 por PR

### Custo Estimado
- **Por teste LLM-as-Judge:** ~$0.001-0.002 (Haiku)
- **Suite completa (10-15 testes):** ~$0.01-0.02
- **CI/CD mensal (30 PRs):** ~$0.30-0.60

---

## üéØ Crit√©rios de Aceite do √âpico 8

### 8.1 Infraestrutura Implementada
- [ ] Fixture `llm_judge` criada em `tests/conftest.py`
- [ ] 5 prompts de avalia√ß√£o criados em `utils/test_prompts.py`
- [ ] Fun√ß√£o `extract_score` criada em `utils/test_helpers.py`
- [ ] Marker `@pytest.mark.llm_judge` adicionado em `pytest.ini`
- [ ] Testes pulam se `ANTHROPIC_API_KEY` n√£o est√° definida

### 8.2 Testes Automatizados Criados
- [ ] Testes adicionados em `test_multi_agent_smoke.py` (fluidez, integra√ß√£o)
- [ ] Testes adicionados em `test_methodologist_smoke.py` (socr√°tico, decis√µes)
- [ ] Scripts de valida√ß√£o convertidos para testes automatizados:
  - [ ] `validate_socratic_behavior.py`
  - [ ] `validate_conversation_flow.py`
  - [ ] `validate_multi_agent_flow.py`
  - [ ] `validate_refinement_loop.py`
- [ ] Cada teste valida qualidade (score >= 4) al√©m de estrutura
- [ ] Testes cobrem problemas identificados no √âpico 7

### 8.3 Documenta√ß√£o Atualizada
- [ ] `docs/testing/strategy.md` atualizado com se√ß√£o sobre LLM-as-Judge
- [ ] Custos estimados documentados (~$0.01-0.02 por execu√ß√£o)
- [ ] Estrat√©gia de execu√ß√£o documentada (local, CI/CD)
- [ ] Como adicionar novos testes LLM-as-Judge documentado

---

## üìö Refer√™ncias

- `docs/testing/epic7_validation_strategy.md` - Valida√ß√£o manual (Fase 1)
- `docs/analysis/llm_judge_strategy.md` - An√°lise completa de estrat√©gia
- `docs/testing/strategy.md` - Estrat√©gia geral de testes

---

**Vers√£o:** 1.0  
**Data:** Dezembro 2025  
**Relacionado:** √âPICO 8 no ROADMAP

