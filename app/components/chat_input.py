"""
Componente de input de chat para interface web conversacional (√âpico 9.1 + 9.2).

Respons√°vel por:
- Renderizar campo de texto para mensagens do usu√°rio
- Invocar LangGraph quando usu√°rio envia mensagem
- Atualizar hist√≥rico de conversa
- Exibir m√©tricas inline (tokens, custo, tempo)

Vers√£o: 3.0
Data: 16/11/2025
Status: Prot√≥tipo completo (localStorage - √âpico 9.9)
"""

import streamlit as st
import logging
from datetime import datetime
from typing import Optional

# Imports do backend
from agents.multi_agent_graph import create_multi_agent_graph
from agents.orchestrator.state import create_initial_multi_agent_state
from utils.event_bus import get_event_bus

# Import localStorage (√âpico 9.9 - Prot√≥tipo)
from app.components.storage import (
    save_session_messages,
    save_session_metadata,
    add_session_to_list
)

logger = logging.getLogger(__name__)


def render_chat_input(session_id: str) -> None:
    """
    Renderiza input de chat e processa mensagens do usu√°rio.

    Args:
        session_id: ID da sess√£o ativa

    Comportamento POC (9.1 + 9.2):
        - Campo de texto para mensagem
        - Bot√£o "Enviar" para submeter
        - Spinner durante processamento
        - Invoca LangGraph com session_id
        - Atualiza st.session_state.messages com resultado

    Integra√ß√£o:
        - LangGraph: Processa input e retorna resposta do orquestrador
        - EventBus: Eventos s√£o publicados automaticamente pelo grafo
        - M√©tricas: Tokens, custo e tempo extra√≠dos dos eventos
    """
    # Usar st.form para melhor UX (permite Enter para enviar)
    with st.form(key="chat_form", clear_on_submit=True):
        user_input = st.text_area(
            "Digite sua mensagem:",
            key="chat_input",
            placeholder="Me conte sobre sua ideia ou observa√ß√£o...",
            height=100,
            label_visibility="collapsed"
        )

        col1, col2 = st.columns([1, 5])
        with col1:
            send_button = st.form_submit_button("Enviar", type="primary", use_container_width=True)

    # Processar mensagem quando bot√£o clicado
    if send_button and user_input.strip():
        _process_user_message(user_input.strip(), session_id)


def _process_user_message(user_input: str, session_id: str) -> None:
    """
    Processa mensagem do usu√°rio invocando LangGraph.

    Args:
        user_input: Mensagem do usu√°rio
        session_id: ID da sess√£o ativa

    Fluxo:
        1. Adiciona mensagem do usu√°rio ao hist√≥rico
        2. Invoca LangGraph (mostra spinner)
        3. Extrai resposta do orquestrador
        4. Busca m√©tricas consolidadas do EventBus
        5. Adiciona resposta do sistema ao hist√≥rico
        6. Re-renderiza interface
    """
    # Inicializar hist√≥rico se necess√°rio
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Adicionar mensagem do usu√°rio (sem m√©tricas ainda)
    st.session_state.messages.append({
        "role": "user",
        "content": user_input,
        "tokens": None,
        "cost": None,
        "duration": None,
        "timestamp": datetime.now().isoformat()
    })

    # Invocar LangGraph com spinner
    with st.spinner("ü§ñ Sistema est√° pensando..."):
        try:
            result = _invoke_langgraph(user_input, session_id)

            # Extrair resposta do orquestrador
            # A mensagem est√° em messages[-1].content (√∫ltimo AIMessage)
            messages = result.get("messages", [])
            if messages and len(messages) > 0:
                # Pegar √∫ltima mensagem (AIMessage do orquestrador)
                last_message = messages[-1]
                assistant_message = last_message.content if hasattr(last_message, 'content') else str(last_message)
            else:
                # Fallback se n√£o houver mensagens
                logger.warning(f"Nenhuma mensagem encontrada no resultado. Usando fallback.")
                assistant_message = "Sistema processou mas n√£o retornou mensagem. Verifique os logs."

            # Debug logging
            logger.info(f"Mensagem extra√≠da do orquestrador: {assistant_message[:100]}...")

            # Buscar m√©tricas consolidadas do EventBus
            metrics = _get_latest_metrics(session_id)

            # Adicionar resposta do sistema ao hist√≥rico
            st.session_state.messages.append({
                "role": "assistant",
                "content": assistant_message,
                "tokens": metrics.get("tokens"),
                "cost": metrics.get("cost"),
                "duration": metrics.get("duration"),
                "timestamp": datetime.now().isoformat()
            })

            logger.info(f"Mensagem processada com sucesso (sess√£o: {session_id[:8]}...)")

            # Salvar no localStorage (√âpico 9.9 - Prot√≥tipo)
            _save_to_localstorage(session_id, user_input)

        except Exception as e:
            logger.error(f"Erro ao processar mensagem: {e}", exc_info=True)
            st.error(f"‚ùå Erro ao processar mensagem: {e}")
            # Remover mensagem do usu√°rio se houve erro
            st.session_state.messages.pop()
            return

    # Re-renderizar interface (force update)
    st.rerun()


def _invoke_langgraph(user_input: str, session_id: str) -> dict:
    """
    Invoca LangGraph e retorna resultado.

    Args:
        user_input: Mensagem do usu√°rio
        session_id: ID da sess√£o ativa

    Returns:
        dict: Estado final do grafo com:
            - orchestrator_output: {message, next_step, agent_suggestion, ...}
            - next_step: "explore", "clarify", "suggest_agent", etc
            - orchestrator_analysis: reasoning completo
            - ... (outros campos do MultiAgentState)

    Raises:
        Exception: Se houver erro na execu√ß√£o do grafo
    """
    logger.info(f"Invocando LangGraph para sess√£o {session_id[:8]}...")

    # Criar grafo (singleton - cache em produ√ß√£o)
    graph = create_multi_agent_graph()

    # Criar estado inicial
    state = create_initial_multi_agent_state(
        user_input=user_input,
        session_id=session_id
    )

    # Configura√ß√£o com thread_id (preserva hist√≥rico entre turnos)
    config = {
        "configurable": {
            "thread_id": session_id
        }
    }

    # Invocar grafo
    result = graph.invoke(state, config=config)

    logger.debug(f"LangGraph executado. Next step: {result.get('next_step')}")

    return result


def _get_latest_metrics(session_id: str) -> dict:
    """
    Busca m√©tricas consolidadas do √∫ltimo turno no EventBus.

    Args:
        session_id: ID da sess√£o ativa

    Returns:
        dict: {
            "tokens": {"input": int, "output": int, "total": int},
            "cost": float,
            "duration": float
        }

    Nota:
        Consolida m√©tricas de todos os agentes executados no √∫ltimo turno.
        Se m√∫ltiplos agentes foram chamados (ex: orchestrator ‚Üí structurer),
        soma tokens/custo e usa dura√ß√£o total.
    """
    try:
        bus = get_event_bus()
        events = bus.get_session_events(session_id)

        # Filtrar apenas eventos "agent_completed" do √∫ltimo turno
        # (assumir que √∫ltimo turno = eventos ap√≥s √∫ltimo "agent_started" do orchestrator)
        completed_events = [e for e in events if e.get("event_type") == "agent_completed"]

        if not completed_events:
            logger.warning(f"Nenhum evento agent_completed encontrado para {session_id}")
            return {"tokens": None, "cost": None, "duration": None}

        # Consolidar m√©tricas (soma tokens/custo, max duration)
        total_tokens_input = 0
        total_tokens_output = 0
        total_cost = 0.0
        max_duration = 0.0

        # Pegar apenas eventos do √∫ltimo turno (√∫ltimos N eventos - heur√≠stica: √∫ltimos 5)
        recent_events = completed_events[-5:]

        for event in recent_events:
            total_tokens_input += event.get("tokens_input", 0)
            total_tokens_output += event.get("tokens_output", 0)
            total_cost += event.get("cost", 0.0)
            max_duration = max(max_duration, event.get("duration", 0.0))

        total_tokens = total_tokens_input + total_tokens_output

        logger.debug(f"M√©tricas consolidadas: {total_tokens} tokens, ${total_cost:.4f}, {max_duration:.2f}s")

        return {
            "tokens": {
                "input": total_tokens_input,
                "output": total_tokens_output,
                "total": total_tokens
            },
            "cost": total_cost,
            "duration": max_duration
        }

    except Exception as e:
        logger.warning(f"Erro ao buscar m√©tricas do EventBus: {e}")
        return {"tokens": None, "cost": None, "duration": None}


def _save_to_localstorage(session_id: str, user_input: str) -> None:
    """
    Salva hist√≥rico e metadados no localStorage (√âpico 9.9 - Prot√≥tipo).

    Args:
        session_id: ID da sess√£o ativa
        user_input: Primeiro input do usu√°rio (para gerar t√≠tulo)

    Comportamento:
        - Salva st.session_state.messages no localStorage
        - Atualiza metadados da sess√£o (t√≠tulo, √∫ltima atividade)
        - Adiciona sess√£o √† lista de sess√µes
    """
    try:
        # Salvar mensagens
        messages = st.session_state.get("messages", [])
        save_session_messages(session_id, messages)

        # Gerar/atualizar metadados
        message_count = len(messages)

        # Auto-gerar t√≠tulo baseado no primeiro input do usu√°rio
        title = _generate_session_title(messages, user_input)

        metadata = {
            "title": title,
            "created_at": messages[0]["timestamp"] if messages else datetime.now().isoformat(),
            "last_activity": datetime.now().isoformat(),
            "message_count": message_count
        }

        save_session_metadata(session_id, metadata)

        # Adicionar √† lista de sess√µes (evita duplicatas automaticamente)
        add_session_to_list(session_id)

        logger.debug(f"Sess√£o salva no localStorage: {session_id[:8]}... ({message_count} mensagens)")

    except Exception as e:
        logger.warning(f"Erro ao salvar no localStorage: {e}")
        # N√£o interromper fluxo se localStorage falhar


def _generate_session_title(messages: list, user_input: str) -> str:
    """
    Gera t√≠tulo autom√°tico para a sess√£o baseado no primeiro input.

    Args:
        messages: Lista de mensagens da sess√£o
        user_input: Input atual do usu√°rio

    Returns:
        str: T√≠tulo da sess√£o (max 50 chars)

    Estrat√©gia:
        - Se √© primeira mensagem: usar user_input truncado
        - Se j√° existe t√≠tulo nos metadados: manter
        - Fallback: "Conversa {data}"
    """
    # Se √© primeira mensagem do usu√°rio (√≠ndice 0 ou 1), usar como t√≠tulo
    user_messages = [m for m in messages if m.get("role") == "user"]

    if len(user_messages) <= 1 and user_input:
        # Primeira intera√ß√£o - usar input como t√≠tulo
        title = user_input[:50]
        if len(user_input) > 50:
            title += "..."
        return title
    elif user_messages:
        # Usar primeira mensagem como t√≠tulo (j√° salvo antes)
        first_user_msg = user_messages[0]["content"]
        title = first_user_msg[:50]
        if len(first_user_msg) > 50:
            title += "..."
        return title
    else:
        # Fallback
        return f"Conversa {datetime.now().strftime('%d/%m/%Y %H:%M')}"
